\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{dirtytalk}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[nodayofweek]{datetime}
\longdate
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{amsthm}
\usepackage{comment}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{float}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition} % definition numbers are dependent on theorem numbers
\newtheorem{exmp}[thm]{Example} % same for example numbers

\setlength\columnsep{30pt}

\geometry{
 	a4paper,
	total={170mm,257mm},
 	left=20mm,
 	top=20mm,
}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\title{
	 \huge 304: Logic-Based Learning\\
	 \huge -- Reference --
}
\date{\today}
\author{
	Sam Yong \\
	\small \href{mailto:sam.yong17@imperial.ac.uk}{sam.yong17@imperial.ac.uk}
}


\begin{document}
\maketitle

\begin{multicols}{2}

\paragraph{} NOTICE: This set of reference is currently incomplete with respect to the syllabus of the course and will be updated as the semester progress. By end Mar 2018 it should be complete.

\section*{Foreword}  

\paragraph{} This reference was made as an condensation from the lecture slides and notes provided by Prof. Alessandra Russo, Prof. Stephen Muggleton and Mark Law in the Imperial College London, Department of Computing's 304: Logic-Based Learning.

\paragraph{} The ordering of this reference may not correspond to the sequence introduced in the lectures, lecture slides and notes. This order is how I feel I would understand the topic better.

\begin{footnotesize}
\paragraph{License} This reference is made publicly available under the MIT License. You should not have paid anyone money in exchange for this document. If you have paid someone for it, well too bad. The source code for this document can be found public available on my Github repository\footnote{\href{https://github.com/mauris/written}{https://github.com/mauris/written}}. If you wish to help improve this document, feel free to open an issue on the Github repository.
\end{footnotesize}

\newpage
\tableofcontents
\newpage

\section{Background}
\subsection{Forms of Reasoning}

\paragraph{Deduction} Reasoning from the general to reach the particular: what follow necessarily from the given premises.

\begin{itemize}
\item \textbf{Rule}: All beans in this bag are white.
\item \textbf{Case}: These beans are from this bag.
\item \textbf{Result}: These beans are white.
\end{itemize}

\paragraph{Induction} Reasoning from the specifics to reach the general: process of deriving reliable generalisations from observations.

\begin{itemize}
\item \textbf{Rule}: These beans are from this bag.
\item \textbf{Case}: These beans are white.
\item \textbf{Result}: All beans in this bag are white.
\end{itemize}

\paragraph{Abduction} Reasoning from observations to explanations: process of using given general rules to establish causal relationships between existing knowledge and observations. 

\begin{itemize}
\item \textbf{Rule}: All beans in this bag are white.
\item \textbf{Case}: These beans are white.
\item \textbf{Result}: These beans are from this bag.
\end{itemize}

\subsection{Clausal Representation}
\subsubsection{Propositional Logic}
\paragraph{} We begin by introducing the clausal representation with the following definitions:

\begin{itemize}
\item \textbf{Theory}: a set (conjunction) of clauses\footnote{Clausal finite theories can also be seen as Conjunctive Normal Form (CNF) formulae.}.\\ e,g, $\{p \lor \lnot q; r; s\}$
\item \textbf{Clause}: disjunction of literals.\\ e.g. $p \lor \lnot q$, $r$, $s$
\item \textbf{Literal}: Atomic sentence or its negation.\\ e.g. $p$, $\lnot q$
\end{itemize}

\paragraph{} As we want to explore how inference tasks can be computed, we will restrict ourselves to the subset of predicate logic that is computational tractable and where efficient automated proof procedures that are able to compute logical inference exists. This subset of predicate logic is called Horn clauses\footnote{A subset of Prolog language.}. Every formula can be converted into a clausal theory:

\begin{itemize}
\item Elimination of $\implies$:\\ $(p \implies q) \longrightarrow \lnot p \lor q$
\item Pushing $\lnot$ inwards:\\ $\lnot(p \lor q) \longrightarrow (\lnot p \land \lnot q)$
\item Distribution of $\land$ and $\lor$:\\ $(\lnot p \land \lnot q) \lor \lnot p \longrightarrow (\lnot p \lor \lnot p) \land (\lnot q \lor \lnot p)$
\item Collecting Terms:\\ $(\lnot p \lor \lnot p) \land (\lnot q \lor \lnot p) \longrightarrow \lnot p \land (\lnot q \lor \lnot p)$
\end{itemize}

\subsubsection{Predicate Logic}

\paragraph {} In the case of predicate logic, atomic sentences may have terms with variables:

\begin{itemize}
\item \textbf{Theory}: a set (conjunction) of clauses.\\ e.g. $\{p(X) \lor \lnot r(a, f(b, X)); q(X, Y)\}$\\ All variables are understood to be universally quantified, i.e.\\ $\forall X, Y [r(a, f(b, X) \implies p(X)] \land \forall X, Y\ q(X, Y)$
\end{itemize}

\paragraph{Substitution} Since terms may have variables in predicate logic, substitution is needed to ground literals. For example, let $\theta = \{V_1/t_1, V_2/t_2, ..., V_n/t_n\}$ where $V_i$ is a variable and $t_i$ a term that replaces $V_i$. Suppose, 

\begin{align*}
&p(X, Y)\\
\theta &= \{X/a, Y/g(b, Z)\}\\
p(X, Y)\theta &= p(a, g(b, Z))
\end{align*}

\paragraph{Grounding} A literal is \textit{ground} if it contains no variables.

\paragraph{Instance} A literal $l'$ is \textit{an instance of} $l$, if for some substitution $\theta$, $l' = l\theta$.

\paragraph{Skolemisation} When converting FOL to CNF, we also need to perform skolemisation to remove existential quantifiers and move all universal quantifiers to the front. 

\begin{itemize}
\item An existential quantifier with no dependency can be skolemised by introducing a new constant. For example, $\exists X\ p(X) \longrightarrow p(c)$. The constant $c$ that is replacing $X$ must not clash in name with other existing constants.
\item If an existential quantifier depends on another quantifier, a function symbol needs to be introduced. For example, $\forall X \exists Y p(X, Y) \longrightarrow \forall p(X, f(X))$.
\end{itemize}

\noindent All universal quantifiers need to be moved to the front. Variable name clashes must be resolved by renaming variables as the universal quantifiers are being moved to the front. Once they are at the front, all universal quantifiers at the front can all be removed. 

\subsection{Horn Clauses}

\begin{defn}Horn Clauses are a particular type of clauses with at most one positive literal only. The positive literal in the clauses is called the head and the other literals form the body of the clause.\end{defn}

\begin{defn}Definite Clauses have exactly one positive literal.  e.g. $\lnot b_1 \lor\lnot b_2 \lor ... \lor\lnot b_n \lor h$. Definite Clauses (aka rules) can also be re-written as $h \Leftarrow b_1 \land b_2 \land ... \land b_n$.\end{defn}

\begin{defn}Denials have no positive clauses. e.g. $\lnot b_1 \lor\lnot b_2 \lor ... \lor\lnot b_n$. Denials (aka constraints) can also be re-written as $\Leftarrow b_1 \land b_2 \land ... \land b_n$.\end{defn}

\begin{defn}Facts are Definite Clauses that have no negative literals. e.g. $h$. We omit the $\leftarrow$  or \lstinline{:-} symbols as with convention for facts.\end{defn}

\subsection{Resolution}

\paragraph{} Resolution is a proof strategy to determine if a proposition can be satisfied by a clausal theory. Essentially, we will see that resolution is actually proof by contradiction (or in Latin, \textit{reductio ad absurdum} abbreviated as RAA).

\subsubsection{Propositional Logic Resolution}

\paragraph{Resolvent} Given two clauses of the form\\ $\{p \lor C_1; \lnot p \lor C_2\}$, the clause $C_1 \lor C_2$ is the inferred clause, called the \textit{resolvent} (conclusion of the premise).

\begin{figure}[H]
\centering
\includegraphics[width=0.25\textwidth]{graphics/propositional-logic-resolution-example1.png}
\caption{In this example, $\lnot r$ and $r$ gets cancelled away and resolves the two statement $w \lor r \lor q$ and $w \lor s \lor \lnot r$ into $w \lor q \lor s$}
\end{figure}

\paragraph{Refutation Completeness} Resolution is complete as a refutation system. That is, if $S$ is a contradictory set of clauses, then resolution can refute $S$, i.e. $S \vdash [\ ]$ or $S \vdash \perp$. For example given the case of $p \models p \lor q$, resolution cannot be directly applied to the given clausal theory $Th = \{p\}$ and infer $p \lor q$. Instead, we have to express it as a refutation problem and show that $\{p, \lnot(p \lor q)\} \models [\ ]$. We then show that the set of clauses $\{p, \lnot p, \lnot q\}$ converted from $Th$ can derive the empty clause $[\ ]$.

\begin{figure}[H]
\centering
\includegraphics[width=0.2\textwidth]{graphics/propositional-logic-resolution-example2.png}
\caption{In the example to show $p \models p \lor q$, we need to first express it as a refutation problem then derive the empty clause using resolution. Not all clauses need to be used.}
\end{figure}

\paragraph{Resolution} Given a knowledge base of clauses $Kb$, if $Kb \vdash c$ by resolution then $Kb \models c$. 

\begin{exmp}For example,
\begin{align*}
Kb &= \{\\
	&s;\\
	&s \implies c;\\
	&c \land m \implies b;\\
	&c \land f \implies g;\\
	&f\\
	\}&
\end{align*}

\noindent To prove that $Kb \models g$, we show that $Kb \cup \{\lnot g\} \models [\ ]$:

\begin{figure}[H]
\centering
\includegraphics[width=0.32\textwidth]{graphics/propositional-logic-resolution-example3.png}
\caption{By resolution we show that $Kb \cup \{\lnot g\} \models [\ ]$, hence $Kb \models g$.}
\end{figure}\end{exmp}

\subsubsection{Predicate Logic Resolution}

\paragraph{} Resolution in FOL is more complex: while it is still based on the idea of resolving opposite literals that appear in two clauses and deriving the empty clause, variables play an important role here. Literals may have unground terms (i.e. variables that yet to be substituted) which are understood as standing for all possible instances. Resolution could happen by referring to any such instances. Hence the role of the unification step is to identify which of these instances to use.

\paragraph{Name Clashes} When resolving two clauses, all variables occurring should be renamed with unused variables to avoid name clashes. A variable $X$ in clause $C_1$ is not the same as another variable named $X$ in $C_2$.

\paragraph{Resolution} Consider two opposite literals in two clauses which we want to resolve: We see if it is possible to find a substitution $\theta$ st when applied to both literals, $\theta$ makes the two literals equal. The resolution can then applied and the substitution has to be applied on all occurrences of those variables in the literals left in the resolvent. For example, suppose

\begin{align*}
Kb &= \{\\
	&on(a, b);\\
	&on(b, c);\\
	&green(a);\\
	&\lnot green(c)\\
	\}&
\end{align*}

\noindent and we want to show that $Kb \models \exists X \exists Y (on(X, Y) \land green(X) \land \lnot green(Y))$, we can apply the following resolution:

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{graphics/predicate-logic-resolution-example1.png}
\caption{The resolution takes the two substitutions (labelled blue) two create equally opposing literals for $on(X, Y)$.}
\end{figure}

\paragraph{} As we take the negation of the entailment, the existential quantifiers get eliminated and hence there is no need for skolemisation.

\paragraph{Answers to Query} Answer to the query may also return unification values (substitution). However, it is possible to construct resolutions that never terminate.

\subsection{Herbrand Theorem}

\paragraph{} It is possible to handle some predicate logic cases by converting them into propositional logic form. Consider $Th$ be a set of clauses (a clausal theory).

\paragraph{Herbrand Domain}\footnote{Also known as Herbrand Universe.} The set of all ground terms formed only using constants and function symbols that appear in $Th$.

\paragraph{Herbrand Base} The set of all ground atoms that can be formed using the predicate symbols in $Th$ and terms in the Herbrand Domain.

\paragraph{Grounding} The set of all $c_i\theta$ ground clauses st $c_i \in Th$ and the substitution $\theta$ replaces variables in $c_i$ by terms in the Herbrand Domain. The grounding of $Th$ is denoted as $ground(Th)$.

\paragraph{Theorem} A clausal theory $Th$ is \textit{satisfiable} iff the grounding of $Th$ is \textit{satisfiable}. Since the grounding of $Th$ has no variables, it is essentially propositional. $Th$ is not satisfiable iff by resolution the grounding of $Th$ concludes to the empty clause.

\begin{exmp}\label{exmp:HerbrandTheorem} Consider FOL sentence $S$ whose language $\mathcal{L}$ includes only the constants $b$, $c$, $l$:\end{exmp}

$$S = \forall X, Y [\lnot p(b, Y) \lor p(c, l) \lor (p(b, X)\lor \lnot p(X, l))]$$

\noindent From $S$ we can build the set $C$ of clauses st $C = \{\lnot p(b, Y); p(c,l); p(b, X) \lor \lnot p(X, l)\}$. The \textit{Herbrand Domain of $C$} is $\{b, c, l\}$ while the grounding is:

\begin{align*}
ground(C) &= \{\\
	&\lnot p(b, b),\\
	&p(b, b), \lor \lnot p(b, l),\\
	&\lnot p(b, c),\\
	&p(b, c) \lor \lnot p(c, l),\\
	&\lnot p(b, l),\\
	&p(b, l) \lor \lnot p(l, l),\\
	&p(c, l)\\
	\}&
\end{align*}

\paragraph{} In Example \ref{exmp:HerbrandTheorem}, $ground(C)$ is not satisfiable because of a contradicting subset of the ground clauses: $\{\lnot p(b, c), p(c, l), p(b, c) \lor\lnot p(c, l)\}$. Hence the set of clauses $C$ is unsatisfiable.


\paragraph{Herbrand Interpretation} A Herbrand Intepretation (HI) of a set $Th$ of definite clauses is a set of ground atoms over the constant, function and predicate symbols occurring in $Th$. In essence, a HI is a subset of the Herbrand Base of $Th$, and the set of all Herbrand Interpretations of $Th$ is the power set of the Herbrand Base.

\paragraph{Herbrand Model} A Herbrand Interpretation $I$ is a Herbrand Model (HM) of $Th$ iff for all clauses $\lnot b_1 \lor \lnot b_2 \lor ... \lor \lnot b_n \lor h_1 \lor h_2 \lor ... \lor h_m$ in $Th$ and ground substitutions $\theta$, $$\{b_1\theta, b_2\theta, ..., b_n\theta\} \in I \implies \{h_1\theta, h_2\theta, ..., h_m\theta\} \cap I \not= \emptyset$$

\noindent The inequality with an empty set denotes that the HI $I$ must satisfy $\exists i \in [1, m]\ h_i\theta$. Hence a Herbrand Model is a Herbrand Interpretation is satisfable in a clausal theory.

\begin{defn} Since there may be more than one HI that satisfies a clausal theory (i.e. more than one HM), some HM may be a subset of another HM. The \textit{Minimal Herbrand Model} is a HM of which none of its subsets is a HM. Any satisfiable clausal theory $Th$ of definite clauses has one unique minimal HM called the \textit{Least Herbrand Model}. \end{defn}

\paragraph{Infinite Herbrand Domain} It is possible for a clausal theory to accept an infinite HM as they may have an infinite HD. Consider the following example which has an infinite HD:

\begin{align*}
Th &= \{\\
	&\text{natural}(0),\\
	&\text{natural}(X) \implies \text{natural}(succ(X))\\
	\}&
\end{align*}

\subsection{SLD Derivation}
\paragraph{} A pure Prolog program is a set of definite clauses and hence its semantics is given by its Least Herbrand Model\footnote{Defined by Luc De Raedt in his book.}. The inference procedure used by Prolog is a special version of resolution that exploits the fact that the given clausal theory is a set of definite clauses and not general clauses. 

\paragraph{} Queries to a Prolog program are not any arbitrary clauses but denial clauses\footnote{We want to proof by refutation.}. Arbitrary clauses must be rewritten in a certain way to accomodate this syntactic restriction of Prolog. 

\paragraph{} Given a set of definite clauses and a denial clause, there can be many resolution proofs that can be constructed. Prolog uses a special form of resolution - SLD resolution - to systematically explore all possible derivations. The SLD derivation is a linear sequence of application of an SLD inference rule that is applied between a denial clause and a definite clause in the original $Th$ clausal theory. SLD is a resolution proof method and as such is still refutation based. Hence the denial clause is the given query expressed in denial form. 

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sld-inference-rule.png}
\caption{$\theta$ in the inference rule is the Most General Unifier $mgu(\alpha_1, \alpha_1')$. $\alpha_i$ and $\beta_j$ are atoms.}
\end{figure}

\paragraph{} Given a denial (goal) $G_0$ and clausal theory $Th$ of definite clauses, an SLD-derivation of $G_0$ from $Th$ is a (possibly infinite) sequence of denials:

$$G_0 \underset{C_0}{\implies} G_1 \underset{C_1}{\implies} ...  \underset{C_{n-2}}{\implies} G_{n - 1}\underset{C_{n - 1}}{\implies} G_n  $$

\noindent ... where $G_{i + 1}$ is derived directly from $G_i$ and a clause $C_i$ with variables appropriate renamed. This means the composition $\theta = \theta_1 \theta_2 ... \theta_n$, where $\theta_i$ is defined at each step of the derivation, gives the entire substitution computed reaching the final derivation if computation is \textit{finite}.

\subsubsection{SLD Trees}

\paragraph{} When performing SLD derivation, there may be one or more choices of clause $C_i$ that can be used with $G_i$ to derive $G_{i+1}$. Consider the following knowledge base and the query $\exists Z\ \text{proud}(Z)$:

\begin{itemize}
\setlength\itemsep{0.0em}
\item[] $\text{proud}(X) \Leftarrow \text{parent}(X, Y), \text{newborn}(Y)$
\item[] $\text{parent}(X, Y) \Leftarrow \text{father}(X, Y)$
\item[] $\text{parent}(X, Y) \Leftarrow \text{mother}(X, Y)$
\item[] $\text{father}(\text{adam}, \text{mary})$
\item[] $\text{newborn}(\text{mary})$
\end{itemize}


\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{graphics/sld-derivation-example.png}
\caption{By SLD derivation, we determine that $Z = \text{adam}$.}
\end{figure}

\paragraph{} However we can see that at $C_2$, another clause $\text{parent}(X, Y) \Leftarrow mother(X, Y)$ could have been picked instead for the reservation. When each sub-goal can unify with more clauses, more than one SLD derivations can be computed. Alternative choices can then be represented as a tree, with each leaf as a possible derivation.

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{graphics/sld-tree.png}
\caption{Each time there is a choice of clauses can be be used to resolve the subgoals, branches are created in the tree to represent the different possible derivations. In this case, picking $\Leftarrow \text{mother}(X, Y), \text{newborn}(Y)$ as $G_2$ would lead to a non-empty derivation. }
\end{figure}

\paragraph{} The SLD Tree represents the search space of all possible derivations. Each path from the original denial $G_0$ to the leaf node is the SLD computation / refutation. The tree is then traversed in a depth-first search to provide each refutation in order. For a finite SLD-tree, this strategy is complete. Whenever the traversal reaches a leaf node of an empty clause, the substitution of the completed refutation is returned. As mentioned before, it is also possible for SLD derivation to generate an infinite sequence of denials and hence an infinite SLD-tree, which explains why sometimes Prolog computations do not terminate.

\subsection{Normal Clausal Logic}\label{sec:NormalClausalLogic}

\paragraph{Normal Clausal Logic} extends Horn Clauses by permitting atoms in the body of a rule / denial to be prefixed with a special operator \textit{not} (read as "fail"). This operator is also referred to as "negation by failure". For example:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] \textbf{Normal Clauses}:\\ $h \Leftarrow b_1, ... b_n, \text{not}\ b_{n+1}, ..., \text{not}\ b_m$
\item[] \textbf{Normal Denials}:\\ $\Leftarrow b_1, ... b_n, \text{not}\ b_{n+1}, ..., \text{not}\ b_m$
\end{itemize}

\paragraph{} The \textit{not} operator in Prolog is known as $\backslash+$. The computational meaning of $\text{not}\ p$ is: i) $\text{not}\ p$ succeeds iff $p$ fails finitely and ii) $\text{not}\ p$ fails iff $p$ succeeds. When evaluating $\Leftarrow \text{not} p(X)$, the atom $p$ must be ground: otherwise the derivation is "floundered"\footnote{The answer is unknown.}. The variable $X$ should have already been grounded in previous steps of the derivation.

\paragraph{} In Normal Clausal Logic, the fail operator never appears in the head of a rule. Putting the fail operator in the head of a rule would be asking to prove what should not be proved, whereas clausal theories define what should be provable.

\subsection{SLDNF Derivation}
\paragraph{} SLDNF derivation is SLD derivation with Negation as Failure. A selected subgoal $\text{not}\ p)$,  succeeds if the subproof fails, and it fails if the subproof succeeds. Consider the following example knowledge base and query $connected$:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] $connected \Leftarrow \text{not}\ unconnected$
\item[] $unconnected \Leftarrow node(X), \text{not}\ succ(X)$
\item[] $succ(X) \Leftarrow arc(X, Y)$
\item[] $node(a)$
\item[] $node(b)$
\item[] $arc(a, b)$
\item[] $arc(b, c)$
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sldnf-example1.png}
\caption{ In the example, we need to prove that $\Leftarrow unconnected$ fails in order to prove the second denial / sub-goal "$\Leftarrow \text{not}\ unconnected$". $\Leftarrow unconnected$ fails iff all all possible outcomes of $\Leftarrow unconnected$ comes to a failure / non-empty clause. The two possible outcomes, for $X = a \text{or} b$: $\Leftarrow \text{not}\ succ(X)$, are proven to to fail since each of $\Leftarrow succ(X)$ succeeds.}
\end{figure}

\paragraph{Floundering} If we make a slight modification to the knowledge base of the example by replacing $unconnected \Leftarrow node(X), \text{not}\ succ(X)$ with $unconnected \Leftarrow node(X), \text{not} arc(X, Y)$, the SLDNF would not be possible to evaluate even though the knowledge bases are equivalent. Figure \ref{fig:sldnf-example2} shows the resolution tree.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sldnf-example2.png}
\caption{With the slight modification, it becomes impossible to prove $\text{not}\ arc(X, Y)$ for $a$ and $b$ since $Y$ was not instantiated, as it would require a search through possibly infinite derivations to prove that there is exists no such value of $Y$. This is why the SLDNF strategy adopted is whenever a non-ground fail literal is encountered as a subgoal, the derivation consider it not possible to evaluate and a floundering condition is reported.}
\label{fig:sldnf-example2}
\end{figure}

\subsection{Abduction}

\paragraph{} So far reasoning has been primarily deductive. Sometimes our knowledge base can be incomplete and deductive inference would fail on certain queries due to lack of information. For example, given the following knowledge base and the query $soreElbow$:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] $soreElbow \Leftarrow tennisElbow$
\item[] $tennisPlayer \Leftarrow tennisElbow$
\item[] $soreElbow \Leftarrow soreJoints$
\item[] $soreJoint \Leftarrow arthritis, untreated$
\end{itemize}

\paragraph{} It is impossible to explain $soreElbow$ using deductive inference, as shown in Figure \ref{fig:abduction-example1} below.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/abduction-example1.png}
\caption{}
\label{fig:abduction-example1}
\end{figure}

\paragraph{} Abductive reasoning computes explanations that are consistent with the given knowledge base to explain (or satisfy) the given observations. The list of explanations can be generated and some may be subset of others. They should not be unnecessarily strong\footnote{i.e. including more ground literals than needed} or unnecessarily weak \footnote{too few to prove the observations in all circumstances}. Abductive algorithms for Normal clauses aim to generate a minimal set of explanations that, together with the given theory, proves the goal.

\paragraph{Abducibles} When modelling a problem domain in an abductive term, we need to think about a vocabulary of what are considered to be plausible explanations for the given types of observations - and we refer this vocabulary as the set of \textit{abducibles}.

\subsubsection{Abductive Model}

\paragraph{} An abductive model of a problem domain is defined as a tuple $<KB, Ab, IC>$ where $KB$ is the knowledge base (set of normal clauses), $Ab$ is the vocabulary of plausible explanations (set of ground undefined literals), and $IC$ is the set of constraints (set of normal details).

\paragraph{Abductive Solution} Given an abductive model, an \textit{abductive solution} (or explanation) of a given observation $O$ is a set $\Delta$ of ground literals st:

\begin{itemize}
\item $\Delta \subseteq Ab$: $\Delta$ belongs to a predefined language of abducibles.
\item $KB \cup \Delta \models O$: $\Delta$ must provide missing information needed to prove observation $O$.
\item $KB \cup \Delta \not\models \perp$: $\Delta$ must be consistent with the knowledge base.
\item $KB \cup \Delta \models IC$: $\Delta$ when combined with the knowledge base must entail the constraints.
\end{itemize}

\paragraph{} When $KB$ is a set of definite clauses, the augmented theory $KB \cup \Delta$ will also be a set of definite clauses that accepts a unique minimal model, the Least Herbrand Model.

\subsection{Abductive Proof Procedure}

\subsubsection{Abductive Phase}\label{sec:AbductiveProofProcedureAbductivePhase}

\paragraph{} Let $<KB, Ab, IC>$ be an abductive model expressed in Normal Clausal Logic and let $O$ be a ground observation. To start the procedure, we let $G_1 = O$ and $\Delta_0$ initially be $\emptyset$:

\paragraph{} Select a subgoal $L \in G_i$, then let $G_i' = G_i - \{L\}$:
\begin{itemize}
\item $L \not\in Ab$ and $L$ is a non-negative atom:\\ If $\exists [(H \Leftarrow B) \in KB]$ st $L = H\theta$,\\ then $G_{i+1} = B\theta \cup G_i$ and $\Delta_{k+1} = \Delta_k$
\item $L \in \Delta_i$: $G_{i+1} = G_i$ and $\Delta_{k+1} = \Delta_k$
\item $L \in Ab$ and $L \not\in \Delta_k$ and $(\text{not}\ L) \not\in \Delta_k$: $L$ can be assumed but needs to go through \textit{Consistency Phase} (Section \ref{sec:AbductiveProofProcedureConsistencyPhase}) to verify that assumption does not introduce inconsistency. If the consistency phase succeeds\footnote{Succeds with a failure in derivation.}, then $\Delta_{k+1} = \Delta_k \cup {L}$.
\end{itemize}

\subsubsection{Consistency Phase}\label{sec:AbductiveProofProcedureConsistencyPhase}

\paragraph{} To prove that an assumption $A$ does not introduce inconsistency, the Consistency Phase requires the derivation to finish with a failure.

\paragraph{} Let $F_1$ be the set of all denials in $IC$ that has been resolved with assumption $A$. Select a denial $\Leftarrow \phi$ in $F_1$ and a literal L from $\phi$.

\begin{itemize}
\item $L \not\in Ab$: Perform SLDNF failure with L as a subgoal.
\item $L \in \Delta_k$: $\phi' = \phi - \{L\}$ and consider the new constraint $\Leftarrow \phi'$\
\item $L \in Ab$ and $(\text{not}\ L) \in \Delta_k$, then continue consistency phase with the next denial in $F_1$ to check.
\item $L \in Ab$ and $L \not\in \Delta_k$ and $(\text{not}\ L) \not\in \Delta_k$: As the literal has to fail, we perform an abductive derivation of its negation to check for its success (i.e. we go back to Abductive Phase, Section \ref{sec:AbductiveProofProcedureAbductivePhase}, with the subgoal $\text{not} L$). 
\end{itemize}

\section{Inductive Logic Programming}

\paragraph{} ILP can be seen as a search problem. In \textit{concept learning} the task is to compute the definition of a concept, expressed in a given language (i.e. hypotheses space), that satisfies all examples labelled as \textbf{positive} and none of the examples labelled as \textbf{negative} in a given dataset.

\paragraph{} However, the question is: how do we make the search for hypotheses that covers relation and quality criterion computationally feasible? A naive approach would be to perform a generate-and-test, which would become very inefficient when the version space gets large.

\subsection{Learning as a Search}

\paragraph{} Given 

\begin{itemize}
\setlength\itemsep{0.1em}
\item $\mathcal{L}_e$: a set of observations where
	\begin{itemize}
	\item $E^+$ is the set of positive examples
	\item $E^-$ is the set of negative examples
	\end{itemize}
\item $B$: Background knowledge / clausal theory
\item $\mathcal{L}_h$: hypothesis language
\item $c(B, \mathcal{L}_h, e)$: coverage of $\mathcal{L}_h$ over the example $e$
\end{itemize}

\noindent We want to find a theory $H \in \mathcal{L}_h$ st

\begin{itemize}
\setlength\itemsep{0.1em}
\item $\forall e \in E^+: B \cup H \models e$: H is \textbf{complete}
\item $\forall e \in E^-: B \cup H \not\models e$: H is \textbf{consistent}
\end{itemize}

\paragraph{} Using the same concept as concept learning, we need to define a notion of \textit{generality relation} between first-order theories and be able to put clauses in general-to-specific order.

\subsection{Generality of Theories}

\paragraph{} Let $C$ and $D$ be two definite clauses. 

\begin{defn} $C$ is more general than $D$ (denoted $C \geq_g D$) iff $C \models D$. If $C \not\models e$, then $D \not\models e$. \end{defn}

\begin{defn} $C$ subsumes $D$ iff $\exists \theta$ st $C\theta \subseteq D$. If $C$ subsumes $D$, $C \models D$. \end{defn}

\paragraph{$\theta$-subsumption} Given two sets of clauses where $H_1 = \{C_1,... , C_n\}$ and $H_2 = \{D_0,... , D_m\}$, to show that $H_1$ $\theta$-subumes $H_2$, we need to show that $\forall D_i$ clause $\in H_2$, $\exists C_i$ clause $\in H_1$ that subsumes $D_i$.

\paragraph{} A clause $C$ can $\theta$-subsume itself as the $\theta$-substitution would be $\theta = \{\}$. If an hypothesis is consistent (i.e. does not cover any negative example) then any specialisation of this hypothesis will also be consistent. Similarly if an hypothesis is complete (i.e. covers every positive example), then every generalisation of this hypothesis will also be complete. Recall we aim to find hypotheses that are complete and consistent.

\subsection{Lattice of Clauses}

\paragraph{} ILP for definite clauses can be described by i) Structure of the hypothesis space based on generality relation and ii) Search strategy (or prune strategy) by $\theta$-subsumption. The subsumption relation over definite clauses defines a lattice structure. There are two types of traversal over the lattice of hypotheses: specialization (going down the lattice to find a more specific hypothesis) and generalization (going up the lattice to find a more general hypothesis). Hence, ILP learning programs for definite clauses have been classified into either \textit{top-down} or \textit{bottom-up} learners.

\subsection{General-to-Specific Traversal}

\paragraph{Shapiro Operator} is a refinement / specialisation operator. The basic idea is to start from a set of positive and negative examples of a new concept and compute a set of Horn clauses that correctly represent this concept by traversing a lattice (i.e. a special version space) of possible hypothesis by means of the Shapiro ($\rho$) operator. The key idea is to add a litteral in the body of the current clause or apply a substitution $\theta$.

\paragraph{} TODO: Here I miss out Specific to General Traversal: Plotkin's least general generalisation of two clauses and Muggleton's inverse resolution.

\subsection{Learning from Interpretation}

\paragraph{} In \textit{Learning from Interpretation}, the set of examples contain a full description nad all the information that belongs to the example is represented in the example, not in the background knowledge. The Background only contains general information concerning the domain, not concerning specific examples. Hence a definite clause theory $H$ is a solution iff $e \in E^+$ is a model of $H$ (i.e. $e \models H$).

\subsection{Learning from Entailment}

\paragraph{} Learning from entailment is a different paradigm. Given the examples $E = <E^+, E^->$, each $e \in E$ is a ground fact and $B$ is the background definite clause theory. We want to find hypothesis $H$ st means $\forall e \in E^+\ B \cup H_i \models e$ and $\forall e \in E^-\ B \cup H_i \not\models e$

\section{HAIL}

\subsection{Predicate Learning}

\paragraph{} Predicate learning is classified into two kinds:

\begin{itemize}
\item \textbf{Observation Predicate Learning (OPL)}: Hypothesis and examples define the same predicates. 
\item \textbf{Non-Observation Predicate Learning (NOPL)}: Hypothesis and examples define different predicates.
\end{itemize}

\paragraph{} Generally knowledge about problem domain is not complete and general principles may need to be learned in order to explain observed complex phenomena. Hence a NOPL would look for new general knowledge, used together with existing knowledge, to explain the observations. 

\subsection{Inverse Entailment}

\paragraph{} Consider the notion of Inverse Entailment\footnote{Introduced by Prof. Muggleton and first implemented in PROGOL}. It combines the advantages of both bottom-up\footnote{narrowing the search by starting from what is known already} and top-down\footnote{refining a general hypothesis to form a new one} searches. We observe that

\[ B \cup H \models E \equiv B \cup \lnot E \models \lnot H \]

\paragraph{} Note that since $H$ and $E$ are set of clauses, their variables are universally quantified. When negating clauses in these sets, the variables becomes existentially quantified - skolemised. 

\subsection{Bottom Set}

\paragraph{} Considering a positive example $e^+ \in E^+$, we can compute the (possibly infinite) set of ground literals that are derivable from (or entailed by) $B \land \lnot e^+$. These set of ground literals are considered as the negation of the Bottom Set, denoted $\lnot Bot(B, e^+)$. Let $h$ and $h$ to be single Horn clauses where

\begin{itemize}
\item $h \equiv l_1 \lor \lnot l_2 \lor ... \lor \lnot l_n$: Note that $l_1$ is the head of the clause.
\item $e^+ \equiv a_1 \lor \lnot a_2 \lor ... \lor \lnot a_m$: Note that $a_1$ is the head of the clause.
\end{itemize}

\paragraph{} We then have their negation with skolemisation:

\begin{itemize}
\item $\lnot h \equiv \lnot l_1 \land l_2\theta \land ... \land l_n\theta$: $\theta$ is a grounding by existential quantifier for $h$.
\item $\lnot e^+ \equiv \lnot a_1\delta \land a_2\delta \land ... \land a_m\delta$: $\delta$ is a grounding by existential quantifier for $h$.
\end{itemize}

\paragraph{} The Bottom set is then defined as:

$$Bot(B, e^+) = \{\lnot l_1\theta, \lnot l_2\theta, ..., \lnot l_n\theta\}$$

\paragraph{} The Bottom Set is the \textbf{most specific ground set of clauses} that is at the bottom of an hypothesis search space that explains the example $e^+$. Let $g(\lnot h_{\perp}) \subseteq \lnot Bot(B, e^+)$ and consequently $\lnot Bot(B, e^+) \models g(\lnot h_{\perp})$. Remember that all variables in the sets $g(\lnot h_{\perp})$ and $\lnot Bot(B, e^+)$ are existentially quantified. By contrapositive, we have $g(h_{\perp}) \models Bot(B, e^+)$. If we replace every constant in $g(h_{\perp})$ with a unique variable, we obtain a universally quantified clause $h_{\perp}$. This clause $h_{\perp}$ $\theta$-subsumes the Bottom Set (and hence $h_{\perp} \models Bot(B, e^+)$).

\paragraph{} $h_{\perp}$ corresponds to the \textbf{most specific unground hypothesis} at the bottom of the hypothesis search space (or lattice) that $\theta$-subsumes $Bot(B, e^+)$. 

\paragraph{} Computing the Bottom Set first allows for a more efficient search for hypotheses, as the search space can be limited to the sub-lattice space delimited by the $Bot(B, e^+)$ as the bottom-most element and the empty clause as the top element. Solutions will be clauses that $\theta$-subsume the Bottom Set $Bot(B, e^+)$.

\paragraph{} We can look at the Least Herbrand Model of the set of $B \cup {\lnot e^+}$ for the list of literals that can be entailed from $B \cup \{\lnot e^+\}$. Alternatively to prove that the set satisfy a clause $h$, we can also use proof by resolution to show that $B \land \lnot e^+ \land \lnot h \vdash_{res} [\ ]$.

\paragraph{Learning by Bottom Generalisation} Using the computed Bottom Set to generate the bottom clause $h_{\perp}$, the next step would be to compute a more generate clause that subsume these bottom set through top-down refinement. We say that an hypothesis $H$ is derivable from the bottom generalisation from $B$ and $e^+$ iff $H \geq_g Bot(B, e^+)$. 

\subsection{Inverse Entailment \& NOPL}

\paragraph{} By definition of Inverse Entailment and Bottom Generalisation, we only look for bottom definite clauses (i.e. the Bottom Set has to include at most one positive literal by definition of definite clauses). Learning by Bottom Generalisation is good for OPL if we assume a complete background knowledge. However, it would fail to compute hypothesis about predicates that are not directly observed. Consider background knowledge and the positive example $hasbeak(tweety)$:

\[
B = \begin{cases}
haspeak(X) \leftarrow bird(X)\\
bird(X) \leftarrow vulture(X)
\end{cases}
\]

\paragraph{} We work out the following steps according to Bottom Generalisation:

\begin{align*}
\lnot e^+ &= \lnot hasbeak(tweety)\\
B \land \lnot e^+ &= \{\\
& \lnot hasbeak(tweety)\\
& \land \lnot bird(tweety) \\
& \land \lnot vulture(tweety)\\
\}&\\
Bot(B, e^+) &= hasbeak(tweety)\\
& \lor bird(tweety)\\
& \lor vulture(tweety)\\
g(h_{\perp}) &= \{ hasbeak(tweety) \}\\
h_{\perp} &= \{ hasbeak(X) \}
\end{align*}

\subsection{Progol5}

\paragraph{} We observe that the hypothesis in the Learning program above we derive have predicates that are in the examples and does not learn new concepts. Since we want to explain the example in terms of other concepts, the background knowledge needs to provide the links. The key problem is how to compute information that is missing in the given background knowledge and use these new notions to generate new hypotheses. Prof. Muggleton proposed an extension of the Progol system that incorporates the notion of contrapositives used in FOL theorem proving\cite{muggleton00}.

\paragraph{} A clause with $n$ number of literals in its body is also equivalent to $n$ number of different clauses generated by contrapositive in the following way:

\begin{align*}
s &\leftarrow\\
p &\leftarrow q, r\\
&\leftarrow \lnot s\\
\lnot q &\leftarrow \lnot p, r\\
\lnot r &\leftarrow \lnot p, q\\
\end{align*}

\paragraph{} As it is invalid syntax for Prolog to have negated literals in the head of the rules, we can be creative by inventing new names that represent such negation, for example:

\begin{align*}
s &\leftarrow\\
p &\leftarrow q, r\\
&\leftarrow non\_s\\
non\_q &\leftarrow non\_p, r\\
non\_r &\leftarrow non\_p, q\\
\end{align*}

\paragraph{} Now the background knowledge includes their equivalent contrapositive clauses.

\subsection{Language Bias}

\paragraph{} Sometimes we would like to define the language of the hypothesis by using a language bias. It is composed of a set of \textbf{mode declarations}.

\[
\text{Mode declarations: }
\begin{cases}
	modeh(r, s)\\
	modeb(r, s)
\end{cases}
\]

\paragraph{modeh} indicates the predicate may appear as head predicate of the rules to learn.
\paragraph{modeb} indicates the predicate may appear as body predicate of the rules to learn.
\paragraph{r} represents a recall, an integer that indicates how many times the predicate may appear in a rule. '*' indicates that the predicate may appear any number of times in a rule.
\paragraph{s} is the scheme, which is a ground atom with the predicate's name, placemarkers $+t$ (input variable), $-t$ (output variable) and $\#t$ (constants) for unary type $t$. 

\paragraph{Example} For example consider the following mode declarations:

\begin{align*}
	&\text{modeh}(1, \text{grandfather}(+\text{person}, +\text{person}))\\
	&\text{modeb}(1, \text{father}(+\text{person}, -\text{person}))\\
	&\text{modeb}(1, \text{parent}(+\text{person}, +\text{person}))
\end{align*}

We can build a rule $grandfather(X, Y) \leftarrow father(X, Z), parent(Z, Y)$.

\subsection{Kernel Set}

\paragraph{} The notion of the BottomSet $Bot(B, e)$ can be generalised into a new notion called \textbf{Kernel Set}. The creation of Kernel Set uses a full abductive reasoning procedure that replaces the StartSet procedure used to derive $Bot(B, e)$. 

{\footnotesize
\begin{align*}
& Kernel(B, E) \\
&= \{a | a \in \Delta \land B \cup \Delta \models e\} \cup \{\lnot b_i | B \cup \{\lnot e\} \models b_i\} \\
&= \bigwedge \{b_i | B \cup \{\lnot e\} \models b_i\} \rightarrow \bigvee \{a | a \in \Delta \land B \cup \Delta \models e\} \models b_i\}
\end{align*}}

\paragraph{} Note from above that the body literals are still generated the same way as it did by Progol5, i.e. $B \cup \{\lnot e\} \models b$. From the Kernel Set (that is ground), we then construct the Kernel Set hypothesis (that is ungrounded) given by

\[ 
K = \begin{cases}
a_1 \leftarrow b_{11}, b_{21}, ..., b_{n1}\\
a_2 \leftarrow b_{12}, b_{22}, ..., b_{m2}\\
...\\
a_k \leftarrow b_{1k}, b_{2k}, ..., b_{hk}
\end{cases}
\]

\subsection{Hybrid Abductive Inductive Learning}

TODO: complete HAIL algorithm

\paragraph{} We have background knowledge $B$, positive examples $E^+$, negative examples $E^-$ and mocdel $M$. 
\begin{enumerate}
\item Abductive Step (replace STARTSET): What are the abducibles?
\item Deductive Step
\item Induction Step
\end{enumerate}

Kernel is the set of clauses . Generalisation shrinks the Kernel set. Head of clauses are from the abduction proof. In Induction Step can I find a $H$ that $\theta$-subsumes $K$ in the $\theta$-lattice. Generalization increases positive-example coverage but we must check that it does not cover any negative examples.

\section{Top-directed Abductive Learning}

TODO: write TAL section

\section{Stable Model Semantics}

\subsection{Definitions}

\paragraph{} A Normal Logic Program is set of rules / clauses, where each rule $R$ is in the form

\begin{lstlisting}
h :- b1, ..., bn, not c1, ..., not cm.
\end{lstlisting}

\noindent ... where $h$, $b_i$ and $c_i$ are all atoms. We define 

\begin{itemize}
\item $head(R) = h$
\item $body^+(R) = \{ b_1, ..., b_n \}$
\item $body^-(R) = \{ c_1, ..., c_m \}$
\end{itemize}

\paragraph{} For convenience, I define $body(R) = body^+(R) \cup body^-(R)$ to be the set of all atoms in the body of the clause.

\subsection{Prolog and Negation}

\paragraph{} Consider the following program:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} What should Prolog return if queried "$p$"? While Prolog will loop infinitely, there are in fact multiple answers to the query. The value of p depends on q and the value of q depends on p. The stable model semantics\cite{gelfond88} is a different approach to solving normal logic programs. Instead of providing solutions to specific queries, the stable model semantics defines the set of "stable" models of the program. we will see that the example program above has the stable models $\{p\}$ and $\{q\}$.

\subsection{Grounding}

\paragraph{} The solving any normal logic program is to first ground the logic program. For any program $P$ with function symbols, there are infinitely many ground instances of each rule in $P$ (consider function symbol compositions and there can be infinitely many different compositions). We write $ground(P)$ to refer to the grounding of logic program $P$.

\paragraph{} Most of these grounding instances of each rule may be redundant instances whose bodies could never be satisfied. ASP solvers do not generate these redundant rules.

\subsection{Safety}

\paragraph{} In Prolog, floundering (see section \ref{sec:NormalClausalLogic}) is a problem because negative literals may contain a variable which is only ground by a positive literal occurring later in the body of the rule. Recall that in Prolog, rule evaluation is ordered top to bottom and left to right. For example, the following logic program flounders in Prolog as $X$ and $Y$ only gets instantiated in $r(X, Y)$, which happens after $not\ q(X, Y)$:

\begin{lstlisting}
p(X) :- not q(X, Y), r(X, Y).
r(a, b).
\end{lstlisting}

\paragraph{} ASP does not consider the ordering of the literals in a rule and hence safety is less of a problem in ASP.  However, ASP needs to ground the entire program and another form of safety is needed. ASP Solvers are restricted to working with "safe" rules only.

\begin{defn}\label{defn:SafeRule}
A rule $R$ is safe, if every variable in $R$ occurs in at least one atom in $body^+(R)$. 
\end{defn}

\paragraph{} Considering Definition \ref{defn:SafeRule}, take a look at the following examples:

\begin{itemize}
\item \lstinline{p(Z) :- not q(X, Y), r(X, Y).} - This rule is unsafe because the variable $Z$ does not occur in any of the atoms in $body^+(R)$.
\item \lstinline{p(X) :- not q(X, Y), r(X, Y).} - This rule is safe.
\item \lstinline{p(Y) :- not q(X, Y), r(Y, Y).} - This rule is unsafe because the variable $X$ does not occur in any of the atoms in $body^+(R)$.
\end{itemize}

\paragraph{} Nonetheless, in ASP even when we restrict to safe rules, for some logic program $P$, $ground(P)$ can still be infinite. For example:

\begin{lstlisting}
p(f(X)) :- p(X).
p(1).
\end{lstlisting}

\subsection{Herbrand Theory}

\subsubsection{Definite Logic Programs}

\paragraph{} For a \textbf{definite logic program} $P$, a Herbrand Interpretation $I$ of $P$ is an Herbrand Model if for all rule $R$ st

\begin{itemize}
\item each atom in $body^+(R)$ is true in $I$
\item each atom in $body^-(R)$ is false in $I$
\item $head(R)$ is true in $I$
\end{itemize}

\paragraph{} We can construct the Least Herbrand Model for a definite logic program $P$, denoted $M(P)$ by starting with the empty set $M = {}$. We then repeatedly add any atom $h$ to $M$M st $h$ is the head of a rule $R$ whose body is a subset of $M$, i.e. we add $head(R)$ to $M$ if $body(R) \subseteq M$. \textit{For definite programs with no loops, this is the same as what is provable using Prolog.}

\subsubsection{Normal Logic Programs}

\paragraph{} However when it comes to \textbf{normal logic programs}, generally there is no Least Herbrand Model. Consider the following example:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} The set of Herbrand Interpretations is $\{\emptyset, \{p\}, \{q\}, \{p ,q\}\}$.

\begin{itemize}
\item In the case of $HI = \emptyset$, it does not satisfy the program since both $not\ p$ and $not\ q$ are satisfied but their heads $q$ and $p$ respectively are not satisfied. 
\item In the case of $HI = \{p\}$, it satisfies the the program and is a Herbrand model of the program.
\item In the case of $HI = \{q\}$, it satisfies the the program and is a Herbrand model of the program.
\item In the case of $HI = \{p, q\}$, it satisfies the the program and is a Herbrand model of the program. However because the earlier two HIs are subsets of this HI, this is not a minimal Herbrand Model.
\end{itemize}

\paragraph{} Hence, instead of having just one Least Herbrand Model, the program has both $\{p\}$ and $\{q\}$ as two Minimal Herbrand Models of the program.

\subsubsection{Supportability}

\paragraph{} Consider the program: \lstinline{p :- not p.}

\paragraph{} The program has the set of Herbrand Interpretations: $\{\emptyset, \{p\}\}$. The $\emptyset$ HI does not satisfy the program while $\{p\}$ does, which makes it the Least Herbrand Model. However, the LHM $\{p\}$ is unsupported because $p$ has no support: it is not a head of any clauses in the program whose body is true in the Herbrand Model. In fact, there are no stable models of this program.

\begin{defn}A Herbrand Model $M(P)$ for a normal logic program $P$ is supported iff every atom $a \in M(P)$ is the head of a clause in $P$ those body $body(R)$ is also true in $M(P)$, i.e. $body(R) \subseteq M(P)$. \end{defn}

\subsection{Reduct}

\begin{defn}The \textbf{reduct} of any ground normal logic program $P$, i.e. $ground(P)$, with respect to any set of atoms $X$ is constructed in two steps:\end{defn}

\begin{enumerate}
\item Remove any rule from $P$ whose body contains negation as failure of an atom in $X$. i.e. we remove rule $R$ from $P$ where $a \in X: not\ a \in body(R)$.
\item Remove any negation as failure atoms from the remaining rules in $P$.
\end{enumerate}

\paragraph{} The remaining logic program is the reduct of $P$ with respect to $X$, written $P^X$. Suppose $X = \{p\}$ and $P$ is the logic program:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} The result $P^X$ would be $\{p\}$. This process can be thought as making a guess to see if an interpretation $X$ may be an Answer Set, then assuming the Answer Set to be true while interpreting negation as failure in the program. If a logic program contains variables, the program needs to be grounded first before we can find the reduct. We represent the reduct of the ground of program $P$ with respect to $X$ as $ground(P)^X$.

\subsection{Stable Model}

\begin{defn}An interpretation $X$ is a \textbf{stable model} of a normal logic program $P$ iff $X$ is the Least Herbrand Model of $ground(P)^X$, i.e. $X \equiv M(ground(P)^X)$.\end{defn}

\paragraph{} Consider the following logic program and an interpretation $X = \{p\}$:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} Since $P^X = M(P^X) = \{p\} = X$, $X$ is a stable model of $P$. Likewise if we take the interpretation $X = \{q\}$, we will find that $\{q\}$ is also a stable model of $P$. This means that different interpretations may result in different reducts for the same logic program.

\begin{defn}An \textit{Answer Set} is a stable model of normal logic program.\end{defn}

\subsection{Answer Set Programming}

\paragraph{} The Answer Set Programming paradigm is to translate the problem we want to solve into an Answer Set program st when we solve the program for Answer Sets, these Answer Sets can be translated back as solutions to the original problem. For example, we translate the rules of the Sudoku game into an ASP representation of the game. We then are able to find the Answer Sets, which can be then mapped back as solutions of the game itself.

\section{Extended Constructs in ASP}\label{sec:ASPExtendedConstructs}

\subsection{Constraints}

\paragraph{} Constraints are a way of filtering any unwanted Answer Sets. They are written as normal clauses with an empty head, e.g. \lstinline{:- b1, ..., bn, not c1, ..., not cm}. The empty head represents falsity $\perp$. When we compute the reduct of such program, rules with empty head will have their heads are replaced with $\perp$. 

\paragraph{} $\perp$ can never be in an Answer Set. Hence any interpretations that satisfy the body of a constraint would end up having $\perp$ in the result, which eliminates the interpretation as an Answer Set. For example:

\begin{lstlisting}
p :- not q.
q :- not p.
:- p, not q.
\end{lstlisting}

\paragraph{} The constraint in the above program eliminates the interpretation $X = \{p\}$ as an answer set. In other words, an Answer Set does not satisfy the body of all constraints in a logic program.

\subsection{Choice Rules}\label{sec:ASPChoiceRules}

\begin{defn}A \textbf{choice rule} is a rule in an ASP program where a \textit{counting aggregate} is allowed to appear in the head of a rule.\end{defn}

\paragraph{} A counting aggregate $a\ \{ h_1, h_2, ..., h_n \}\ b$ is satisfied by an interpretation $X$ if $$a \leq |\{h_1, h_2, ..., h_n \} \cap X| \leq b$$

\paragraph{} For example, the rule 

\begin{lstlisting}
1 {value(C, h), value(C, t)} 1 :- coin(C).
\end{lstlisting}

expresses that every coin $C$ must either take the value "h" or "t" (but not both, since $b = 1$).

\paragraph{Semantics} We compute the Answer Sets of a logic program $P$ containing choice rules by inserting an additional step into the computation process of reduct $P^X$. For each rule $R$ that is a choice rule:

\begin{enumerate}
\item If the aggregate is not satisfied by $X$, we convert $R$ into a constraint by replacing the head with $\perp$.
\item If the aggregate is satisifed by $X$, we generate one rule for each atom $A$ in the aggregate which is also in $X$, with $A$ at the head.
\end{enumerate}

\paragraph{} For example, consider the following program $P$ with the interpretation $X = \{p, q, r\}$:

\begin{lstlisting}
1 {p, q} 1 :- r.
r.
\end{lstlisting}

\paragraph{} Since $| \{ p, q \} \cup X | \geq 1$, we compute the reduct $P^X$ of the program by replacing the head with $\perp$:

\begin{lstlisting}[mathescape=true]
$\perp$ :- r.
r.
\end{lstlisting}

\paragraph{} Alternatively, we consider the slightly modified program $P'$ below with the same interpretation $X = \{p, q, r\}$:

\begin{lstlisting}
1 {p, q} 2 :- r.
r.
\end{lstlisting}

\paragraph{} Now that $| \{ p, q \} \cup X | = 2$, we can compute the reduct $P^X$ of the program to be as such:

\begin{lstlisting}
p :- r.
q :- r.
r.
\end{lstlisting}

\subsection{Optimisation Statements}

\paragraph{} It is possible set up an ASP program to give an ordering over Answer Sets to specify which Answer Sets are preferred over others. Finding optimal Answer Sets of a ASP program can be done by adding optimisation statements like this:

\begin{lstlisting}[mathescape=true]
#minimize [ $a_1$ = $w_1$, ..., $a_n$ = $w_n$ ].
\end{lstlisting}

\paragraph{} The above statement\footnote{Note the Non-British spelling of minimise.} assigns weights $w_i$ to its corresponding literal $a_i$. The weight of each Answer Set is summed from the weights assigned to each atom in the Answer Set. In the statement above, the optimal Answer Set has the lowest weight. It is also possible to find Answer Sets that has the greatest weight by using \#maximize instead:

\begin{lstlisting}[mathescape=true]
#maximize [ $a_1$ = $w_1$, ..., $a_n$ = $w_n$ ].
\end{lstlisting}

\section{Brave and Cautious Entailment}

\subsection{Induction for Definite Programs}

\paragraph{} For a definite program $P$, since there is always a unique LHM (written $M(P)$), entailment is defined in terms of this LHM. The task of ILP is therefore to find a hypothesis $H$ st $M(B \cup H)$ contains all of a set of positive examples and none of a set of negative examples. There are two different kind of entailments: \textit{brave} and \textit{cautious}. 

\subsection{Brave Induction}
\paragraph{} An atom $A$ is bravely entailed by a program $P$ if it is true in \textbf{at least one stable model} of $P$ (written $P \models_b A$).

\paragraph{} Based on the semantics of brave entailment, we can construct the concept of Brave Induction  \cite{sakama08}. Given a Brave ILP (denoted $\text{ILP}_\text{B}$) task as the tuple $<B, E^+, E^->$, we want to search for a hypothesis $H$ st $B \cup H$ has \textbf{at least one Answer Set} which contains all of the positive examples and none of the negative examples i.e. $\exists A$ of $B \cup H$ st $\forall e^+ \in E^+: e^+ \in A$ and $\forall e^- \in E^-: e^- \not\in A$. We can also write it as:

$$B \cup H \models_b (e_1^+ \land ... \land e_n^+ \land \text{not}\ e_1^- \land ...  \land \text{not}\ e_m^-)$$

\subsection{Limitations of Brave Induction}\label{sec:BraveInductionLimitations}

\paragraph{} Some hypotheses cannot be learned from using Brave Induction alone. For example, brave induction cannot be used to learn any hypothesis which only rules out Answer Sets and does not generate anything new.

\paragraph{} In particular, a brave ILP task will never have, as an optimal solution, a hypothesis containing a constraint. If the hypothesis is a solution for the brave ILP task, it must have at least one Answer Set that contains all of the positive examples and none of the negative examples. As constraints only rule out Answer Sets, this Answer Sets will still be an Answer Set of the program without the constraint.

\subsection{Cautious Induction}
\paragraph{} An atom $A$ is cautiously entailed by a program $P$ if it is true in \textbf{all stable models} of $P$ (written $P \models_c A$).

\paragraph{} Based on the semantics of cautious entailment, we can construct the concept of Cautious Induction  \cite{sakama08}. Given a Cautious ILP (denoted $\text{ILP}_\text{C}$) task as the tuple $<B, E^+, E^->$, we want to search for a hypothesis $H$ st $B \cup H$ has at least one Answer Set and \textbf{all of its Answer Sets} contain all of the positive examples and none of the negative examples i.e. $\forall A$ of $B \cup H$ st $\forall e^+ \in E^+: e^+ \in A$ and $\forall e^- \in E^-: e^- \not\in A$. We can also write it as:

$$B \cup H \models_c (e_1^+ \land ... \land e_n^+ \land \text{not}\ e_1^- \land ...  \land \text{not}\ e_m^-)$$

\subsection{Limitations of Cautious Induction}

\paragraph{} Consider an empty background knowledge $B$, we cannot construct a set of examples st any of the shortest hypotheses are:

\begin{lstlisting}
1 {value(C, h), value(C, t)} 1 :- coin(C).
coin(c1).
\end{lstlisting}

\paragraph{} The only atom that is true in all Answer Sets of the program that we are trying to learn would be $coin(c1)$. Neither atoms $value(c1, heads)$ nor $value(c1, tails)$ is false in all Answer Sets. Hence this would cause us to learn only $coin(c1)$. This is not what we are aiing for as we want to learn a program with two distinct Answer Sets, which corresponds to the coin $c1$ being $heads$ or $tails$. Cautious entailment of all examples in such a case may be a requirement that is too strong. Hence, in such situation, a Brave ILP learning task would be able to give what is true in some Answer Sets but not all Answer Sets of the learned program.

\section{ASP Abductive Learning}

\paragraph{} Using ASP, we can perform abductive learning (hence ASPAL) by using the extended constructs in ASP as described in Section \ref{sec:ASPExtendedConstructs}. 

\subsection{Skeleton Rules}

\paragraph{} A skeleton rule for the mode declaration $<M_h, M_b>$ is a compatible rule where all constant placemarkers are replaced with different variables instead of constants. For example, consider the following mode declarations:

\begin{lstlisting}
modeh(1, penguin(+bird)).
modeb(2, not can(+bird, #ability)).

bird(a).
bird(b).
ability(fly).
ability(swim).
can(a, fly).
can(b, swim).
\end{lstlisting}

\paragraph{} For every variable, ASPAL will add the type of the variable to the body of the rule. In he case of $penguin(+bird)$, $bird(V1)$ is added to the body of the rule. This enforces that the rules only apply to terms of these types and will also mean that ASPAP would not need to worry about the safety of the rules. All variables will certainly appear in at least one positive literal in the body of the rule. The rule  \lstinline{penguin(V1) :- bird(V1), not can(V1, C1).} represents:

\begin{lstlisting}
penguin(V1) :- bird(V1), not can(V1, fly).
penguin(V1) :- bird(V1), not can(V1, swim).
\end{lstlisting}

\paragraph{} By using skeleton rules where the constant symbols are not yet ground, ASPAL leaves the task of finding the grounding to the ASP solver. Each skeleton rule represents a set of rules where the constant-representative variables have been replaced with constants of the correct type.

\subsection{Limits}

To limit the the hypothesis search space, we introduce two constraints in addition to the given mode declarations: $L_\text{max}$ specifies the number of literals allowed to appear in the body of the rule and $V_\text{max}$ specifies the number of unique variables allowed in the rule.

\paragraph{} ASPAL constructs a set of skeleton rules $S_M$ - we call this set the hypothesis space. $S_M$ is maximal given language constraints $<M_h, M_b>, L_\text{max}, V_\text{max}$ if any rule which can be constructed respecting the constraints is equivalent to a rule already in $S_M$. We need to maximize this hypothesis space because we want to include all possible rules allowed by the language constraints, before we later prune off inconsistent instances of the skeleton rules later using a choice rule.

\subsection{Hypothesis Space}\label{sec:ASPALHypothesisSpace}

\paragraph{} Given the following background knowledge $B$:

\begin{lstlisting}
bird(a).
bird(b).
ability(fly).
ability(swim).
can(a, fly).
can(b, swim).
\end{lstlisting}

\paragraph{} and given the following set of skeleton rules $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1).
penguin(V1) :- bird(V1), not can(V1, C1).
penguin(V1) :- bird(V1), not can(V1, C1), not can (V2, C2).
\end{lstlisting}

\paragraph{} The following is the list of all possible rules that are represented by $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1).
penguin(V1) :- bird(V1), not can(V1, fly).
penguin(V1) :- bird(V1), not can(V1, swim).
penguin(V1) :- bird(V1), not can(V1, fly), not can(V1, swim).
\end{lstlisting}

\subsection{ASP Encoding}

\subsubsection{Rule Encoding}

\paragraph{} ASPAL encodes an ILP task as a meta level ASP program. The Answer Sets would contain atoms that represent each of the rules in the hypothesis. To help us map the Answer Set of the meta level program back to an inductive solution of the ILP task, we assign a unique rule identifier $R_\text{ID}$ to each skeleton rule in $S_M$. The atom $rule(R_\text{ID}, c_1, ..., c_n)$ represents the skeleton rule $R$ with each constant variables replaced with constants $c_1, ..., c_n$.

\paragraph{} We can then use the choice rule (See Section \ref{sec:ASPChoiceRules}) on the set of rules and the combination of constants to let the ASP solver help us find the solutions to the ILP task.

\paragraph{} Considering the penguin example in Section \ref{sec:ASPALHypothesisSpace}, we can add the rule atom to each of the rules in $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1), rule(1).
penguin(V1) :- bird(V1), not can(V1, C1), rule(2, C1).
penguin(V1) :- bird(V1), not can(V1, C1), not can (V2, C2), rule(3, C1, C2).
\end{lstlisting}

\paragraph{} The choice rule below causes one Answer Set to be generated for each set of rules (i.e. each hypothesis):

\begin{lstlisting}
{ rule(1), rule(2, fly), rule(2, swim), rule(3, fly, swim) }.
\end{lstlisting}

\paragraph{} The rule atoms that appear in the Answer Sets represent the hypothesis. 

\subsubsection{Example Encoding}

\paragraph{} To rule out any Answer Set of the meta program which corresponds to an Answer Set of $B \cup H$ which either 1) does not contain all of the positive examples or 2) contains one or more negative examples, we add the goal rule and its constraint to the program:

\begin{lstlisting}
goal :- e1+, ..., en+, e1-, ..., em-.
:- not goal.
\end{lstlisting}

\paragraph{} The result of this is that Answer Sets of the meta program will correspond exactly to the inductive solutions of the ILP task. 

\subsection{Optimization}

\paragraph{} ASLAP uses an optimisation statement st the optimal Answer Sets of the meta level program will correspond exactly to the optimally inductive solutions of the task. We can do this using the \lstinline{#minimize} statement in ASP (See Section \ref{sec:ASPExtendedConstructs}) and by weighing each of the rules by its length:

\begin{lstlisting}
#minimize[rule(1, c1, ..., cn) = Rlen, ...].
\end{lstlisting}

\paragraph{} We define the length of the rule to be the number of literals in the rule (including the head) excluding type enforcement literals.

\section{Learning from Answer Sets}

\paragraph{} Many other applications can be solved with brave induction alone. However as shown in the limitations of Brave Induction in Section \ref{sec:BraveInductionLimitations}, there are programs which cannot be learned with solvely brave or cautious induction. One such problem is to learn the rules of sudoku. Learning from Answer Sets (LAS) can be used to learn such programs\cite{law14}.

\subsection{Partial Interpretation}

\paragraph{} A partial interpretation $e$ is a pair of sets of atoms $\langle e^\text{inc}, e^\text{exc}\rangle $. $e^\text{inc}$ is the set of \textit{inclusions} and $e^\text{exc}$ is the set of \textit{exclusions}.

\paragraph{} A Herbrand Interpretation $I$ extends a partial interpretation $e$ iff $e^\text{inc} \subseteq I$ and $e^\text{exc} \cap I = \emptyset$.

\paragraph{} For example: sets $\{p, q\}$ and $\{p, q, s\}$ extend $\langle \{p, q\}, \{r\} \rangle$ but not neither $\{p\}$ nor $\{p, q, r\}$ do. In LAS, examples are covered if there exists an Answer Set of $B \cup H$ which extends the example (as a partial interpretation).

\subsection{Learning}

\paragraph{} A LAS task is a tuple $\langle B, S_M, E^+, E^- \rangle$. Unlike ASPAL and similar systems, as LAS is aimed at learning ASP rather than Prolog, LAS has no concept of input and output variables. The only restriction is that the rules in $S_M$ are safe. 

\paragraph{} A hypothesis $H$ is an inductive solution, written $H \in \text{ILP}_\text{LAS}\langle B, S_M, B^+, B^- \rangle$, iff it is constructed from the rules in $S_M$ (i.e. $H \subseteq S_M$) and each positive example is extended by at least one Answer Set of $B \cup H$ (this can be different Answer Set for each positive example) and none of the negative examples are extended by any Answer Set of $B \cup H$. Formally,

\begin{itemize}
\item $\forall e \in E^+: \exists A \in AS(B \cup H)\ \text{st}\ A\ \text{extends}\ e$
\item $\forall e \in E^-: \forall A \in AS(B \cup H)\ \text{st}\ \lnot(A\ \text{extends}\ e)$
\end{itemize}

\paragraph{} Consider the following $\text{ILP}_\text{LAS}$ task. Given the background knowledge $B$:

\begin{lstlisting}
coin(C) :- biased_coin(C).
biased_coin(c1).
coin(c2).
\end{lstlisting}

\paragraph{} and given the following positive examples:

\begin{lstlisting}
<{value(c1, tails), value(c2, heads)}, {}>
\end{lstlisting}

\paragraph{} and given the following negative examples:

\begin{lstlisting}
<{}, {value(c2, heads), value(c2, tails)}>
<{value(c2, heads), value(c2, tails)}, {}>
<{}, {value(c1, tails)}>
\end{lstlisting}

\paragraph{} The positive example says that there must be at least one Answer Set of $B \cup H$ that contains both \lstinline{value(c1, tails)} and \lstinline{value(c2, heads)}. This example on its own is satisfied by the choice rule 

\begin{lstlisting}
1 { value(C, heads), value(C, tails) } 1 :- coin(C).
\end{lstlisting}

\paragraph{} in the hypothesis $H$. However, we can also allow hypotheses which place less restrictive bounds on the aggregate, for example:

\begin{lstlisting}
0 { value(C, heads), value(C, tails) } 2 :- coin(C).
\end{lstlisting}

\paragraph{} Nonetheless if we look at the negative examples, we realise hypotheses that as less restrictive bounds on the aggregate would cover some of the negative examples. The first negative example, says that no Answer Set is allowed to contain neither of \lstinline{value(c2, tails)} and \lstinline{value(c2, heads)} and the second negative example says that no answer is allowed to contain both of them. 

\paragraph{} The third negative example says that no Answer Set is allowed to not contain \lstinline{value(c1, tails)}. One way of ensuring this is to add the constraint

\begin{lstlisting}
:- value(C, heads), biased_coin(C).
\end{lstlisting}

\subsection{Relation to Brave Induction}

\paragraph{} A Brave ILP Task $\text{ILP}_b\langle B, E^+, E^-\rangle$ is satisfied by a hypothesis $H$ iff there is at least one Answer Set of $B \cup H$ which includes all of the positive examples $E^+$ and none of the negative examples $E^-$.

\paragraph{} This is equivalent to there being an Answer Set of $B \cup H$ which extends the partial interpretation $\langle E^+, E^-\rangle$, which is in turn equivalent to $H$ being an inductive solution of a LAS task $\text{ILP}_\text{LAS} \langle B, \{\langle E^+, E^- \rangle\}, \emptyset\rangle$ with a single positive example $\langle E^+, E^-\rangle$.

\subsection{Relation to Cautious Induction}

\paragraph{} A Cautious ILP task $\text{ILP}_c\langle B, E^+, E^-\rangle$ is satisfied by a hypothesis $H$ iff $B \cup H$ has at least one Answer Set and every Answer Set of $B \cup H$ includes all of the positive examples $E^+$ and none of the negative examples $E^-$.

\paragraph{} This is equivalent to there being no Answer Set of $B \cup H$ which contains any negative example and for each positive example, no Answer Set of $B \cup H$ which does not contain that example.

\paragraph{} It can also the same as $B \cup H$ having no Answer Set which extends any of the partial interpretations $\langle \emptyset, e^+_1\rangle, ..., \langle \emptyset, e^+_n\rangle, \langle e^-_1, \emptyset\rangle, ..., \langle e^-_m, \emptyset\rangle$ and having at least one Answer Set which extends $\langle \emptyset, \emptyset \rangle$. This is equivalent to $H$ being an inductive solution of a LAS task:

$$\text{ILP}_\text{LAS} \langle B, \{\langle \emptyset, \emptyset \rangle\}, \{\langle \emptyset, e^+_1\rangle, ..., \langle \emptyset, e^+_n\rangle, \langle e^-_1, \emptyset\rangle, ..., \langle e^-_m, \emptyset\rangle\}\rangle$$

\end{multicols}

\bibliographystyle{plain}
\bibliography{references}

\end{document}