\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{dirtytalk}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[nodayofweek]{datetime}
\longdate
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{amsthm}
\usepackage{comment}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{float}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition} % definition numbers are dependent on theorem numbers
\newtheorem{exmp}[thm]{Example} % same for example numbers

\setlength\columnsep{30pt}

\geometry{
 	a4paper,
	total={170mm,257mm},
 	left=20mm,
 	top=20mm,
}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\title{
	 \huge 304: Logic-Based Learning\\
	 \huge -- Reference --
}
\date{\today}
\author{
	Sam Yong \\
	\small \href{mailto:sam.yong17@imperial.ac.uk}{sam.yong17@imperial.ac.uk}
}


\begin{document}
\maketitle

\begin{multicols}{2}

\paragraph{} NOTICE: This set of reference is currently incomplete with respect to the syllabus of the course and will be updated as the semester progress. By end Mar 2018 it should be complete.

\section*{Foreword}  

\paragraph{} This reference was made as an condensation from the lecture slides and notes provided by Prof. Alessandra Russo, Prof. Stephen Muggleton and Mark Law in the Imperial College London, Department of Computing's 304: Logic-Based Learning.

\paragraph{} The ordering of this reference may not correspond to the sequence introduced in the lectures, lecture slides and notes. This order is how I feel I would understand the topic better.

\begin{footnotesize}
\paragraph{License} This reference is made publicly available under the MIT License. You should not have paid anyone money in exchange for this document. If you have paid someone for it, well too bad. The source code for this document can be found public available on my Github repository\footnote{\href{https://github.com/mauris/written}{https://github.com/mauris/written}}. If you wish to help improve this document, feel free to open an issue on the Github repository.
\end{footnotesize}

\newpage
\tableofcontents
\newpage

\section{Background}
\subsection{Forms of Reasoning}

\paragraph{Deduction} Reasoning from the general to reach the particular: what follow necessarily from the given premises.

\begin{itemize}
\item \textbf{Rule}: All beans in this bag are white.
\item \textbf{Case}: These beans are from this bag.
\item \textbf{Result}: These beans are white.
\end{itemize}

\paragraph{Induction} Reasoning from the specifics to reach the general: process of deriving reliable generalisations from observations.

\begin{itemize}
\item \textbf{Rule}: These beans are from this bag.
\item \textbf{Case}: These beans are white.
\item \textbf{Result}: All beans in this bag are white.
\end{itemize}

\paragraph{Abduction} Reasoning from observations to explanations: process of using given general rules to establish causal relationships between existing knowledge and observations. 

\begin{itemize}
\item \textbf{Rule}: All beans in this bag are white.
\item \textbf{Case}: These beans are white.
\item \textbf{Result}: These beans are from this bag.
\end{itemize}

\subsection{Clausal Representation}
\subsubsection{Propositional Logic}
\paragraph{} We begin by introducing the clausal representation with the following definitions:

\begin{itemize}
\item \textbf{Theory}: a set (conjunction) of clauses\footnote{Clausal finite theories can also be seen as Conjunctive Normal Form (CNF) formulae.}.\\ e,g, $\{p \lor \lnot q; r; s\}$
\item \textbf{Clause}: disjunction of literals.\\ e.g. $p \lor \lnot q$, $r$, $s$
\item \textbf{Literal}: Atomic sentence or its negation.\\ e.g. $p$, $\lnot q$
\end{itemize}

\paragraph{} As we want to explore how inference tasks can be computed, we will restrict ourselves to the subset of predicate logic that is computational tractable and where efficient automated proof procedures that are able to compute logical inference exists. This subset of predicate logic is called Horn clauses\footnote{A subset of Prolog language.}. Every formula can be converted into a clausal theory:

\begin{itemize}
\item Elimination of $\implies$:\\ $(p \implies q) \longrightarrow \lnot p \lor q$
\item Pushing $\lnot$ inwards:\\ $\lnot(p \lor q) \longrightarrow (\lnot p \land \lnot q)$
\item Distribution of $\land$ and $\lor$:\\ $(\lnot p \land \lnot q) \lor \lnot p \longrightarrow (\lnot p \lor \lnot p) \land (\lnot q \lor \lnot p)$
\item Collecting Terms:\\ $(\lnot p \lor \lnot p) \land (\lnot q \lor \lnot p) \longrightarrow \lnot p \land (\lnot q \lor \lnot p)$
\end{itemize}

\subsubsection{Predicate Logic}

\paragraph {} In the case of predicate logic, atomic sentences may have terms with variables:

\begin{itemize}
\item \textbf{Theory}: a set (conjunction) of clauses.\\ e.g. $\{p(X) \lor \lnot r(a, f(b, X)); q(X, Y)\}$\\ All variables are understood to be universally quantified, i.e.\\ $\forall X, Y [r(a, f(b, X) \implies p(X)] \land \forall X, Y\ q(X, Y)$
\end{itemize}

\paragraph{Substitution} Since terms may have variables in predicate logic, substitution is needed to ground literals. For example, let $\theta = \{V_1/t_1, V_2/t_2, ..., V_n/t_n\}$ where $V_i$ is a variable and $t_i$ a term that replaces $V_i$. Suppose, 

\begin{align*}
&p(X, Y)\\
\theta &= \{X/a, Y/g(b, Z)\}\\
p(X, Y)\theta &= p(a, g(b, Z))
\end{align*}

\paragraph{Grounding} A literal is \textit{ground} if it contains no variables.

\paragraph{Instance} A literal $l'$ is \textit{an instance of} $l$, if for some substitution $\theta$, $l' = l\theta$.

\paragraph{Skolemisation} When converting FOL to CNF, we also need to perform skolemisation to remove existential quantifiers and move all universal quantifiers to the front. 

\begin{itemize}
\item An existential quantifier with no dependency can be skolemised by introducing a new constant. For example, $\exists X\ p(X) \longrightarrow p(c)$. The constant $c$ that is replacing $X$ must not clash in name with other existing constants.
\item If an existential quantifier depends on another quantifier, a function symbol needs to be introduced. For example, $\forall X \exists Y p(X, Y) \longrightarrow \forall p(X, f(X))$.
\end{itemize}

\noindent All universal quantifiers need to be moved to the front. Variable name clashes must be resolved by renaming variables as the universal quantifiers are being moved to the front. Once they are at the front, all universal quantifiers at the front can all be removed. 

\subsection{Horn Clauses}

\begin{defn}Horn Clauses are a particular type of clauses with at most one positive literal only. The positive literal in the clauses is called the head and the other literals form the body of the clause.\end{defn}

\begin{defn}Definite Clauses have exactly one positive literal.  e.g. $\lnot b_1 \lor\lnot b_2 \lor ... \lor\lnot b_n \lor h$. Definite Clauses (aka rules) can also be re-written as $h \Leftarrow b_1 \land b_2 \land ... \land b_n$.\end{defn}

\begin{defn}Denials have no positive clauses. e.g. $\lnot b_1 \lor\lnot b_2 \lor ... \lor\lnot b_n$. Denials (aka constraints) can also be re-written as $\Leftarrow b_1 \land b_2 \land ... \land b_n$.\end{defn}

\begin{defn}Facts are Definite Clauses that have no negative literals. e.g. $h$. We omit the $\leftarrow$  or \lstinline{:-} symbols as with convention for facts.\end{defn}

\subsection{Resolution}\label{sec:Resolution}

\paragraph{} Resolution is a proof strategy to determine if a proposition can be satisfied by a clausal theory. Essentially, we will see that resolution is actually proof by contradiction (or in Latin, \textit{reductio ad absurdum} abbreviated as RAA).

\subsubsection{Propositional Logic Resolution}

\paragraph{Resolvent} Given two clauses of the form\\ $\{p \lor C_1; \lnot p \lor C_2\}$, the clause $C_1 \lor C_2$ is the inferred clause, called the \textit{resolvent} (conclusion of the premise).

\begin{figure}[H]
\centering
\includegraphics[width=0.25\textwidth]{graphics/propositional-logic-resolution-example1.png}
\caption{In this example, $\lnot r$ and $r$ gets cancelled away and resolves the two statement $w \lor r \lor q$ and $w \lor s \lor \lnot r$ into $w \lor q \lor s$}
\end{figure}

\paragraph{Refutation Completeness} Resolution is complete as a refutation system. That is, if $S$ is a contradictory set of clauses, then resolution can refute $S$, i.e. $S \vdash [\ ]$ or $S \vdash \perp$. For example given the case of $p \models p \lor q$, resolution cannot be directly applied to the given clausal theory $Th = \{p\}$ and infer $p \lor q$. Instead, we have to express it as a refutation problem and show that $\{p, \lnot(p \lor q)\} \models [\ ]$. We then show that the set of clauses $\{p, \lnot p, \lnot q\}$ converted from $Th$ can derive the empty clause $[\ ]$.

\begin{figure}[H]
\centering
\includegraphics[width=0.2\textwidth]{graphics/propositional-logic-resolution-example2.png}
\caption{In the example to show $p \models p \lor q$, we need to first express it as a refutation problem then derive the empty clause using resolution. Not all clauses need to be used.}
\end{figure}

\paragraph{Resolution} Given a knowledge base of clauses $Kb$, if $Kb \vdash c$ by resolution then $Kb \models c$. 

\begin{exmp}For example,
\begin{align*}
Kb &= \{\\
	&s;\\
	&s \implies c;\\
	&c \land m \implies b;\\
	&c \land f \implies g;\\
	&f\\
	\}&
\end{align*}

\noindent To prove that $Kb \models g$, we show that $Kb \cup \{\lnot g\} \models [\ ]$:

\begin{figure}[H]
\centering
\includegraphics[width=0.32\textwidth]{graphics/propositional-logic-resolution-example3.png}
\caption{By resolution we show that $Kb \cup \{\lnot g\} \models [\ ]$, hence $Kb \models g$.}
\end{figure}\end{exmp}

\subsubsection{Predicate Logic Resolution}

\paragraph{} Resolution in FOL is more complex: while it is still based on the idea of resolving opposite literals that appear in two clauses and deriving the empty clause, variables play an important role here. Literals may have unground terms (i.e. variables that yet to be substituted) which are understood as standing for all possible instances. Resolution could happen by referring to any such instances. Hence the role of the unification step is to identify which of these instances to use.

\paragraph{Name Clashes} When resolving two clauses, all variables occurring should be renamed with unused variables to avoid name clashes. A variable $X$ in clause $C_1$ is not the same as another variable named $X$ in $C_2$.

\paragraph{Resolution} Consider two opposite literals in two clauses which we want to resolve: We see if it is possible to find a substitution $\theta$ st when applied to both literals, $\theta$ makes the two literals equal. The resolution can then applied and the substitution has to be applied on all occurrences of those variables in the literals left in the resolvent. For example, suppose

\begin{align*}
Kb &= \{\\
	&on(a, b);\\
	&on(b, c);\\
	&green(a);\\
	&\lnot green(c)\\
	\}&
\end{align*}

\noindent and we want to show that $Kb \models \exists X \exists Y (on(X, Y) \land green(X) \land \lnot green(Y))$, we can apply the following resolution:

\begin{figure}[H]
\centering
\includegraphics[width=0.5\textwidth]{graphics/predicate-logic-resolution-example1.png}
\caption{The resolution takes the two substitutions (labelled blue) two create equally opposing literals for $on(X, Y)$.}
\end{figure}

\paragraph{} As we take the negation of the entailment, the existential quantifiers get eliminated and hence there is no need for skolemisation.

\paragraph{Answers to Query} Answer to the query may also return unification values (substitution). However, it is possible to construct resolutions that never terminate.

\subsection{Herbrand Theorem}

\paragraph{} It is possible to handle some predicate logic cases by converting them into propositional logic form. Consider $Th$ be a set of clauses (a clausal theory).

\paragraph{Herbrand Domain}\footnote{Also known as Herbrand Universe.} The set of all ground terms formed only using constants and function symbols that appear in $Th$.

\paragraph{Herbrand Base} The set of all ground atoms that can be formed using the predicate symbols in $Th$ and terms in the Herbrand Domain.

\paragraph{Grounding} The set of all $c_i\theta$ ground clauses st $c_i \in Th$ and the substitution $\theta$ replaces variables in $c_i$ by terms in the Herbrand Domain. The grounding of $Th$ is denoted as $ground(Th)$.

\paragraph{Theorem} A clausal theory $Th$ is \textit{satisfiable} iff the grounding of $Th$ is \textit{satisfiable}. Since the grounding of $Th$ has no variables, it is essentially propositional. $Th$ is not satisfiable iff by resolution the grounding of $Th$ concludes to the empty clause.

\begin{exmp}\label{exmp:HerbrandTheorem} Consider FOL sentence $S$ whose language $\mathcal{L}$ includes only the constants $b$, $c$, $l$:\end{exmp}

$$S = \forall X, Y [\lnot p(b, Y) \lor p(c, l) \lor (p(b, X)\lor \lnot p(X, l))]$$

\noindent From $S$ we can build the set $C$ of clauses st $C = \{\lnot p(b, Y); p(c,l); p(b, X) \lor \lnot p(X, l)\}$. The \textit{Herbrand Domain of $C$} is $\{b, c, l\}$ while the grounding is:

\begin{align*}
ground(C) &= \{\\
	&\lnot p(b, b),\\
	&p(b, b), \lor \lnot p(b, l),\\
	&\lnot p(b, c),\\
	&p(b, c) \lor \lnot p(c, l),\\
	&\lnot p(b, l),\\
	&p(b, l) \lor \lnot p(l, l),\\
	&p(c, l)\\
	\}&
\end{align*}

\paragraph{} In Example \ref{exmp:HerbrandTheorem}, $ground(C)$ is not satisfiable because of a contradicting subset of the ground clauses: $\{\lnot p(b, c), p(c, l), p(b, c) \lor\lnot p(c, l)\}$. Hence the set of clauses $C$ is unsatisfiable.


\paragraph{Herbrand Interpretation} A Herbrand Intepretation (HI) of a set $Th$ of definite clauses is a set of ground atoms over the constant, function and predicate symbols occurring in $Th$. In essence, a HI is a subset of the Herbrand Base of $Th$, and the set of all Herbrand Interpretations of $Th$ is the power set of the Herbrand Base.

\paragraph{Herbrand Model} A Herbrand Interpretation $I$ is a Herbrand Model (HM) of $Th$ iff for all clauses $\lnot b_1 \lor \lnot b_2 \lor ... \lor \lnot b_n \lor h_1 \lor h_2 \lor ... \lor h_m$ in $Th$ and ground substitutions $\theta$, $$\{b_1\theta, b_2\theta, ..., b_n\theta\} \in I \implies \{h_1\theta, h_2\theta, ..., h_m\theta\} \cap I \not= \emptyset$$

\noindent The inequality with an empty set denotes that the HI $I$ must satisfy $\exists i \in [1, m]\ h_i\theta$. Hence a Herbrand Model is a Herbrand Interpretation is satisfable in a clausal theory.

\begin{defn} Since there may be more than one HI that satisfies a clausal theory (i.e. more than one HM), some HM may be a subset of another HM. The \textit{Minimal Herbrand Model} is a HM of which none of its subsets is a HM. Any satisfiable clausal theory $Th$ of definite clauses has one unique minimal HM called the \textit{Least Herbrand Model}. \end{defn}

\paragraph{Infinite Herbrand Domain} It is possible for a clausal theory to accept an infinite HM as they may have an infinite HD. Consider the following example which has an infinite HD:

\begin{align*}
Th &= \{\\
	&\text{natural}(0),\\
	&\text{natural}(X) \implies \text{natural}(succ(X))\\
	\}&
\end{align*}

\subsection{SLD Derivation}
\paragraph{} A pure Prolog program is a set of definite clauses and hence its semantics is given by its Least Herbrand Model\footnote{Defined by Luc De Raedt in his book.}. The inference procedure used by Prolog is a special version of resolution that exploits the fact that the given clausal theory is a set of definite clauses and not general clauses. 

\paragraph{} Queries to a Prolog program are not any arbitrary clauses but denial clauses\footnote{We want to proof by refutation.}. Arbitrary clauses must be rewritten in a certain way to accomodate this syntactic restriction of Prolog. 

\paragraph{} Given a set of definite clauses and a denial clause, there can be many resolution proofs that can be constructed. Prolog uses a special form of resolution - SLD resolution - to systematically explore all possible derivations. The SLD derivation is a linear sequence of application of an SLD inference rule that is applied between a denial clause and a definite clause in the original $Th$ clausal theory. SLD is a resolution proof method and as such is still refutation based. Hence the denial clause is the given query expressed in denial form. 

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sld-inference-rule.png}
\caption{$\theta$ in the inference rule is the Most General Unifier $mgu(\alpha_1, \alpha_1')$. $\alpha_i$ and $\beta_j$ are atoms.}
\end{figure}

\paragraph{} Given a denial (goal) $G_0$ and clausal theory $Th$ of definite clauses, an SLD-derivation of $G_0$ from $Th$ is a (possibly infinite) sequence of denials:

$$G_0 \underset{C_0}{\implies} G_1 \underset{C_1}{\implies} ...  \underset{C_{n-2}}{\implies} G_{n - 1}\underset{C_{n - 1}}{\implies} G_n  $$

\noindent ... where $G_{i + 1}$ is derived directly from $G_i$ and a clause $C_i$ with variables appropriate renamed. This means the composition $\theta = \theta_1 \theta_2 ... \theta_n$, where $\theta_i$ is defined at each step of the derivation, gives the entire substitution computed reaching the final derivation if computation is \textit{finite}.

\subsubsection{SLD Trees}

\paragraph{} When performing SLD derivation, there may be one or more choices of clause $C_i$ that can be used with $G_i$ to derive $G_{i+1}$. Consider the following knowledge base and the query $\exists Z\ \text{proud}(Z)$:

\begin{itemize}
\setlength\itemsep{0.0em}
\item[] $\text{proud}(X) \Leftarrow \text{parent}(X, Y), \text{newborn}(Y)$
\item[] $\text{parent}(X, Y) \Leftarrow \text{father}(X, Y)$
\item[] $\text{parent}(X, Y) \Leftarrow \text{mother}(X, Y)$
\item[] $\text{father}(\text{adam}, \text{mary})$
\item[] $\text{newborn}(\text{mary})$
\end{itemize}


\begin{figure}[H]
\centering
\includegraphics[width=0.45\textwidth]{graphics/sld-derivation-example.png}
\caption{By SLD derivation, we determine that $Z = \text{adam}$.}
\end{figure}

\paragraph{} However we can see that at $C_2$, another clause $\text{parent}(X, Y) \Leftarrow mother(X, Y)$ could have been picked instead for the reservation. When each sub-goal can unify with more clauses, more than one SLD derivations can be computed. Alternative choices can then be represented as a tree, with each leaf as a possible derivation.

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{graphics/sld-tree.png}
\caption{Each time there is a choice of clauses can be be used to resolve the subgoals, branches are created in the tree to represent the different possible derivations. In this case, picking $\Leftarrow \text{mother}(X, Y), \text{newborn}(Y)$ as $G_2$ would lead to a non-empty derivation. }
\end{figure}

\paragraph{} The SLD Tree represents the search space of all possible derivations. Each path from the original denial $G_0$ to the leaf node is the SLD computation / refutation. The tree is then traversed in a depth-first search to provide each refutation in order. For a finite SLD-tree, this strategy is complete. Whenever the traversal reaches a leaf node of an empty clause, the substitution of the completed refutation is returned. As mentioned before, it is also possible for SLD derivation to generate an infinite sequence of denials and hence an infinite SLD-tree, which explains why sometimes Prolog computations do not terminate.

\subsection{Normal Clausal Logic}\label{sec:NormalClausalLogic}

\paragraph{Normal Clausal Logic} extends Horn Clauses by permitting atoms in the body of a rule / denial to be prefixed with a special operator \textit{not} (read as "fail"). This operator is also referred to as "negation by failure". For example:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] \textbf{Normal Clauses}:\\ $h \Leftarrow b_1, ... b_n, \text{not}\ b_{n+1}, ..., \text{not}\ b_m$
\item[] \textbf{Normal Denials}:\\ $\Leftarrow b_1, ... b_n, \text{not}\ b_{n+1}, ..., \text{not}\ b_m$
\end{itemize}

\paragraph{} The \textit{not} operator in Prolog is known as $\backslash+$. The computational meaning of $\text{not}\ p$ is: i) $\text{not}\ p$ succeeds iff $p$ fails finitely and ii) $\text{not}\ p$ fails iff $p$ succeeds. When evaluating $\Leftarrow \text{not} p(X)$, the atom $p$ must be ground: otherwise the derivation is "floundered"\footnote{The answer is unknown.}. The variable $X$ should have already been grounded in previous steps of the derivation.

\paragraph{} In Normal Clausal Logic, the fail operator never appears in the head of a rule. Putting the fail operator in the head of a rule would be asking to prove what should not be proved, whereas clausal theories define what should be provable.

\subsection{SLDNF Derivation}
\paragraph{} SLDNF derivation is SLD derivation with Negation as Failure. A selected subgoal $\text{not}\ p)$,  succeeds if the subproof fails, and it fails if the subproof succeeds. Consider the following example knowledge base and query $connected$:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] $connected \Leftarrow \text{not}\ unconnected$
\item[] $unconnected \Leftarrow node(X), \text{not}\ succ(X)$
\item[] $succ(X) \Leftarrow arc(X, Y)$
\item[] $node(a)$
\item[] $node(b)$
\item[] $arc(a, b)$
\item[] $arc(b, c)$
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sldnf-example1.png}
\caption{ In the example, we need to prove that $\Leftarrow unconnected$ fails in order to prove the second denial / sub-goal "$\Leftarrow \text{not}\ unconnected$". $\Leftarrow unconnected$ fails iff all all possible outcomes of $\Leftarrow unconnected$ comes to a failure / non-empty clause. The two possible outcomes, for $X = a \text{or} b$: $\Leftarrow \text{not}\ succ(X)$, are proven to to fail since each of $\Leftarrow succ(X)$ succeeds.}
\end{figure}

\paragraph{Floundering} If we make a slight modification to the knowledge base of the example by replacing $unconnected \Leftarrow node(X), \text{not}\ succ(X)$ with $unconnected \Leftarrow node(X), \text{not} arc(X, Y)$, the SLDNF would not be possible to evaluate even though the knowledge bases are equivalent. Figure \ref{fig:sldnf-example2} shows the resolution tree.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/sldnf-example2.png}
\caption{With the slight modification, it becomes impossible to prove $\text{not}\ arc(X, Y)$ for $a$ and $b$ since $Y$ was not instantiated, as it would require a search through possibly infinite derivations to prove that there is exists no such value of $Y$. This is why the SLDNF strategy adopted is whenever a non-ground fail literal is encountered as a subgoal, the derivation consider it not possible to evaluate and a floundering condition is reported.}
\label{fig:sldnf-example2}
\end{figure}

\subsection{Abduction}

\paragraph{} So far reasoning has been primarily deductive. Sometimes our knowledge base can be incomplete and deductive inference would fail on certain queries due to lack of information. For example, given the following knowledge base and the query $soreElbow$:

\begin{itemize}
\setlength\itemsep{0.1em}
\item[] $soreElbow \Leftarrow tennisElbow$
\item[] $tennisPlayer \Leftarrow tennisElbow$
\item[] $soreElbow \Leftarrow soreJoints$
\item[] $soreJoint \Leftarrow arthritis, untreated$
\end{itemize}

\paragraph{} It is impossible to explain $soreElbow$ using deductive inference, as shown in Figure \ref{fig:abduction-example1} below.

\begin{figure}[H]
\centering
\includegraphics[width=0.3\textwidth]{graphics/abduction-example1.png}
\caption{}
\label{fig:abduction-example1}
\end{figure}

\paragraph{} Abductive reasoning computes explanations that are consistent with the given knowledge base to explain (or satisfy) the given observations. The list of explanations can be generated and some may be subset of others. They should not be unnecessarily strong\footnote{i.e. including more ground literals than needed} or unnecessarily weak \footnote{too few to prove the observations in all circumstances}. Abductive algorithms for Normal clauses aim to generate a minimal set of explanations that, together with the given theory, proves the goal.

\paragraph{Abducibles} When modelling a problem domain in an abductive term, we need to think about a vocabulary of what are considered to be plausible explanations for the given types of observations - and we refer this vocabulary as the set of \textit{abducibles}.

\subsubsection{Abductive Model}

\paragraph{} An abductive model of a problem domain is defined as a tuple $<KB, Ab, IC>$ where $KB$ is the knowledge base (set of normal clauses), $Ab$ is the vocabulary of plausible explanations (set of ground undefined literals), and $IC$ is the set of constraints (set of normal details).

\paragraph{Abductive Solution} Given an abductive model, an \textit{abductive solution} (or explanation) of a given observation $O$ is a set $\Delta$ of ground literals st:

\begin{itemize}
\item $\Delta \subseteq Ab$: $\Delta$ belongs to a predefined language of abducibles.
\item $KB \cup \Delta \models O$: $\Delta$ must provide missing information needed to prove observation $O$.
\item $KB \cup \Delta \not\models \perp$: $\Delta$ must be consistent with the knowledge base.
\item $KB \cup \Delta \models IC$: $\Delta$ when combined with the knowledge base must entail the constraints.
\end{itemize}

\paragraph{} When $KB$ is a set of definite clauses, the augmented theory $KB \cup \Delta$ will also be a set of definite clauses that accepts a unique minimal model, the Least Herbrand Model.

\subsection{Abductive Proof Procedure}

\subsubsection{Abductive Phase}\label{sec:AbductiveProofProcedureAbductivePhase}

\paragraph{} Let $<KB, Ab, IC>$ be an abductive model expressed in Normal Clausal Logic and let $O$ be a ground observation. To start the procedure, we let $G_1 = O$ and $\Delta_0$ initially be $\emptyset$:

\paragraph{} Select a subgoal $L \in G_i$, then let $G_i' = G_i - \{L\}$:
\begin{itemize}
\item $L \not\in Ab$ and $L$ is a non-negative atom:\\ If $\exists [(H \Leftarrow B) \in KB]$ st $L = H\theta$,\\ then $G_{i+1} = B\theta \cup G_i$ and $\Delta_{k+1} = \Delta_k$
\item $L \in \Delta_i$: $G_{i+1} = G_i$ and $\Delta_{k+1} = \Delta_k$
\item $L \in Ab$ and $L \not\in \Delta_k$ and $(\text{not}\ L) \not\in \Delta_k$: $L$ can be assumed but needs to go through \textit{Consistency Phase} (Section \ref{sec:AbductiveProofProcedureConsistencyPhase}) to verify that assumption does not introduce inconsistency. If the consistency phase succeeds\footnote{Succeds with a failure in derivation.}, then $\Delta_{k+1} = \Delta_k \cup {L}$.
\end{itemize}

\subsubsection{Consistency Phase}\label{sec:AbductiveProofProcedureConsistencyPhase}

\paragraph{} To prove that an assumption $A$ does not introduce inconsistency, the Consistency Phase requires the derivation to finish with a failure.

\paragraph{} Let $F_1$ be the set of all denials in $IC$ that has been resolved with assumption $A$. Select a denial $\Leftarrow \phi$ in $F_1$ and a literal L from $\phi$.

\begin{itemize}
\item $L \not\in Ab$: Perform SLDNF failure with L as a subgoal.
\item $L \in \Delta_k$: $\phi' = \phi - \{L\}$ and consider the new constraint $\Leftarrow \phi'$\
\item $L \in Ab$ and $(\text{not}\ L) \in \Delta_k$, then continue consistency phase with the next denial in $F_1$ to check.
\item $L \in Ab$ and $L \not\in \Delta_k$ and $(\text{not}\ L) \not\in \Delta_k$: As the literal has to fail, we perform an abductive derivation of its negation to check for its success (i.e. we go back to Abductive Phase, Section \ref{sec:AbductiveProofProcedureAbductivePhase}, with the subgoal $\text{not} L$). 
\end{itemize}

\section{Inductive Logic Programming}

\paragraph{} ILP can be seen as a search problem. In \textit{concept learning} the task is to compute the definition of a concept, expressed in a given language (i.e. hypotheses space), that satisfies all examples labelled as \textbf{positive} and none of the examples labelled as \textbf{negative} in a given dataset.

\paragraph{} However, the question is: how do we make the search for hypotheses that covers relation and quality criterion computationally feasible? A naive approach would be to perform a generate-and-test, which would become very inefficient when the version space gets large.

\subsection{Learning as a Search}

\paragraph{} Given 

\begin{itemize}
\setlength\itemsep{0.1em}
\item $\mathcal{L}_e$: a set of observations where
	\begin{itemize}
	\item $E^+$ is the set of positive examples
	\item $E^-$ is the set of negative examples
	\end{itemize}
\item $B$: Background knowledge / clausal theory
\item $\mathcal{L}_h$: hypothesis language
\item $c(B, \mathcal{L}_h, e)$: coverage of $\mathcal{L}_h$ over the example $e$
\end{itemize}

\noindent We want to find a theory $H \in \mathcal{L}_h$ st

\begin{itemize}
\setlength\itemsep{0.1em}
\item $\forall e \in E^+: B \cup H \models e$: H is \textbf{complete}
\item $\forall e \in E^-: B \cup H \not\models e$: H is \textbf{consistent}
\end{itemize}

\paragraph{} Using the same concept as concept learning, we need to define a notion of \textit{generality relation} between first-order theories and be able to put clauses in general-to-specific order.

\subsection{Generality of Theories}

\paragraph{} Let $C$ and $D$ be two definite clauses. 

\begin{defn} $C$ is more general than $D$ (denoted $C \geq_g D$) iff $C \models D$. If $C \not\models e$, then $D \not\models e$. \end{defn}

\begin{defn} $C$ subsumes $D$ iff $\exists \theta$ st $C\theta \subseteq D$. If $C$ subsumes $D$, $C \models D$. \end{defn}

\paragraph{$\theta$-subsumption} Given two sets of clauses where $H_1 = \{C_1,... , C_n\}$ and $H_2 = \{D_0,... , D_m\}$, to show that $H_1$ $\theta$-subumes $H_2$, we need to show that $\forall D_i$ clause $\in H_2$, $\exists C_i$ clause $\in H_1$ that subsumes $D_i$.

\paragraph{} A clause $C$ can $\theta$-subsume itself as the $\theta$-substitution would be $\theta = \{\}$. If an hypothesis is consistent (i.e. does not cover any negative example) then any specialisation of this hypothesis will also be consistent. Similarly if an hypothesis is complete (i.e. covers every positive example), then every generalisation of this hypothesis will also be complete. Recall we aim to find hypotheses that are complete and consistent.

\subsection{Lattice of Clauses}

\paragraph{} ILP for definite clauses can be described by i) Structure of the hypothesis space based on generality relation and ii) Search strategy (or prune strategy) by $\theta$-subsumption. The subsumption relation over definite clauses defines a lattice structure. There are two types of traversal over the lattice of hypotheses: specialization (going down the lattice to find a more specific hypothesis) and generalization (going up the lattice to find a more general hypothesis). Hence, ILP learning programs for definite clauses have been classified into either \textit{top-down} or \textit{bottom-up} learners.

\subsection{General-to-Specific Traversal}

\paragraph{Shapiro Operator} is a refinement / specialisation operator. The basic idea is to start from a set of positive and negative examples of a new concept and compute a set of Horn clauses that correctly represent this concept by traversing a lattice (i.e. a special version space) of possible hypothesis by means of the Shapiro ($\rho$) operator. The key idea is to add a literal in the body of the current clause or apply a substitution $\theta$.

\subsection{Specific-to-General Traversal}

\paragraph{} There are two main operators developed in ILP that allow specific-to-general traversal over the lattice space of hypotheses:

\begin{itemize}
\item Plotkin's least general generalisation (lgg) of two clauses
\item Muggleton's inverse resolution
\end{itemize}

\subsubsection{Plotkin's Least General Generalisation}

\paragraph{} Plotkin's least general generalisation (lgg)\cite{plotkin70} takes two clauses and tries to compute a third clause that is the \textit{most specific of all the clauses}, but yet still more general than both given clauses.

\paragraph{} The lgg the two \textit{terms} is given by the following examples:

\begin{itemize}
\item $lgg(a, b) = X$
\item $lgg(f(a), f(b)) = f(lgg(a, b)) = f(Z)$
\item $lgg(f(X), g(Y)) = Z$
\item $lgg(f(a, b, a), f(c, c, c)) = f(X, Y, X)$
\end{itemize}

\paragraph{} The lgg of two \textit{literals} of the same predicate name and number of arguments are given by:

\begin{align*}
lgg(p(s_1, \dots, s_n), p(t_1, \dots, t_n)) =\\
	p(lgg(s_1, t_1),\dots,lgg(s_n, t_n))
\end{align*}

\paragraph{}The lgg of two \textit{clauses} are given by:

\begin{align*}
lgg(c_1, c_2) = \{lgg(l_1, l_2)\ |\ l_1 \in c_1 \land l_2 \in c_2 \\
\land\ lgg(l_1, l_2) \text{ is defined}\}
\end{align*} 

\paragraph{} Consider the example of the following two clauses:

\begin{align*}
c_1 = \{f(t,a)\lor\lnot p(t, a); \lnot m(t); \lnot m(a)\}\\
c_2 = \{f(j,p)\lor\lnot p(j, p); \lnot m(j); \lnot f(p)\}
\end{align*} 

\noindent Then the lgg of $c_1$ and $c2$ given above would be the set:

$$\{f(X,Y) \lor \lnot p(X, Y); \lnot m(X); \lnot m(Z)\}$$

\paragraph{} Note that there are two literals $\lnot m(X)$ and $\lnot m(Z)$ because $\lnot m(j)$ in $c_2$ gets matched to two different "$\lnot m(X)$"s in $c_1$.

\subsubsection{Muggleton's Inverse Resolution}

\paragraph{} The method for searching hypotheses from specific to general is the use of inverse resolution proposed by Muggleton\cite{muggleton95} as a mechanism for computing relative generality relation between clauses. In his paper, the generality relation was computed relative to a given background knowledge.

\paragraph{} The idea of inverse resolution is to compute clauses from given clauses that reflect an inverse of the standard resolution rules as seen in Section \ref{sec:Resolution}. 

\paragraph{} The following are four main inverse resolution operations on propositional logic:

\paragraph{Absorption} is applied to two clauses $C_1$ and $C_2$ st $C_1$ includes all the body conditions that define a predicate $Y$ in the first clause $C_1$:

\begin{align*}
& Y \leftarrow C, D, E && \text{Clause } C_1\\
& X \leftarrow A, B, C, D, E && \text{Clause } C_2\\
& X \leftarrow A, B, Y && \text{Resulting Clause } C_3
\end{align*}

\noindent A new clause $C_3$ is generated from $C_2$ by replacing the body literals in $C2$ that are used in $C_1$ with the head of the clause $C_1$. The new clause is a generalisation of the two given clause as it would allow the inference of $X$ by using any other definition of $Y$.

\paragraph{Identification} is used to identify a set of literals common in two clauses and identify a single (leftover) literal (i.e. $Y$ in the example below), with a (leftover) set of literals in the second clause (i.e. $C$, $D$ and $E$) and generate a new clause that contains this leftover literal ($Y$) in terms of the other leftover literals.

\begin{align*}
& X \leftarrow A, B, Y && \text{Clause } C_1\\
& X \leftarrow A, B, C, D, E && \text{Clause } C_2\\
& Y \leftarrow C, D, E && \text{Resulting Clause } C_3
\end{align*}

\paragraph{} The following two operations do not generalise the current knowledge but attempts to restructure it.

\paragraph{Intra-construction} involve more than two clauses, i.e. inverse of two or more parallel resolutions. It identifies a common set of literals in rules with the same head and defines a new concept using the literals that are not common in the used clauses.

\begin{align*}
& X \leftarrow A, B, C, D && \text{Clause } C_1\\
& X \leftarrow A, B, E, F && \text{Clause } C_2\\
& X \leftarrow A, B, N && \text{Resulting Clause } C_3\\
& N \leftarrow C, D && \text{Resulting Clause } C_4\\
& N \leftarrow E, F && \text{Resulting Clause } C_5\\
\end{align*}

\paragraph{Inter-construction} involve more than two clauses, i.e. inverse of two or more parallel resolutions. It identifies a common set of literals in rules and replace them with a new concept

\begin{align*}
& X \leftarrow A, B, C, D && \text{Clause } C_1\\
& X \leftarrow A, B, E, F && \text{Clause } C_2\\
& N \leftarrow A, B && \text{Resulting Clause } C_3\\
& X \leftarrow N, C, D && \text{Resulting Clause } C_4\\
& X \leftarrow N, E, F && \text{Resulting Clause } C_5\\
\end{align*}

\subsection{Learning as a Search}\label{sec:LearningAsASearch}

\paragraph{} The problem of logic-based learning is a problem of searching over a version space of theories (possible solutions). Given that generality relation between clauses in a version space is expressed as entailment and the hypothesis space consist of definite clauses, we can use several different approaches described earlier.

\paragraph{} There are two main search operators:

\begin{itemize}
\item \textbf{Using $\theta$-subsumption}: either done top-down by specialising clauses to remove coverage over negative examples (using Shapiro $\rho$ refinement operator) or bottom-up by computing more general clauses (using Plotkin's lgg operator).
\item \textbf{Using inverse entailment}: defining a logic-based process (using inverse resolution) as the underlying mechanism then define induction on top of a richer logic-based inference mechanism. Inverse resolution is a bottom-up approach as it computes more general clauses from specific one.
\end{itemize}

\subsection{Learning from Interpretation}

\paragraph{} In \textit{Learning from Interpretation}, the set of examples contain a full description, and all the information that belongs to the example is represented in the example, not in the background knowledge. The Background only contains general information concerning the domain, not concerning specific examples. Hence a definite clause theory $H$ is a solution iff $e \in E^+$ is a model of $H$ (i.e. $e \models H$).

\subsection{Learning from Entailment}

\paragraph{} Learning from entailment is a different paradigm. Given the examples $E = <E^+, E^->$, each $e \in E$ is a ground fact and $B$ is the background definite clause theory. We want to find hypothesis $H$ st means $\forall e \in E^+\ B \cup H_i \models e$ and $\forall e \in E^-\ B \cup H_i \not\models e$

\section{HAIL \& Progol}

\paragraph{} As discussed in Section \ref{sec:LearningAsASearch}, the third method of using inverse entailment put forth by Muggleton combines both top-down and bottom-up searches by using the notion of inverse entailment and general-to-specific search. This was put into a system called PROGOL and its focus was to support the learning of concepts whose instances are directly observed (.e. Observation Predicate Learning)

\subsection{Predicate Learning}

\paragraph{} Predicate learning is classified into two kinds:

\begin{itemize}
\item \textbf{Observation Predicate Learning (OPL)}: Hypothesis and examples define the same predicates. 
\item \textbf{Non-Observation Predicate Learning (NOPL)}: Hypothesis and examples define different predicates.
\end{itemize}

\paragraph{} Generally knowledge about problem domain is not complete and general principles may need to be learned in order to explain observed complex phenomena. Hence a NOPL would look for new general knowledge, used together with existing knowledge, to explain the observations. 

\subsection{Inverse Entailment}

\paragraph{} Consider the notion of Inverse Entailment. It combines the advantages of both bottom-up\footnote{narrowing the search by starting from what is known already} and top-down\footnote{refining a general hypothesis to form a new one} searches. We observe that

\[ B \cup H \models E \equiv B \cup \lnot E \models \lnot H \]

\paragraph{} Note that since $H$ and $E$ are set of clauses, their variables are universally quantified. When negating clauses in these sets, the variables becomes existentially quantified - skolemised. 

\subsection{Language Bias}\label{sec:LanguageBias}

\paragraph{} Sometimes we would like to define the language of the hypothesis by using a language bias. It is composed of a set of \textbf{mode declarations}.

\[
\text{Mode declarations: }
\begin{cases}
	modeh(r, s)\\
	modeb(r, s)
\end{cases}
\]

\paragraph{modeh} indicates the predicate may appear as head predicate of the rules to learn.
\paragraph{modeb} indicates the predicate may appear as body predicate of the rules to learn.
\paragraph{r} represents a recall, an integer that indicates how many times the predicate may appear in a rule. '*' indicates that the predicate may appear any number of times in a rule.
\paragraph{s} is the scheme, which is a ground atom with the predicate's name, placemarkers $+t$ (input variable), $-t$ (output variable) and $\#t$ (constants) for unary type $t$. 

\paragraph{Example} For example consider the following mode declarations:

\begin{align*}
	&\text{modeh}(1, \text{grandfather}(+\text{person}, +\text{person}))\\
	&\text{modeb}(1, \text{father}(+\text{person}, -\text{person}))\\
	&\text{modeb}(1, \text{parent}(+\text{person}, +\text{person}))
\end{align*}

We can build a rule $grandfather(X, Y) \leftarrow father(X, Z), parent(Z, Y)$.

\subsection{Bottom Set}

\paragraph{} Considering a positive example $e^+ \in E^+$, we can compute the (possibly infinite) set of ground literals that are derivable from (or entailed by) $B \land \lnot e^+$. These set of ground literals are considered as the negation of the Bottom Set, denoted $\lnot Bot(B, e^+)$. Let $h$ to be a single Horn clause where

\begin{itemize}
\item $h \equiv l_1 \lor \lnot l_2 \lor ... \lor \lnot l_n$: Note that $l_1$ is the head of the clause.
\item $e^+ \equiv a_1 \lor \lnot a_2 \lor ... \lor \lnot a_m$: Note that $a_1$ is the head of the clause.
\end{itemize}

\paragraph{} We then have their negation with skolemisation:

\begin{itemize}
\item $\lnot h \equiv \lnot l_1 \land l_2\theta \land ... \land l_n\theta$: $\theta$ is a grounding by existential quantifier for $h$.
\item $\lnot e^+ \equiv \lnot a_1\delta \land a_2\delta \land ... \land a_m\delta$: $\delta$ is a grounding by existential quantifier for $h$.
\end{itemize}

\paragraph{} The Bottom set is then defined as:

$$Bot(B, e^+) = \{\lnot l_1\theta, \lnot l_2\theta, ..., \lnot l_n\theta\}$$

\paragraph{} The Bottom Set is the \textbf{most specific ground set of clauses} that is at the bottom of an hypothesis search space that explains the example $e^+$. Let $g(\lnot h_{\perp}) \subseteq \lnot Bot(B, e^+)$ and consequently $\lnot Bot(B, e^+) \models g(\lnot h_{\perp})$. Remember that all variables in the sets $g(\lnot h_{\perp})$ and $\lnot Bot(B, e^+)$ are existentially quantified. By contrapositive, we have $g(h_{\perp}) \models Bot(B, e^+)$. If we replace every constant in $g(h_{\perp})$ with a unique variable, we obtain a universally quantified clause $h_{\perp}$. This clause $h_{\perp}$ $\theta$-subsumes the Bottom Set (and hence $h_{\perp} \models Bot(B, e^+)$).

\paragraph{} $h_{\perp}$ corresponds to the \textbf{most specific unground hypothesis} at the bottom of the hypothesis search space (or lattice) that $\theta$-subsumes $Bot(B, e^+)$. 

\paragraph{} Computing the Bottom Set first allows for a more efficient search for hypotheses, as the search space can be limited to the sub-lattice space delimited by the $Bot(B, e^+)$ as the bottom-most element and the empty clause as the top element. Solutions will be clauses that $\theta$-subsume the Bottom Set $Bot(B, e^+)$.

\paragraph{} We can look at the Least Herbrand Model of the set of $B \cup {\lnot e^+}$ for the list of literals that can be entailed from $B \cup \{\lnot e^+\}$. Alternatively to prove that the set satisfy a clause $h$, we can also use proof by resolution to show that $B \land \lnot e^+ \land \lnot h \vdash_{res} [\ ]$.

\paragraph{Learning by Bottom Generalisation} Using the computed Bottom Set to generate the bottom clause $h_{\perp}$, the next step would be to compute a more generate clause that subsume these bottom set through top-down refinement. We say that an hypothesis $H$ is derivable from the bottom generalisation from $B$ and $e^+$ iff $H \geq_g Bot(B, e^+)$. 

\subsection{Inverse Entailment \& NOPL}

\paragraph{} By definition of Inverse Entailment and Bottom Generalisation, we only look for bottom definite clauses (i.e. the Bottom Set has to include at most one positive literal by definition of definite clauses). Learning by Bottom Generalisation is good for OPL if we assume a complete background knowledge. However, it would fail to compute hypothesis about predicates that are not directly observed. Consider background knowledge and the positive example $hasbeak(tweety)$:

\[
B = \begin{cases}
haspeak(X) \leftarrow bird(X)\\
bird(X) \leftarrow vulture(X)
\end{cases}
\]

\paragraph{} We work out the following steps according to Bottom Generalisation:

\begin{align*}
\lnot e^+ &= \lnot hasbeak(tweety)\\
B \land \lnot e^+ &= \{\\
& \lnot hasbeak(tweety)\\
& \land \lnot bird(tweety) \\
& \land \lnot vulture(tweety)\\
\}&\\
Bot(B, e^+) &= hasbeak(tweety)\\
& \lor bird(tweety)\\
& \lor vulture(tweety)\\
g(h_{\perp}) &= \{ hasbeak(tweety) \}\\
h_{\perp} &= \{ hasbeak(X) \}
\end{align*}

\subsection{Progol5}

\paragraph{} We observe that the hypothesis in the Learning program above, we derived predicates that are in the examples and does not learn new concepts. Since we want to explain the examples in terms of other concepts, the background knowledge needs to provide those links. The key problem is how to compute information that is missing in the given background knowledge and use these new notions to generate new hypotheses. Prof. Muggleton proposed an extension of the Progol system that incorporates the notion of contrapositives used in FOL theorem proving\cite{muggleton00}.

\paragraph{} A clause with $n$ number of literals in its body is also equivalent to $n$ number of different clauses generated by contrapositive in the following way:

\begin{align*}
s &\leftarrow\\
p &\leftarrow q, r\\
&\leftarrow \lnot s\\
\lnot q &\leftarrow \lnot p, r\\
\lnot r &\leftarrow \lnot p, q\\
\end{align*}

\paragraph{} As it is invalid syntax for Prolog to have negated literals in the head of the rules, we can be creative by inventing new names that represent such negation, for example:

\begin{align*}
s &\leftarrow\\
p &\leftarrow q, r\\
&\leftarrow non\_s\\
non\_q &\leftarrow non\_p, r\\
non\_r &\leftarrow non\_p, q\\
\end{align*}

\paragraph{} Now the background knowledge includes their equivalent contrapositive clauses.

\paragraph{} The proof procedure for a given learning task $\langle B, E^+, E^-, M\rangle$ in Progol5 uses a covering loop where in the loop the steps are as follows:

\begin{enumerate}
\item Pick a seed example $e \in E^+$
\item Normalise $B$ and $e$
\item \textbf{StartSet}: Compute a ground head atom $a \in Bot(B, e)$ that is subsumed by some atom in the language of $M$
\item \textbf{BottomSet}: Compute a set of ground body atoms $b_1, \dots, b_n \in Bot(B, e)$ st $a \leftarrow b_1,\dots,b_n$ is subsumed by some clause in the language of $M$.
\item \textbf{Search}: Compute compressed hypothesis $h$ in language of $M$ that subsumes $a \leftarrow b_1, \dots, b_n$
\item Add hypothesis $h$ to $B$ (i.e. $B = B \cup H$) and remove \textit{all} cover from $E^+$ (i.e. $E^+ = \{e \ in E^+\ |\ B \not\models e\}$).
\item If $E^+$ is non-empty, continue back at step (1).
\end{enumerate}

\subsection{Kernel Set}

\paragraph{} The notion of the BottomSet $Bot(B, e)$ can be generalised into a new notion called \textbf{Kernel Set}. The creation of Kernel Set uses a full abductive reasoning procedure that replaces the StartSet procedure used to derive $Bot(B, e)$. 

{\footnotesize
\begin{align*}
& Kernel(B, E) \\
&= \{a | a \in \Delta \land B \cup \Delta \models e\} \cup \{\lnot b_i | B \cup \{\lnot e\} \models b_i\} \\
&= \bigwedge \{b_i | B \cup \{\lnot e\} \models b_i\} \rightarrow \bigvee \{a | a \in \Delta \land B \cup \Delta \models e\} \models b_i\}
\end{align*}}

\paragraph{} Note from above that the body literals are still generated the same way as it did by Progol5, i.e. $B \cup \{\lnot e\} \models b$. From the Kernel Set (that is ground), we then construct the Kernel Set hypothesis (that is ungrounded) given by

\[ 
K = \begin{cases}
a_1 \leftarrow b_{11}, b_{21}, ..., b_{n1}\\
a_2 \leftarrow b_{12}, b_{22}, ..., b_{m2}\\
...\\
a_k \leftarrow b_{1k}, b_{2k}, ..., b_{hk}
\end{cases}
\]

\subsection{HAIL Algorithm}

\paragraph{} The Hybrid Abductive Inductive Learning (HAIL) algorithm is similar to Progol5 in the sense that it has a covering loop and in each iteration a single positive example is processed.

\paragraph{} The proof procedure for a given learning task $\langle B, E^+, E^-, M\rangle$ is as such:
\begin{enumerate}
\item Pick a seed example $e \in E^+$
\item Normalise $B$ and $e$
\item \textbf{Abduction}: An abductive proof procedure produces a possible explanation of $e$ using the background knowledge and set of abducibles given by set of mode head declarations in $M$. This possible explanation is represented by a set of positive ground abducibles. 
\item \textbf{Deduction}: $B$ and $e$ are used to compute ground instances of the mode body predicates according to language bias $M$. This computation is pure deductive inference. We generate the Kernel Set $Kernel(B, e)$. The unground version of the Kernel Set forms the bottom element o the lattice so that we can perform a bottom-up search for a more compressed hypothesis. 
\item \textbf{Induction}: We search for a more compressed hypothesis that will subsume $Kernel(B, e)$. It will search for a more general hypothesis that will have the same example coverage, but will be more general / compressed. This hypothesis is also known as one that has been derived by Kernel Set Subsumption (KSS).
\item Add hypothesis $h$ to $B$ (i.e. $B = B \cup H$) and remove \textit{all} cover from $E^+$ (i.e. $E^+ = \{e \ in E^+\ |\ B \not\models e\}$).
\item If $E^+$ is non-empty, continue back at step (1).
\end{enumerate}

\section{Top-directed Abductive Learning}

\paragraph{} In this section we will look at a more recent class of logic-based learning that can cover the learning of normal logic programs with negation as failure\footnote{Not just definite logic programs.}. This class of learning approaches is called \textit{meta-level learning}, characterised by the following:

\begin{itemize}
\item Mode declarations\footnote{See section \ref{sec:LanguageBias}} are represented as a "meta-level" top-theory, not just predicate statements: We want to also learn the mode declarations; and,
\item Learning task is computed by means of an inference procedure on the background knowledge extended with this meta-level top-theory.
\end{itemize}

\paragraph{} The idea of a top-directed learning approach is that the language bias is not expressed as meta-logical statements to guide the search but as a logic itself, hence called top-theory. The computation of a hypothesis that conforms with the give language bias is given by an inference process over this top-theory together with the given background knowledge.

\subsection{TopLog}

\paragraph{} For example, consider the following mode declarations (head and body):

\begin{lstlisting}
modeh(1, penguin(+any))
modeb(*, can(+any, #ability))
\end{lstlisting}

\noindent We first add labels to each of the declarations:

\begin{lstlisting}
m1: modeh(penguin(+any))
m2: modeb(can(+any, #ability))
\end{lstlisting}

\noindent Then from the mode declarations, we can construct the top logic $T$ as such:

\[\footnotesize
T = \begin{cases}
T_1: penguin(X) \leftarrow \$body(X)\\
T_2: \$body(X) \leftarrow\\
T_3: \$body(X) \leftarrow can(X, C), ability(C), \$body(X).
\end{cases}
\]

\paragraph{} Each head mode declaration (i.e. $modeh$) becomes the head of the "start" clause of the top theory in $T$. Non-terminal predicate is used in the body of this first clause, written as $\$body(\dots)$ predicate - a place holder for the possible body construction for the clause.

\paragraph{} The non-terminal predicate $\$body(\dots)$ is then the head of the remaining clauses in $T$, where there is a base case of $\$body(\dots) \leftarrow$ and for each body mode declaration (i.e. $modeb$) is represented as in the body of a recursive clause in $T$ with the non-terminal predicate as the head of that clause.

\paragraph{} In the example above, the predicate $ability(C)$ in $T_3$ of $T$ was added to enforce the type of the arguments in the predicate $can$.

\paragraph{} The TopLog algorithm, proposed by Muggleton at ICLP 2008, considers a $e \in E^+$ and constructs an SLD derivation of $e$ from $B \cup T$. From the multiple hypotheses extracted, a coverage score is calculated for each of these hypotheses by:

$$score(h) = |\{e^+  | B \cup h \models e^+\}| - |\{e^- | B \cup h \models e^-\}|$$

\paragraph{} The coverage score awards on coverage on positive examples and penalizes on coverage of negative examples. The hypothesis of the highest score would be returned as the best hypothesis from the learning task.

\paragraph{} The use of a top-theory allows the computation of hypothesis directly from the positive examples and background knowldge, There is no longer a need to generate a bottom clause first to constraint the lattice space then compute the hypothesis by generalising the bottom clause.

\paragraph{} We also could see that the use of logic program as language bias allows more expressivity compared to use of meta-logical statements. In particular, TopLog can learn recursive programs which are not computable from Progol, and hypothesis from single seed examples that are composed of more than one clause. This is also referred as multi-clause learning. 

\subsection{Limitations of TopLog}

\paragraph{} However, there are limitations to TopLog:

\begin{itemize}
\item \textbf{Limited to definite logic programs}: we saw that we could not learn negation of a body predicate, which means we could not learn normal logic programs. 
\item \textbf{Cannot learn from negative examples}: The program only considers the positive examples when building the hypotheses. The negative examples are not considered until scoring takes place. It is possible due to the incompleteness of the background knowledge, some information cannot be proved during computation because of such incompleteness. In situations like this, Toplog will lead to failure of the computation. 
\item \textbf{Computes mainly OPL}: Cannot perform NOPL.
\end{itemize}

\subsection{Abductive Logic Programs as Declarative Bias}

\paragraph{} Despite TopLog's limitations, the idea of defining language bias as a declarative program is powerful. Instead of deductive inference (as used in TopLog). taking the abductive inference over a special type of declarative top theories can enable the learning of a much wider class of hypotheses:

\begin{enumerate}[i)]
\item hypothesis about non-observed predicates
\item multi-clause hypotheses
\item recursive programs
\item normal logic programs
\end{enumerate}

\paragraph{Top-directed Abductive Learning} The use of abductive inference to search for inductive hypothesis over a top-theory declarative bias can be referred to as Top-directed Abductive Learning (TAL). The underlying idea of TAL is to use abduction to directly compute hypothesis by first transforming a given learning task into an equivalent abductive task. 

\paragraph{} In this approach, abduction is not integrated into the learning program\footnote{as seen in HAIL}, but it is the computational mechanism itself. Learning approaches that is based on this technique is referred as "meta-level" learning.

\paragraph{} In fact, what TAL proposes is a new ILP approach based on an equivalent ALP problem. The key aspect of TAL is how to conjecture a top-theory that allows the computation of abductive solutions that correspond to the inductive soltions of the original learning task compatible with the given mode declarations.

\subsection{Modes as Data Structures}

\paragraph{} The first important idea for generating an abductive top-theory is to define an injective\footnote{one-to-one} translation function that maps rules compatible with given mode declarations into a "data structure" that can be used as terms of abducibles.

\paragraph{} Each mode declaration is given a unique identifier or label so that references to the label can points back to the original mode declaration. The data structure also captures all the information given by a mode declaration and is a tuple of 4 elements.

\paragraph{} Consider the following mode declaration format whose label is $m1$: $$m1: mode(load(+type1, \#type2, -type3))$$

\noindent The structure for literal $load(X, a, Y)$ the would be: $\langle m1, [a], [X], [Y]\rangle$. This is in the format $\langle modeDec,\ const,\ inputVars,\ outputVars \rangle$.

\paragraph{} A rule that is comaptible with a given set of mode declarations can then be expressed as a sequence of such tuples, with one tuple per literal in the rule. Consider the following example mode declaration:

\[
M = \begin{cases}
m1: modeh(p(+any))\\
m2: modeb(r(+any, \#any))\\
m2: modeb(q(+any, -any))
\end{cases}
\]

\noindent The tuple representation of the clause $p(X) \leftarrow q(X, Y), r(Y, a)$ would then be given by the tuples: $\langle m1, [], [X], []\rangle, \langle m3, [], [X], [Y] \rangle, \langle m2, [a], [Y], [] \rangle$

\paragraph{Compaction} Note that as each output variable is a new variable in a rule, given the mode declarations that already specify the arity of each predicate, it is possible to further simplify the representation. 

\paragraph{} We assume that in a rule, all its distinct variables are numbered from left to right, so we can omit the list of output variables and only keep track of the input variables by maintaining the position of in the rule where that variable occurs first.

\paragraph{} The data structure that corresponds to a literal in a rule is now reduced to just a tuple of three elements. The tuple for a head predicate will always be a tuple that just contains the mode identifier,  and the list of constants and list of input variables are empty. The other tuples correspond to the body of a rule. 

\paragraph{} Using the example above, we number $X$ to be 1 and $Y$ to be 2. The corresponding compact representation would then be: $\langle m1, [], []\rangle, \langle m3, [], [1] \rangle, \langle m2, [a], [2] \rangle$

\paragraph{} To rebuild the rules, we look up the mode declarations $M$ using the labels in the tuple.

\subsection{Abductive Top-Theory}

\paragraph{} The list of tuples for a rule can be used in an abducible predicate $rule(rid, \dots)$, where $rid$ refers to the unique identifier for the rule. This predicate is essentially a meta-predicate that states the existence of a rule whose structure is captured by its term. 

\paragraph{} We can now represent the hypothesis space as an abductive top-theory that, when executed, captures the construction of hypothesis by reasoning about what can be added to a currently partial hypothesis\footnote{We refer to such a partial hypothesis as "RuleSoFar"} in order to get a solution that is complete and consistent.

\paragraph{} The generation of an abductive top-theory is an automatic process that takes in as a set of mode declarations as input. Each mode declaration is assumed to be transformed into an unground or possibly negated atom where each argument is replaced with a new variable name, regardless of the type of the argument. This is also known as variabilisation.

\paragraph{Notation Remark} The argument of the mode declaration statement is referred to as schema $s$. Its variabilisation is referred to as $s^*$. Its constant arguments, input arguments and output arguments are denoted as lists $con(s^*)$, $inp(s^*)$ and $out(s^*)$ respectively.

\paragraph{Constructing Head Mode Declarations} For each head mode declaration: $mh: modeh(sh)$, we add the following rule to our top-theory:

$$sh^* \leftarrow body(inp(sh^*), [\langle mh, con(sh^*), [] \rangle])$$


\paragraph{Constructing Body Mode Declarations} For each body mode declaration: $mb: modeh(sb)$, we add the following rule to our top-theory:

{\footnotesize
\begin{align*}
body&(InputSoFar, RuleSoFar) \leftarrow\\
& sb*,\\
& link(inp(sb*), InputSoFar, Links),\\
& append(RuleSoFar, \langle mb, con(sb^*), Links\rangle, NewRule),\\
& append(InputSoFar, out(sb^*), newInputs),\\
& body(NewInputs, NewRule)\\
\\
body&(InputSoFar, RuleSoFar) \leftarrow rule(RuleSoFar)
\end{align*}
}

\paragraph{} The utility predicate $link/3$ is defined as follows:

\begin{align*}
link&([H|T], InpList, [N|TN]) \leftarrow\\
& nth1(N, H, InpList),\\
& link(T, InpList, TN)\\
\\
link&([], List, [])
\end{align*}

\subsection{TAL Algorithm}

\paragraph{} A TAL learning task $\langle E, B, M, IC\rangle$ where $E$ is the set of examples, $B$ is the background knowledge, $M$ is the mode declarations and $IC$ is the set of integrity constraints. The output will be a hypothesis. The algorithm is as follows:

\begin{align*}
T_M &= \text{Preprocessing}(E, B, M)\\
\Delta &= \text{Abduce}(B \cup T_M, \{rule(.)\}, IC) \text{ with goal }E\\
H &= \text{Postprocessing}(\Delta, M)
\end{align*}

\paragraph{Step 1} The first step generates an abductive top-theory from the given mode declarations. Once the $T_M$ top-theory has been generated, this can be seen as an abductive theory as it will include a predicate $rule(\dots)$ that is yet to be defined. Deductive inference would fail if applied to this theory. This is one of the main differences between a top-theory in the TopLog approach vs a top-theory in TAL.

\paragraph{Step 2} The second step performs a pure abductive inference. The background knowledge for the abductive reasoning is $B \cup T_M$ and it is used to infer predicates that may appear in the body of the hypothesis, similar to the case of inverse entailment. The step can be considered as: $$B \cup T_M \cup \Delta \vdash_\text{abductive} E$$

\paragraph{} In NOPL, the first rule of the top-theory will only be considered once some resolution steps have been applied between the examples and $B$. The non-observed predicate has been reached as unknown predicate that has to be learned.

\paragraph{} The set of abducibles of this task is given by all possible ground instances of the atom $rule(\dots)$. The set of integrity constraints is the same set that might appear already on the given initial  learning task. The goal of the abductive inference is the entire set of examples, where negative examples are written as negated literals.

\paragraph{} All the examples are considered in one go, because the learning being non-monotonic, TAL cannot use the usual covering-loop mechanism we saw in Progol and HAIL. The final abductive answer (or alternative answers) will explain all given positive example and non of the negative examples (taken in their positive form). No generalisation step is required for this approach.

\paragraph{Step 3} In the final step, we apply the inverse transformation to the abductive answer $\Delta$ and generate the corresponding hypothesis. $\Delta$ can be a set of abduced facts of type $rule(\dots)$. This will correspond to a hypothesis having multiple clauses. Alternative $\Delta$s could be computed, which means that the learning task may have alternative inductive solutions.

\section{Stable Model Semantics}

\subsection{Definitions}

\paragraph{} A Normal Logic Program is set of rules / clauses, where each rule $R$ is in the form

\begin{lstlisting}
h :- b1, ..., bn, not c1, ..., not cm.
\end{lstlisting}

\noindent ... where $h$, $b_i$ and $c_i$ are all atoms. We define 

\begin{itemize}
\item $head(R) = h$
\item $body^+(R) = \{ b_1, ..., b_n \}$
\item $body^-(R) = \{ c_1, ..., c_m \}$
\end{itemize}

\paragraph{} For convenience, I define $body(R) = body^+(R) \cup body^-(R)$ to be the set of all atoms in the body of the clause.

\subsection{Prolog and Negation}

\paragraph{} Consider the following program:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} What should Prolog return if queried "$p$"? While Prolog will loop infinitely, there are in fact multiple answers to the query. The value of p depends on q and the value of q depends on p. The stable model semantics\cite{gelfond88} is a different approach to solving normal logic programs. Instead of providing solutions to specific queries, the stable model semantics defines the set of "stable" models of the program. we will see that the example program above has the stable models $\{p\}$ and $\{q\}$.

\subsection{Grounding}

\paragraph{} The solving any normal logic program is to first ground the logic program. For any program $P$ with function symbols, there are infinitely many ground instances of each rule in $P$ (consider function symbol compositions and there can be infinitely many different compositions). We write $ground(P)$ to refer to the grounding of logic program $P$.

\paragraph{} Most of these grounding instances of each rule may be redundant instances whose bodies could never be satisfied. ASP solvers do not generate these redundant rules.

\subsection{Safety}

\paragraph{} In Prolog, floundering (see section \ref{sec:NormalClausalLogic}) is a problem because negative literals may contain a variable which is only ground by a positive literal occurring later in the body of the rule. Recall that in Prolog, rule evaluation is ordered top to bottom and left to right. For example, the following logic program flounders in Prolog as $X$ and $Y$ only gets instantiated in $r(X, Y)$, which happens after $not\ q(X, Y)$:

\begin{lstlisting}
p(X) :- not q(X, Y), r(X, Y).
r(a, b).
\end{lstlisting}

\paragraph{} ASP does not consider the ordering of the literals in a rule and hence safety is less of a problem in ASP.  However, ASP needs to ground the entire program and another form of safety is needed. ASP Solvers are restricted to working with "safe" rules only.

\begin{defn}\label{defn:SafeRule}
A rule $R$ is safe, if every variable in $R$ occurs in at least one atom in $body^+(R)$. 
\end{defn}

\paragraph{} Considering Definition \ref{defn:SafeRule}, take a look at the following examples:

\begin{itemize}
\item \lstinline{p(Z) :- not q(X, Y), r(X, Y).} - This rule is unsafe because the variable $Z$ does not occur in any of the atoms in $body^+(R)$.
\item \lstinline{p(X) :- not q(X, Y), r(X, Y).} - This rule is safe.
\item \lstinline{p(Y) :- not q(X, Y), r(Y, Y).} - This rule is unsafe because the variable $X$ does not occur in any of the atoms in $body^+(R)$.
\end{itemize}

\paragraph{} Nonetheless, in ASP even when we restrict to safe rules, for some logic program $P$, $ground(P)$ can still be infinite. For example:

\begin{lstlisting}
p(f(X)) :- p(X).
p(1).
\end{lstlisting}

\subsection{Herbrand Theory}

\subsubsection{Definite Logic Programs}

\paragraph{} For a \textbf{definite logic program} $P$, a Herbrand Interpretation $I$ of $P$ is an Herbrand Model if for all rule $R$ st

\begin{itemize}
\item each atom in $body^+(R)$ is true in $I$
\item each atom in $body^-(R)$ is false in $I$
\item $head(R)$ is true in $I$
\end{itemize}

\paragraph{} We can construct the Least Herbrand Model for a definite logic program $P$, denoted $M(P)$ by starting with the empty set $M = {}$. We then repeatedly add any atom $h$ to $M$M st $h$ is the head of a rule $R$ whose body is a subset of $M$, i.e. we add $head(R)$ to $M$ if $body(R) \subseteq M$. \textit{For definite programs with no loops, this is the same as what is provable using Prolog.}

\subsubsection{Normal Logic Programs}

\paragraph{} However when it comes to \textbf{normal logic programs}, generally there is no Least Herbrand Model. Consider the following example:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} The set of Herbrand Interpretations is $\{\emptyset, \{p\}, \{q\}, \{p ,q\}\}$.

\begin{itemize}
\item In the case of $HI = \emptyset$, it does not satisfy the program since both $not\ p$ and $not\ q$ are satisfied but their heads $q$ and $p$ respectively are not satisfied. 
\item In the case of $HI = \{p\}$, it satisfies the the program and is a Herbrand model of the program.
\item In the case of $HI = \{q\}$, it satisfies the the program and is a Herbrand model of the program.
\item In the case of $HI = \{p, q\}$, it satisfies the the program and is a Herbrand model of the program. However because the earlier two HIs are subsets of this HI, this is not a minimal Herbrand Model.
\end{itemize}

\paragraph{} Hence, instead of having just one Least Herbrand Model, the program has both $\{p\}$ and $\{q\}$ as two Minimal Herbrand Models of the program.

\subsubsection{Supportability}

\paragraph{} Consider the program: \lstinline{p :- not p.}

\paragraph{} The program has the set of Herbrand Interpretations: $\{\emptyset, \{p\}\}$. The $\emptyset$ HI does not satisfy the program while $\{p\}$ does, which makes it the Least Herbrand Model. However, the LHM $\{p\}$ is unsupported because $p$ has no support: it is not a head of any clauses in the program whose body is true in the Herbrand Model. In fact, there are no stable models of this program.

\begin{defn}A Herbrand Model $M(P)$ for a normal logic program $P$ is supported iff every atom $a \in M(P)$ is the head of a clause in $P$ those body $body(R)$ is also true in $M(P)$, i.e. $body(R) \subseteq M(P)$. \end{defn}

\subsection{Reduct}

\begin{defn}The \textbf{reduct} of any ground normal logic program $P$, i.e. $ground(P)$, with respect to any set of atoms $X$ is constructed in two steps:\end{defn}

\begin{enumerate}
\item Remove any rule from $P$ whose body contains negation as failure of an atom in $X$. i.e. we remove rule $R$ from $P$ where $a \in X: not\ a \in body(R)$.
\item Remove any negation as failure atoms from the remaining rules in $P$.
\end{enumerate}

\paragraph{} The remaining logic program is the reduct of $P$ with respect to $X$, written $P^X$. Suppose $X = \{p\}$ and $P$ is the logic program:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} The result $P^X$ would be $\{p\}$. This process can be thought as making a guess to see if an interpretation $X$ may be an Answer Set, then assuming the Answer Set to be true while interpreting negation as failure in the program. If a logic program contains variables, the program needs to be grounded first before we can find the reduct. We represent the reduct of the ground of program $P$ with respect to $X$ as $ground(P)^X$.

\subsection{Stable Model}

\begin{defn}An interpretation $X$ is a \textbf{stable model} of a normal logic program $P$ iff $X$ is the Least Herbrand Model of $ground(P)^X$, i.e. $X \equiv M(ground(P)^X)$.\end{defn}

\paragraph{} Consider the following logic program and an interpretation $X = \{p\}$:

\begin{lstlisting}
p :- not q.
q :- not p.
\end{lstlisting}

\paragraph{} Since $P^X = M(P^X) = \{p\} = X$, $X$ is a stable model of $P$. Likewise if we take the interpretation $X = \{q\}$, we will find that $\{q\}$ is also a stable model of $P$. This means that different interpretations may result in different reducts for the same logic program.

\begin{defn}An \textit{Answer Set} is a stable model of normal logic program.\end{defn}

\subsection{Answer Set Programming}

\paragraph{} The Answer Set Programming paradigm is to translate the problem we want to solve into an Answer Set program st when we solve the program for Answer Sets, these Answer Sets can be translated back as solutions to the original problem. For example, we translate the rules of the Sudoku game into an ASP representation of the game. We then are able to find the Answer Sets, which can be then mapped back as solutions of the game itself.

\section{Extended Constructs in ASP}\label{sec:ASPExtendedConstructs}

\subsection{Constraints}

\paragraph{} Constraints are a way of filtering any unwanted Answer Sets. They are written as normal clauses with an empty head, e.g. \lstinline{:- b1, ..., bn, not c1, ..., not cm}. The empty head represents falsity $\perp$. When we compute the reduct of such program, rules with empty head will have their heads are replaced with $\perp$. 

\paragraph{} $\perp$ can never be in an Answer Set. Hence any interpretations that satisfy the body of a constraint would end up having $\perp$ in the result, which eliminates the interpretation as an Answer Set. For example:

\begin{lstlisting}
p :- not q.
q :- not p.
:- p, not q.
\end{lstlisting}

\paragraph{} The constraint in the above program eliminates the interpretation $X = \{p\}$ as an answer set. In other words, an Answer Set does not satisfy the body of all constraints in a logic program.

\subsection{Choice Rules}\label{sec:ASPChoiceRules}

\begin{defn}A \textbf{choice rule} is a rule in an ASP program where a \textit{counting aggregate} is allowed to appear in the head of a rule.\end{defn}

\paragraph{} A counting aggregate $a\ \{ h_1, h_2, ..., h_n \}\ b$ is satisfied by an interpretation $X$ if $$a \leq |\{h_1, h_2, ..., h_n \} \cap X| \leq b$$

\paragraph{} For example, the rule 

\begin{lstlisting}
1 {value(C, h), value(C, t)} 1 :- coin(C).
\end{lstlisting}

expresses that every coin $C$ must either take the value "h" or "t" (but not both, since $b = 1$).

\paragraph{Semantics} We compute the Answer Sets of a logic program $P$ containing choice rules by inserting an additional step into the computation process of reduct $P^X$. For each rule $R$ that is a choice rule:

\begin{enumerate}
\item If the aggregate is not satisfied by $X$, we convert $R$ into a constraint by replacing the head with $\perp$.
\item If the aggregate is satisifed by $X$, we generate one rule for each atom $A$ in the aggregate which is also in $X$, with $A$ at the head.
\end{enumerate}

\paragraph{} For example, consider the following program $P$ with the interpretation $X = \{p, q, r\}$:

\begin{lstlisting}
1 {p, q} 1 :- r.
r.
\end{lstlisting}

\paragraph{} Since $| \{ p, q \} \cup X | \geq 1$, we compute the reduct $P^X$ of the program by replacing the head with $\perp$:

\begin{lstlisting}[mathescape=true]
$\perp$ :- r.
r.
\end{lstlisting}

\paragraph{} Alternatively, we consider the slightly modified program $P'$ below with the same interpretation $X = \{p, q, r\}$:

\begin{lstlisting}
1 {p, q} 2 :- r.
r.
\end{lstlisting}

\paragraph{} Now that $| \{ p, q \} \cup X | = 2$, we can compute the reduct $P^X$ of the program to be as such:

\begin{lstlisting}
p :- r.
q :- r.
r.
\end{lstlisting}

\subsection{Optimisation Statements}

\paragraph{} It is possible set up an ASP program to give an ordering over Answer Sets to specify which Answer Sets are preferred over others. Finding optimal Answer Sets of a ASP program can be done by adding optimisation statements like this:

\begin{lstlisting}[mathescape=true]
#minimize [ $a_1$ = $w_1$, ..., $a_n$ = $w_n$ ].
\end{lstlisting}

\paragraph{} The above statement\footnote{Note the Non-British spelling of minimise.} assigns weights $w_i$ to its corresponding literal $a_i$. The weight of each Answer Set is summed from the weights assigned to each atom in the Answer Set. In the statement above, the optimal Answer Set has the lowest weight. It is also possible to find Answer Sets that has the greatest weight by using \#maximize instead:

\begin{lstlisting}[mathescape=true]
#maximize [ $a_1$ = $w_1$, ..., $a_n$ = $w_n$ ].
\end{lstlisting}

\section{Brave and Cautious Entailment}

\subsection{Induction for Definite Programs}

\paragraph{} For a definite program $P$, since there is always a unique LHM (written $M(P)$), entailment is defined in terms of this LHM. The task of ILP is therefore to find a hypothesis $H$ st $M(B \cup H)$ contains all of a set of positive examples and none of a set of negative examples. There are two different kind of entailments: \textit{brave} and \textit{cautious}. 

\subsection{Brave Induction}
\paragraph{} An atom $A$ is bravely entailed by a program $P$ if it is true in \textbf{at least one stable model} of $P$ (written $P \models_b A$).

\paragraph{} Based on the semantics of brave entailment, we can construct the concept of Brave Induction  \cite{sakama08}. Given a Brave ILP (denoted $\text{ILP}_\text{B}$) task as the tuple $<B, E^+, E^->$, we want to search for a hypothesis $H$ st $B \cup H$ has \textbf{at least one Answer Set} which contains all of the positive examples and none of the negative examples i.e. $\exists A$ of $B \cup H$ st $\forall e^+ \in E^+: e^+ \in A$ and $\forall e^- \in E^-: e^- \not\in A$. We can also write it as:

$$B \cup H \models_b (e_1^+ \land ... \land e_n^+ \land \text{not}\ e_1^- \land ...  \land \text{not}\ e_m^-)$$

\subsection{Limitations of Brave Induction}\label{sec:BraveInductionLimitations}

\paragraph{} Some hypotheses cannot be learned from using Brave Induction alone. For example, brave induction cannot be used to learn any hypothesis which only rules out Answer Sets and does not generate anything new.

\paragraph{} In particular, a brave ILP task will never have, as an optimal solution, a hypothesis containing a constraint. If the hypothesis is a solution for the brave ILP task, it must have at least one Answer Set that contains all of the positive examples and none of the negative examples. As constraints only rule out Answer Sets, this Answer Sets will still be an Answer Set of the program without the constraint.

\subsection{Cautious Induction}
\paragraph{} An atom $A$ is cautiously entailed by a program $P$ if it is true in \textbf{all stable models} of $P$ (written $P \models_c A$).

\paragraph{} Based on the semantics of cautious entailment, we can construct the concept of Cautious Induction  \cite{sakama08}. Given a Cautious ILP (denoted $\text{ILP}_\text{C}$) task as the tuple $<B, E^+, E^->$, we want to search for a hypothesis $H$ st $B \cup H$ has at least one Answer Set and \textbf{all of its Answer Sets} contain all of the positive examples and none of the negative examples i.e. $\forall A$ of $B \cup H$ st $\forall e^+ \in E^+: e^+ \in A$ and $\forall e^- \in E^-: e^- \not\in A$. We can also write it as:

$$B \cup H \models_c (e_1^+ \land ... \land e_n^+ \land \text{not}\ e_1^- \land ...  \land \text{not}\ e_m^-)$$

\subsection{Limitations of Cautious Induction}

\paragraph{} Consider an empty background knowledge $B$, we cannot construct a set of examples st any of the shortest hypotheses are:

\begin{lstlisting}
1 {value(C, h), value(C, t)} 1 :- coin(C).
coin(c1).
\end{lstlisting}

\paragraph{} The only atom that is true in all Answer Sets of the program that we are trying to learn would be $coin(c1)$. Neither atoms $value(c1, heads)$ nor $value(c1, tails)$ is false in all Answer Sets. Hence this would cause us to learn only $coin(c1)$. This is not what we are aiing for as we want to learn a program with two distinct Answer Sets, which corresponds to the coin $c1$ being $heads$ or $tails$. Cautious entailment of all examples in such a case may be a requirement that is too strong. Hence, in such situation, a Brave ILP learning task would be able to give what is true in some Answer Sets but not all Answer Sets of the learned program.

\section{ASP Abductive Learning}

\paragraph{} Using ASP, we can perform abductive learning (hence ASPAL) by using the extended constructs in ASP as described in Section \ref{sec:ASPExtendedConstructs}. 

\subsection{Skeleton Rules}

\paragraph{} A skeleton rule for the mode declaration $<M_h, M_b>$ is a compatible rule where all constant placemarkers are replaced with different variables instead of constants. For example, consider the following mode declarations:

\begin{lstlisting}
modeh(1, penguin(+bird)).
modeb(2, not can(+bird, #ability)).

bird(a).
bird(b).
ability(fly).
ability(swim).
can(a, fly).
can(b, swim).
\end{lstlisting}

\paragraph{} For every variable, ASPAL will add the type of the variable to the body of the rule. In he case of $penguin(+bird)$, $bird(V1)$ is added to the body of the rule. This enforces that the rules only apply to terms of these types and will also mean that ASPAP would not need to worry about the safety of the rules. All variables will certainly appear in at least one positive literal in the body of the rule. The rule  \lstinline{penguin(V1) :- bird(V1), not can(V1, C1).} represents:

\begin{lstlisting}
penguin(V1) :- bird(V1), not can(V1, fly).
penguin(V1) :- bird(V1), not can(V1, swim).
\end{lstlisting}

\paragraph{} By using skeleton rules where the constant symbols are not yet ground, ASPAL leaves the task of finding the grounding to the ASP solver. Each skeleton rule represents a set of rules where the constant-representative variables have been replaced with constants of the correct type.

\subsection{Limits}

To limit the the hypothesis search space, we introduce two constraints in addition to the given mode declarations: $L_\text{max}$ specifies the number of literals allowed to appear in the body of the rule and $V_\text{max}$ specifies the number of unique variables allowed in the rule.

\paragraph{} ASPAL constructs a set of skeleton rules $S_M$ - we call this set the hypothesis space. $S_M$ is maximal given language constraints $<M_h, M_b>, L_\text{max}, V_\text{max}$ if any rule which can be constructed respecting the constraints is equivalent to a rule already in $S_M$. We need to maximize this hypothesis space because we want to include all possible rules allowed by the language constraints, before we later prune off inconsistent instances of the skeleton rules later using a choice rule.

\paragraph{} Constants replaced with variables do not count towards the $V_\text{max}$ limit. \cite[p. 6]{lawnonmonotonic} The constant "variables" in skeleton rules should be considered as placeholders for constants rather than real variables that count towards $V_\text{max}$.

\subsection{Hypothesis Space}\label{sec:ASPALHypothesisSpace}

\paragraph{} Given the following background knowledge $B$:

\begin{lstlisting}
bird(a).
bird(b).
ability(fly).
ability(swim).
can(a, fly).
can(b, swim).
\end{lstlisting}

\paragraph{} and given the following set of skeleton rules $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1).
penguin(V1) :- bird(V1), not can(V1, C1).
penguin(V1) :- bird(V1), not can(V1, C1), not can (V2, C2).
\end{lstlisting}

\paragraph{} The following is the list of all possible rules that are represented by $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1).
penguin(V1) :- bird(V1), not can(V1, fly).
penguin(V1) :- bird(V1), not can(V1, swim).
penguin(V1) :- bird(V1), not can(V1, fly), not can(V1, swim).
\end{lstlisting}

\subsection{ASP Encoding}

\subsubsection{Rule Encoding}

\paragraph{} ASPAL encodes an ILP task as a meta level ASP program. The Answer Sets would contain atoms that represent each of the rules in the hypothesis. To help us map the Answer Set of the meta level program back to an inductive solution of the ILP task, we assign a unique rule identifier $R_\text{ID}$ to each skeleton rule in $S_M$. The atom $rule(R_\text{ID}, c_1, ..., c_n)$ represents the skeleton rule $R$ with each constant variables replaced with constants $c_1, ..., c_n$.

\paragraph{} We can then use the choice rule (See Section \ref{sec:ASPChoiceRules}) on the set of rules and the combination of constants to let the ASP solver help us find the solutions to the ILP task.

\paragraph{} Considering the penguin example in Section \ref{sec:ASPALHypothesisSpace}, we can add the rule atom to each of the rules in $S_M$:

\begin{lstlisting}
penguin(V1) :- bird(V1), rule(1).
penguin(V1) :- bird(V1), not can(V1, C1), rule(2, C1).
penguin(V1) :- bird(V1), not can(V1, C1), not can (V2, C2), rule(3, C1, C2).
\end{lstlisting}

\paragraph{} The choice rule below causes one Answer Set to be generated for each set of rules (i.e. each hypothesis):

\begin{lstlisting}
{ rule(1), rule(2, fly), rule(2, swim), rule(3, fly, swim) }.
\end{lstlisting}

\paragraph{} The rule atoms that appear in the Answer Sets represent the hypothesis. 

\subsubsection{Example Encoding}

\paragraph{} To rule out any Answer Set of the meta program which corresponds to an Answer Set of $B \cup H$ which either 1) does not contain all of the positive examples or 2) contains one or more negative examples, we add the goal rule and its constraint to the program:

\begin{lstlisting}
goal :- e1+, ..., en+, e1-, ..., em-.
:- not goal.
\end{lstlisting}

\paragraph{} The result of this is that Answer Sets of the meta program will correspond exactly to the inductive solutions of the ILP task. 

\subsection{Optimization}

\paragraph{} ASLAP uses an optimisation statement st the optimal Answer Sets of the meta level program will correspond exactly to the optimally inductive solutions of the task. We can do this using the \lstinline{#minimize} statement in ASP (See Section \ref{sec:ASPExtendedConstructs}) and by weighing each of the rules by its length:

\begin{lstlisting}
#minimize[rule(1, c1, ..., cn) = Rlen, ...].
\end{lstlisting}

\paragraph{} We define the length of the rule to be the number of literals in the rule (including the head) excluding type enforcement literals.

\section{Learning from Answer Sets}

\paragraph{} Many other applications can be solved with brave induction alone. However as shown in the limitations of Brave Induction in Section \ref{sec:BraveInductionLimitations}, there are programs which cannot be learned with solvely brave or cautious induction. One such problem is to learn the rules of sudoku. Learning from Answer Sets (LAS) can be used to learn such programs\cite{law14}.

\subsection{Partial Interpretation}

\paragraph{} A partial interpretation $e$ is a pair of sets of atoms $\langle e^\text{inc}, e^\text{exc}\rangle $. $e^\text{inc}$ is the set of \textit{inclusions} and $e^\text{exc}$ is the set of \textit{exclusions}.

\paragraph{} A Herbrand Interpretation $I$ extends a partial interpretation $e$ iff $e^\text{inc} \subseteq I$ and $e^\text{exc} \cap I = \emptyset$.

\paragraph{} For example: sets $\{p, q\}$ and $\{p, q, s\}$ extend $\langle \{p, q\}, \{r\} \rangle$ but not neither $\{p\}$ nor $\{p, q, r\}$ do. In LAS, examples are covered if there exists an Answer Set of $B \cup H$ which extends the example (as a partial interpretation).

\subsection{Learning}

\paragraph{} A LAS task is a tuple $\langle B, S_M, E^+, E^- \rangle$. Unlike ASPAL and similar systems, as LAS is aimed at learning ASP rather than Prolog, LAS has no concept of input and output variables. The only restriction is that the rules in $S_M$ are safe. 

\paragraph{} A hypothesis $H$ is an inductive solution, written $H \in \text{ILP}_\text{LAS}\langle B, S_M, B^+, B^- \rangle$, iff it is constructed from the rules in $S_M$ (i.e. $H \subseteq S_M$) and each positive example is extended by at least one Answer Set of $B \cup H$ (this can be different Answer Set for each positive example) and none of the negative examples are extended by any Answer Set of $B \cup H$. Formally,

\begin{itemize}
\item $\forall e \in E^+: \exists A \in AS(B \cup H)\ \text{st}\ A\ \text{extends}\ e$
\item $\forall e \in E^-: \forall A \in AS(B \cup H)\ \text{st}\ \lnot(A\ \text{extends}\ e)$
\end{itemize}

\paragraph{} Consider the following $\text{ILP}_\text{LAS}$ task. Given the background knowledge $B$:

\begin{lstlisting}
coin(C) :- biased_coin(C).
biased_coin(c1).
coin(c2).
\end{lstlisting}

\paragraph{} and given the following positive examples:

\begin{lstlisting}
<{value(c1, tails), value(c2, heads)}, {}>
\end{lstlisting}

\paragraph{} and given the following negative examples:

\begin{lstlisting}
<{}, {value(c2, heads), value(c2, tails)}>
<{value(c2, heads), value(c2, tails)}, {}>
<{}, {value(c1, tails)}>
\end{lstlisting}

\paragraph{} The positive example says that there must be at least one Answer Set of $B \cup H$ that contains both \lstinline{value(c1, tails)} and \lstinline{value(c2, heads)}. This example on its own is satisfied by the choice rule 

\begin{lstlisting}
1 { value(C, heads), value(C, tails) } 1 :- coin(C).
\end{lstlisting}

\paragraph{} in the hypothesis $H$. However, we can also allow hypotheses which place less restrictive bounds on the aggregate, for example:

\begin{lstlisting}
0 { value(C, heads), value(C, tails) } 2 :- coin(C).
\end{lstlisting}

\paragraph{} Nonetheless if we look at the negative examples, we realise hypotheses that as less restrictive bounds on the aggregate would cover some of the negative examples. The first negative example, says that no Answer Set is allowed to contain neither of \lstinline{value(c2, tails)} and \lstinline{value(c2, heads)} and the second negative example says that no answer is allowed to contain both of them. 

\paragraph{} The third negative example says that no Answer Set is allowed to not contain \lstinline{value(c1, tails)}. One way of ensuring this is to add the constraint

\begin{lstlisting}
:- value(C, heads), biased_coin(C).
\end{lstlisting}

\subsection{Relation to Brave Induction}

\paragraph{} A Brave ILP Task $\text{ILP}_b\langle B, E^+, E^-\rangle$ is satisfied by a hypothesis $H$ iff there is at least one Answer Set of $B \cup H$ which includes all of the positive examples $E^+$ and none of the negative examples $E^-$.

\paragraph{} This is equivalent to there being an Answer Set of $B \cup H$ which extends the partial interpretation $\langle E^+, E^-\rangle$, which is in turn equivalent to $H$ being an inductive solution of a LAS task $\text{ILP}_\text{LAS} \langle B, \{\langle E^+, E^- \rangle\}, \emptyset\rangle$ with a single positive example $\langle E^+, E^-\rangle$.

\subsection{Relation to Cautious Induction}

\paragraph{} A Cautious ILP task $\text{ILP}_c\langle B, E^+, E^-\rangle$ is satisfied by a hypothesis $H$ iff $B \cup H$ has at least one Answer Set and every Answer Set of $B \cup H$ includes all of the positive examples $E^+$ and none of the negative examples $E^-$.

\paragraph{} This is equivalent to there being no Answer Set of $B \cup H$ which contains any negative example and for each positive example, no Answer Set of $B \cup H$ which does not contain that example.

\paragraph{} It can also the same as $B \cup H$ having no Answer Set which extends any of the partial interpretations $\langle \emptyset, e^+_1\rangle, ..., \langle \emptyset, e^+_n\rangle, \langle e^-_1, \emptyset\rangle, ..., \langle e^-_m, \emptyset\rangle$ and having at least one Answer Set which extends $\langle \emptyset, \emptyset \rangle$. This is equivalent to $H$ being an inductive solution of a LAS task:

$$\text{ILP}_\text{LAS} \langle B, \{\langle \emptyset, \emptyset \rangle\}, \{\langle \emptyset, e^+_1\rangle, ..., \langle \emptyset, e^+_n\rangle, \langle e^-_1, \emptyset\rangle, ..., \langle e^-_m, \emptyset\rangle\}\rangle$$

\section{Meta-Interpretive Learning of Grammars}

\paragraph{} State-of-art ILP systems cannot learn grammar because they are fail to learn recursions and invent new predicates as needed. We now look at the Meta-Interpretive Learning (MIL) framework\cite{muggleton13} that enables this.

\subsection{Parity Example}

\paragraph{} We look at the rules for a even parity example on accepting or rejecting an input. The following shows the Finite State Maching (FSM) diagram of the finite acceptor:

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{graphics/mil-parity-fsm.png}
\caption{The finite acceptor of the parity example with two states, $q_0$ and $q_1$. The system starts at the $q_0$ and the double circle means that the system must end at the state $q_0$ for it to be valid.}
\end{figure}

The Definite Clause Grammar of the even parity example can be written down as:

\begin{align*}
q_0([], []) &\leftarrow\\
q_0([0|A], B) &\leftarrow q_0(A, B)\\
q_0([1|A], B) &\leftarrow q_1(A, B)\\
q_1([0|A], B) &\leftarrow q_1(A, B)\\
q_1([1|A], B) &\leftarrow q_0(A, B)\\
\end{align*}

\paragraph{} Some positive examples can include: $\lambda, 0, 11, 00, 101$, where $\lambda$ represents the empty string. We notice that we can build a general form of DCG as such:

\begin{align*}
Q([], []) &\leftarrow\\
Q([C|x],y) &\leftarrow P(X, Y)
\end{align*}

\paragraph{} We can perform predicate invention using a higher-order abduction. Suppose we build a meta-interpreter for the regular grammar of parity bit as follows:

\begin{align*}
parse(S) \leftarrow\ &parse(q0, S, []).\\
parse(Q, [], []) \leftarrow\ &acceptor(Q).\\
parse(Q, [C|X], Y) \leftarrow\ &delta1(Q, C, P),\\ &parse(P, X, Y).
\end{align*}

\paragraph{} This is also a Meta-Interpreter for Regular Languages.

\subsection{MIL Setting}

\paragraph{} The input of learning task is a tuple $\langle B, E\rangle$ where $B = \langle B_M, B_A \rangle$ where $B_M$ is the Meta-Interpreter and $B_A$ is the Atomic background knowledge. $E = \langle E^+, E^- \rangle$ are the sets of positive and negative examples respectively. A hypothesis $H \in \mathcal{H}_{B,E}$ is a set of higher-order $\exists$-quantified Datalog atoms st $B, H \models E^+$ and $B, E^-$ consistent.

\paragraph{} We apply inverse entailment $B, \lnot E^+ \models \lnot H$, where $\lnot E^+$ and $\lnot H$ are $\forall$-quantified denials.

\paragraph{} For the parity example, we construct the following examples:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | l | }

\hline
$E^+$ & $\lnot E^+$ & $E^-$ \\
\hline

$parse([]) \leftarrow$ & $\leftarrow parse([]),$ & $\leftarrow parse([1])$ \\
$parse([1, 1]) \leftarrow$ & $parse([1, 1]),$ & $\leftarrow parse([0, 1])$ \\
$parse([0, 1, 1]) \leftarrow$ & $parse([0, 1, 1]),$ & $\leftarrow parse([1, 0])$ \\
$parse([1, 0, 1]) \leftarrow$ & $parse([1, 0, 1]),$ & $\leftarrow parse([0, 0, 1])$ \\
$parse([1, 1, 0]) \leftarrow$ & $parse([1, 1, 0]).$ & $\leftarrow parse([1, 1, 1])$ \\

\hline
\end{tabular}
\caption{The table of MIL examples for the Parity example. The negation of $E^+$ can be seen in the second column.}
\end{table}

\subsection{Hypothesis Ordering in MIL}

\begin{defn}Within the MIL setting, we say that $H \succeq_{B,E} H'$ in the case that $H, H' \in \mathcal{H}_{B,E}$ and $\lnot H' \succeq_\theta \lnot H$.\end{defn}

\paragraph{Proposition (Lattice)} Given $\mathcal{H}_{B,E}$ and the relation $\succeq_{B,E}$, the pair $\langle \mathcal{H}_{B,E}, \succeq_{B,E} \rangle$ forms a lattice.

\paragraph{Proposition (Unique $\top$)} There exists $\top \in \mathcal{H}_{B,E}$ st $\forall H \in \mathcal{H}_{B.E}: \top \succeq_{B,E} H$ and $\top$ is unique up to renaming of Skolem constants.

\paragraph{Proposition (Unique $\perp$)} There exists $\perp \in \mathcal{H}_{B,E}$ st $\forall H \in \mathcal{H}_{B.E}: H \succeq_{B,E} \perp$ and $\perp$ is unique up to renaming of Skolem constants.

\subsection{Meta-Interpreter for Context-Free Grammars}

\paragraph{} Using the MIL setting and definitions, we build a meta-interpreter for Context-Free Grammars (CFGs) using five statements:

\begin{align*}
parse(S) \leftarrow start(Q), parse(Q, S, []).
\end{align*}

\paragraph{} The statement above begins parsing $S$ by finding a start state $Q$ and parse $S$ beginning at state $Q$. In the last argument of $parse$, we also indicate that parsing terminates at an empty list.

\begin{align*}
parse(Q, X, X) \leftarrow acceptor(Q).
\end{align*}

\paragraph{} Here we define the parsing recursive base case where $Q$ is an acceptor in the FSM and the last two arguments of $parse$ are equal.

\begin{align*}
parse(Q, [C|X], Y) \leftarrow\ &delta1(Q, C, P),\\ &parse(P, X, Y).
\end{align*}

\paragraph{} The third statement states that if $delta1(Q, C, P)$, and $C$ is at the front of list $X$, we perform $parse(P, X, Y)$. $delta1$ checks if a transition from state $Q$ to state $P$, given that $C$ is currently observed, is allowed. The last literal $parse(P, X, Y)$ simply continues to parse the rest of the list recursively from state $P$.

\begin{align*}
parse(Q, X, Y) \leftarrow\ &delta2(Q, P, C),\\ &parse(P, X, [C|Y]).
\end{align*}

\paragraph{} The fourth statement performs an accumulation of $C$ into the third parameter of $parse$ and performs the transition from state Q to P if $delta2(Q, P, C)$ holds. The accumulation is later checked at the base case to see if the ending list and accumulated list matches at the acceptor.

\begin{align*}
parse(Q, X, Y) \leftarrow\ &delta3(Q, P, R),\\ &parse(P, X, Z), parse(R, Z, Y).
\end{align*}

% TODO: discuss delta3

\subsection{Metagol${}_R$ Prolog Implementation}

\paragraph{} The following is the Metagol${}_R$ implementation in Prolog. The $R$ stands for Regular Languages.

\begin{lstlisting}
parse(S, G1, G2) :- parse(s(0), S, [], G1, G2).

parse(Q, X, X, G1, G2) :- abduce(acceptor(Q), G1, G2).
parse(Q, [C|X], Y, G1, G2) :- skolem(P), abduce(delta1(Q, C, P), G1, G3), parse(P, X, Y, G3, G2).

abduce(X, G, G) :- member(X, G).
abduce(X, G, [X|G]) :- not member(X, G).

skolem(s(0)).
skolem(s(1)).
...
\end{lstlisting}

\paragraph{} Abducible terms are simply accumulated in variables $G1$, $G2$ and $G3$. A finite set of Skolem constants is provided by the monadic predicate \lstinline{skolem/1}.

\paragraph{} To build the learn the correct state transitions, we provide a set of positive and negative examples in our query. For example in the case the Parity example:

\begin{lstlisting}
:- parse([], [], G1), parse([0], G1, G2), parse([0, 0], G2, G3), parse([1, 1], G3, G4), parse([0, 0, 0], G4, G5), parse([0, 1, 1], G5, G6), parse([1, 0, 1], G6, G), not parse([1], G, G), not parse([0, 1], G, G).
\end{lstlisting}

\paragraph{} The set of abducibles is built iteratively through each positive examples in G1, G2, ... until G, where the final set of abduciles are created. The negative examples are prefixed with $not$ to ensure that the abducibles in $G$ do not cause our answer to entail negative examples. An answer to the query would be:

\begin{lstlisting}
G = [
  delta1(s(1), 0, s(1)),
  delta1(s(1), 1, s(0)),
  delta1(s(0), 1, s(1)),
  delta1(s(0), 0, s(0)),
  acceptor(s(0))
]
\end{lstlisting}

\section{MIL of Higher-Order Dyadic Datalog}

\paragraph{Dyadic} Binary functions; functions of arity 2.

\paragraph{} In early sections of MIL, we saw how programs can learn regular languages and context free grammars. However, the program has yet to learn how to perform \textbf{predicate invention} or learn any recursion. We consider the example of family relations with the following target theory:

\begin{align*}
father(ted, bob) \leftarrow&\\
father(ted, jane) \leftarrow&\\
parent(X, Y) \leftarrow\ &mother(X, Y).\\
parent(X, Y) \leftarrow\ &father(X, Y).\\
ancestor(X, Y) \leftarrow\ &parent(X, Y).\\
ancestor(X, Y) \leftarrow\ &parent(X, Z),\\ &ancestor(Z, Y).\\
\end{align*}

\paragraph{} In the family relations theory above, we see that given the predicates $father/2$ and $mother/2$, we want to learn $parent/2$ through predicate invention and $ancestor/2$ through both predicate invention and recursion.

\subsection{Generalised Meta-Interpreter}

\paragraph{} We perform some meta-logical substitutions to have us achieve such a learning task. For example:

\begin{align*}
father(ted, bob) \leftarrow
\end{align*}

would be substituted as:

\begin{align*}
metasub(instance, [father, ted, bob]).
\end{align*}

and

\begin{align*}
p1(X, Y) \leftarrow father(X, Y).
\end{align*}

would be substituted as:

\begin{align*}
metasub(base, [p1, father]).
\end{align*}

The tail recursive substitution would then be:

\begin{align*}
ancestor(X, Y) \leftarrow\ &parent(X, Z),\\ &ancestor(Z, Y).
\end{align*}

would be substituted as:

\begin{align*}
metasub(tailrec, [ancestor, p1, ancestor]).
\end{align*}

\paragraph{} Finally, we build a generalised Meta-Interpreter as such:

\begin{lstlisting}
prove([], Prog, Prog).
prove([Atom | As], Prog1, Prog2) :-
	metarule(Name, MetaSub, (Atom :- Body), Order),
	Order,
	save_subst(metasub(Name, MetaSub), Prog1, Prog3),
	prove(Body, Prog3, Prog4),
	prove(As, Prog4, Prog2).
\end{lstlisting}

\paragraph{} The interpreter takes a base case \lstinline{prove([], Prog, Prog)} that returns the program in the third argument if there is nothing to prove.

\paragraph{} For the recursive proving rule, it performs an abduction then proves the body recursively. This allows recursive learning to happen. The substitution abducibles are saved in propagating manner through \lstinline{Prog3}, \lstinline{Prog4} and finally \lstinline{Prog2}.

\subsection{Table of Metarules}

The metarules used in the meta-interpreter are as follows:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | l | }
\hline
\textbf{Name} & \textbf{Meta-Rule} & \textbf{Order} \\
\hline
\hline

Instance & $P(X, Y) \leftarrow$ & \textit{True}\\
\hline

Base & $P(x, y) \leftarrow Q(x, y)$ & $P \succ Q$\\
\hline

Chain & $P(x, y) \leftarrow Q(x, z), R(z, y)$ & $P \succ Q, P \succ R$\\
\hline

TailRec & $P(x, y) \leftarrow Q(x, z), P(z, y)$ & $P \succ Q, x \succ z \succ q$\\
\hline
\end{tabular}
\caption{The table of Metarules used by the Meta-Interpreter.}\label{table:MILMetarules}
\end{table}

\paragraph{} The total ordering on P, Q, R and x, y, z helps interval shrinking so that the program eventually leads to a terminating state. The tail recursion introduces the danger of not terminating if ordering is not in use. From the general form of each metarule in Table \ref{table:MILMetarules}, we can define the metarule general form with quantification:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | l | }
\hline
\textbf{Name} & \textbf{Meta-Rule} & \textbf{Quantification} \\
\hline
\hline

Instance & $P(X, Y) \leftarrow$ & $\exists P, X, Y$\\
\hline

Base & $P(x, y) \leftarrow Q(x, y)$ & $\exists P\ \forall x, y$\\
\hline

Chain & $P(x, y) \leftarrow Q(x, z), R(z, y)$ & $\exists P, Q, R\ \forall x, y, z$\\
\hline

TailRec & $P(x, y) \leftarrow Q(x, z), P(z, y)$ & $\exists P, Q, R\ \forall x, y, z$\\
\hline
\end{tabular}
\caption{The table of quantification of each metarule.}\label{table:MILMetarulesQuantification}
\end{table}

\subsection{Expressivity of $H^2_2$}

\paragraph{} In the Family relations example, we consider datalog logic programs in $H^2_2$, which contain predicates of at most \textbf{2} arity and has at most \textbf{2} atoms in the body.

\paragraph{} Given an infinite signature, $H^2_2$ has Universal Turning Machine expressivity.\cite{tarnlund77}

\begin{align*}
utm(S, S) \leftarrow\ &halt(S).\\
utm(S, T) \leftarrow\ &execute(S, S1),\\ &utm(S1, T).\\
execute(S, T) \leftarrow\ &instruction(S, F),\\ &F(S, T).\\
\end{align*}

\paragraph{} But the question is, how can we limit $H^2_2$ to avoid the halting problem?

\subsection{Bias Reformulation}

\paragraph{} Consider the following computation problem:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
bob & BOB \\
alice & ?\\
\hline
\end{tabular}
\caption{Text transformation problem}\label{table:MILTextTransformation}
\end{table}

\paragraph{} Given "bob" and the correct label "BOB", how would we expect a program to learn how to give the correct answer for "alice"? One possible answer would be

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
bob & BOB \\
alice & BOICE\\
\hline
\end{tabular}
\caption{Solution 1 to the text transformation problem}\label{table:MILTextTransformation2}
\end{table}

\paragraph{} Perhaps the system should write "BO" followed by the remaining characters "ICE"? Another possible answer would be:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
bob & BOB \\
alice & ALILA\\
\hline
\end{tabular}
\caption{Solution 2 to the text transformation problem}\label{table:MILTextTransformation3}
\end{table}


\paragraph{} or perhaps the system should should consider the answer "BOB" as a capitalised reversal of "bob" and does the same for "alice", creating "ALILA" and ignoring "ce"? Intuitively to us humans, the following solution would have been what was expected:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
bob & BOB \\
alice & ALICE\\
\hline
\end{tabular}
\caption{Solution 3 to the text transformation problem}\label{table:MILTextTransformation3}
\end{table}

\paragraph{} It's obvious there are bias and intuition we picked up over the years that we cannot expect a machine to have immediately without learning them. Other harder tasks could involve:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | p{3.2cm} | l | }
\hline
Task 1 & miKe dwIGHT & Mike Dwight \\
\hline
Task 2 & European Conference on Artificial Intelligence & ECAI \\
\hline
Task 3 & My name is John. & John \\
\hline
\end{tabular}
\caption{Harder tasks of text transformation learning.}\label{table:MILTextTransformation3}
\end{table}

\paragraph{} How can this human text transformation bias be learned by a computer? Ideally we want machines to look at one positive example and would be able to start getting correct predictions.

\paragraph{Option 1} Flash Fill in Microsoft Excel 2013 (Gulwani, 2011, 2012) with a hardcoded bias as domain-specific language could learn how to extract all the names from email addresses given one example. However, there are still other non-intuitive error in Flash Fill:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
IaN RoDny & Ian Rodny \\
StaNleY TRAVis & Itanley Rley travis\\
\hline
\end{tabular}
\caption{Non-intuitive error in Flash Fill}\label{table:Flashfill}
\end{table}

\paragraph{Option 2} We learn the bias by using a variant of Meta-Interpretive Learning (presented at IJCAI 2013):

\begin{lstlisting}[mathescape=true]
ep04(A, B) $\leftarrow$ ep04_1(A, C), ep04_2(C, B).
ep04_1(A, B) $\leftarrow$ ep04_3(A, C), ep04_4(C, B).
ep04_2(A, B) $\leftarrow$ ep04_3(A, C),
	skiprest(C, B).
ep04_3(A, B) $\leftarrow$ make_uppercase(A, C),
	copyword(C, B).
ep04_4(A, B) $\leftarrow$ skip1(A, C),
	write_space(C, B).
\end{lstlisting}

\paragraph{} However, the performance of learning by MIL is not desirable. It took 9.3 seconds to learn the bias above. Those five clauses are sufficient to work on an example such as:

\begin{table}[H]
\centering\footnotesize
\begin{tabular}{ | l | l | }
\hline
brent.harold@hotmail.com & Brent Harold\\
\hline
\end{tabular}
\caption{Example of name extraction from email address.}\label{table:Flashfill}
\end{table}

\paragraph{} However there may be previously learned theory that can be re-used to speed up learning:

\begin{lstlisting}[mathescape=true]
ep02(A, B) $\leftarrow$ ep02_1(A, C), write_dot(C, B).
ep02_1(A, B) $\leftarrow$ make_upper(A, C), copyword(C, B)

ep04(A, B) $\leftarrow$ ep04_1(A, C), ep04_2(C, B).
ep04_1(A, B) $\leftarrow$ ep02_1(A, C), ep04_4(C, B).
ep04_2(A, B) $\leftarrow$ ep02_1(A, C),
	skiprest(C, B).
ep04_4(A, B) $\leftarrow$ skip1(A, C),
	write_space(C, B).
\end{lstlisting}

\paragraph{} Note in the results above, ep04\_1 and ep04\_2 could now re-use ep02\_1 instead of learning one more clauses. Episode 4 now has one less clause to learn, which brought the learning time down to 3.1 seconds.

\subsection{Language Class \& Complexity}

\paragraph{} The cardinality of hypothesis space $O(m^n p^{3n})$, given $m$ metarules, $n$ clauses, and $p$ predicate symbols. The complexity is on the exponent which is the number of clauses. By reducing the number of clauses we could greatly reduce the hypothesis space.

\section{Stochastic Logic Programs}

\paragraph{} A stochastic\footnote{Having a random probability distribution / pattern that may be analysed statistically but may not be predicted exactly.} logic program provides a means to structurally defining a probability distribution that can be used to represent a machine learning algorithm's bias over the hypothesis and instance space\cite{muggleton96}. 

\paragraph{} Stochastic automaton can be represented using a Markov model, for example in Figure \ref{fig:StochasticAutomaton} below.

\begin{figure}[H]
\includegraphics[scale=0.6]{graphics/stochastic-automaton}
\caption{An example of a stochastic automaton. Probabilities of all edges going out of a single node sum to one because at each node, a decision is made based on the probabilities to decide with path to take.}\label{fig:StochasticAutomaton}
\end{figure}

\paragraph{} We can for example determine the probability of obtaining the string "abbc" from the automaton described in Figure \ref{fig:StochasticAutomaton} as such: 

$$P(abbc) = (0.4)(0.6)(0.7)(0.3) \approx 0.05$$

\noindent The sum of all strings possible in the automaton described in Figure \ref{fig:StochasticAutomaton} sums up to one: $$\sum_{s \in L} P(s) = 1$$

\paragraph{} The same concept in the stochastic automaton Figure \ref{fig:StochasticAutomaton} can also be described in terms of stochastic grammar as follows:

\begin{align*}
&0.4: S_0 \rightarrow aS_0\\
&0.6: S_0 \rightarrow bS_1\\
\\
&0.7: S_1 \rightarrow bS_1\\
&0.3: S_1 \rightarrow cS_2\\
\\
&1.0: S_2 \rightarrow \lambda\\
\end{align*}

\paragraph{} With this grammar, we can rewrite it into a Stochastic Logic Program (SLP) as such:

\begin{lstlisting}
0.4: s0([a|X], Y) :- s0(X, Y).
0.6: s0([b|X], Y) :- s1(X, Y).

0.7: s1([b|X], Y) :- s1(X, Y).
0.3: s1([c|X], Y) :- s2(X, Y).

1.0: s0([], []).
\end{lstlisting}

\paragraph{Applications of SLPs} There are a few application of SLPs:

\begin{itemize}
\item Sampling: It can be used to perform SLD resolution with random clause selection.
\item Information Content: We can perform proof of log probability goal using a SLP
\item Condition: Prove goal and update frequency counts on clauses in the proof.
\end{itemize}

\subsection{Fair Coin}\label{sec:SLPFairCoin}

\paragraph{} Considering the following SLP $S$ that describes a fair coin:

\begin{lstlisting}
0.5: coin(0).
0.5: coin(1).
\end{lstlisting}%

\subsection{Natural Numbers - Exponential}

\paragraph{} Consider the following SLP $P$ that represents an \textit{exponential} sampling distribution over natural numbers:

\begin{align*}
&0.5: nate(0) \leftarrow\\
&0.5: nate(s(N)) \leftarrow nate(N)
\end{align*}

\noindent The probability of any $N$ is given by: $$P(nate(N)|P) = 2^{-N-1}$$

\paragraph{} For example consider the refutation of the goal $\leftarrow nate(s(s(0)))$:

{\footnotesize \begin{align*}
&\leftarrow nate(s(s(0))) && \text{\% resolves with 2nd clause, prob } = \frac{1}{2}\\
&\leftarrow nate(s(0)) && \text{\% resolves with 2nd clause, prob } = \frac{1}{2}\\
&\leftarrow nate(0) && \text{\% resolves with 1st clause, prob }= \frac{1}{2}
\end{align*}}

\paragraph{} The probability of this derivation is $$P(nate(s(s(0)))|P) = \left(\frac{1}{2}\right)^3 = \frac{1}{8}$$

\subsection{Natural Numbers - Polynomial}

\paragraph{} It is also possible to build a SLP $Q$ that describes a \textit{polynomial} sampling distribution over natural numbers in reverse binary form\cite[pp. 8-9]{muggleton96}. Numbers are constructed by

\begin{enumerate}
\item Choosing the length of its binary representation
\item Filling out the binary expression by repeated tossing of a fair coin (see Section \ref{sec:SLPFairCoin})
\end{enumerate}

\paragraph{} The following is program $Q$:

\begin{align*}
&1.0: natp(N) \leftarrow nate(U), bin(U, N)\\
\\
&0.5: bin(0, [1]) \leftarrow\\
&0.5: bin(s(U), [C|N]) \leftarrow coin(C), bin(U, N)
\end{align*}

\paragraph{} The probability of choosing a number of length $L = log_2(N)$ is approximately $2^{-L}$ and there are $2^L$ such numbers, each with equal probability of $P(natp(N)|Q) \approx 2^{-2log_2(N)} = N^{-2}$.

\section{Bayesian Meta-Interpretive Learning}

\subsection{Stochastic Refinement Tree}

\paragraph{} With the notion of SLP, we can consider hypotheses constructed with SLP as ones derived from Stochastic Refinement\cite{muggleton11}. If we consider all the possible construction, we would build a tree called Stochastic Refinement Tree (SRT),  where each branch is associated with the probabilities described in the SLP. The deeper the tree we go, the smaller the probability. Each node in the tree represents a Finite State Automata.

\paragraph{} As the SRT contains all possible construction, we need to knock out inconsistent branches against the given example.

\paragraph{} The low probability on deep branches (also higher probability on shallower branches) in the SRT reflect the realistic desire for favouring simpler hypothesis over complicated (or redundant) ones.

\subsection{MetaBayes Refinement Framework}

\paragraph{} In the MetaBayes Refinement Framework\cite{muggleton14}, we can use SLP and Bayes' Theorem to help us select the  optimal hypothesis. We look at the following:

\paragraph{Setting} Inverse entailment: $B, \lnot E \models \lnot H$

\paragraph{Meta-Rule} $\exists \mathcal{S}\ \forall\mathcal{T}\ P(s_1, \dots, s_n) \leftarrow Q(t_1, \dots, t_m)$

\paragraph{Stochastic Refinement} 

{\footnotesize
$$\sigma^*(C) = \{\langle D_i, p_i \rangle\ |\ D_i \in \rho^*(C), p_i \in [0, 1], \sum_{i \in [1, |\rho^*(C)|]} p_i = 1 \}$$}

\paragraph{Prior} The probability of a hypothesis given a background knowledge is $P(H|B) = \sum_{\langle H, p \rangle \in \sigma^*(\lnot B)} p$ and $P(H) = P(H|\emptyset)$

\paragraph{Likelihood} We also set the likelihood according to consistency to filter out inconsistent hypothesis:

\[
P(E|B,H) = \begin{cases}
1 & \text{if } B,H \models E\\
0 & \text{otherwise}
\end{cases}
\]

\paragraph{Posterior} Using Bayes' Theorem, the posterior probability\footnote{I am using notation consistent with 493 Data Analysis and Probabilistic Inference} would be given by:

$$P(H|B,E) = \alpha P(H|B)P(E|B,H)$$

\noindent where $\alpha$ is a normalising constant. A hypothesis $H$ is said to have maximum a posteriori (MAP) estimate if it is the case that $H \in argmax_H P(H|B,E)$.

\subsection{Implementation and Variants}

\paragraph{} There are three variants of generalised meta-interpreter with uniform distribution stochastic refinement of meta-rules:

\paragraph{MetaBayes${}_{SR}$} Model averaging prediction based on sampling hypotheses \textit{with replacement}.

\paragraph{MetaBayes${}_{RS}$} Model averaging prediction based on sampling hypotheses \textit{without replacement}.

\paragraph{MetaBayes${}_{MAP}$} Prediction based on leftmost maximum a posteriori estimation (i.e. leftmost MAP Estimator).

\subsection{MetaBayes${}_{RS}$ - Without Replacement}

\paragraph{} If we have chosen a hypothesis and we do not choose it again (replacement), we would reduce the amount of computation needed. Sampling without replacement is more efficient since it avoids generating
repeated hypotheses. This method is also known as Regular Sampling.

\paragraph{} Also, in without replacement, given a target probability, we can decide which branch to descend in the SRT based on the cumulative frequencies as each subtree of a node in the SRT is partitioned into equally sized interval.

\end{multicols}

\bibliographystyle{plain}
\bibliography{references}

\end{document}