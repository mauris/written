\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{dirtytalk}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{multicol}

\setlength\columnsep{30pt}
\newcommand{\indentitem}{\setlength\itemindent{25pt}}

\geometry{
 	a4paper,
	total={170mm,257mm},
 	left=20mm,
 	top=20mm,
}

\title{
	 \large 518: Logic and AI Programming \\
	 \huge Propositional Logic
}
\date{14 Dec 2017}
\author{
	Sam Yong \\
	\small \href{mailto:sam.yong17@imperial.ac.uk}{sam.yong17@imperial.ac.uk}
}


\begin{document}
  \maketitle
  
  \begin{multicols}{2}
  
  \section*{Foreword}  
  
  \paragraph{} This Propositional Logic reference was made as an condensation from the lecture slides and notes provided by Dr Fariba Sadri in the Imperial College London, Department of Computing's 518: Logic and AI Programming course.
  
  \paragraph{} The ordering of this reference may not correspond to the sequence introduced in the lectures, lecture slides and notes. This order is how I feel I would understand the topic better.
  
  \begin{footnotesize}
  \paragraph{License} This reference is made publicly available under the MIT License. You should not have paid anyone money in exchange for this document. If you have paid someone for it, well too bad. The source code for this document can be found public available on my Github repository\footnote{\href{https://github.com/mauris/written}{https://github.com/mauris/written}}. If you wish to help improve this document, feel free to open an issue on the Github repository. The author(s) of this document are not liable for your performance and grades in your coursework. 
  \end{footnotesize}
  
  \section{Syntax}
  
  \subsection{Semantic Consequence}

  \paragraph{Definition} Let $S$ be a set of wffs\footnote{wff: Well-Formed Formula} and $W$ be a wff. If all the wffs in $S$ are true and $W$ is also true, then $W$ is a semantic consequence of $S$. This is denoted using the $\vDash$ semantic turnstile symbol as:
  
  $S \vDash W$
  
  \noindent We can also say that $W$ is semantically entailed by $S$. If $W$ is a tautology, then
  
  $$\vDash W$$
  
  \subsection{Validity}
  
  \paragraph{Definition} Valid is just another term for tautology. A formula is valid if it is true in every interpretation. $\vDash A$ if $A$ is valid.
  
  \subsection{Satisfiable}
  
  \paragraph{Definition} A formula is satisfiable if it is true in at least one interpretation.
  
  \subsection{Inference}
  
  Given certain wffs are true (the premises), we can make some inference / conclusion from these given statements. For example, given that:
  
  \begin{align*}
  & (pE \land pP) \implies pM.\\
  & pE.\\
  & pP.
  \end{align*}
  
  We can infer (or conclude) that $pM$ is true. 
  
  
  \subsection{Definition / Proof}
  
  \paragraph{Definition} A derivation or proof of a wff $W$ in propositional logic from a given set of wffs $P$ - called premises - is a finite sequence of wffs st the last wff is $W$ and each eff in the sequence is one of the following:
  
  \begin{enumerate}
  \item a wff $\in$ P (i.e. a premise); 
  \item an immediate consequence of one or more wffs preceding in its sequence, as determined by one of the inference rules of propositional logic; or
  \item an assumption that is later discharged by an application of $\Rightarrow I$ or RAA.
  \end{enumerate}
  
  The derivation can be denoted using the syntactic turnstile $\vdash$. $P \vdash W$ denotes that $W$ is (syntactically) derivable from $P$. For example, 
  
  $$P \land Q, R \Rightarrow \lnot P \vdash \lnot R$$
  
  \subsection{Soundness \& Completeness}
  
  Let $S$ be any set of wffs, and let $W$ be a wff.
  
  \paragraph{Soundness} If $S \vdash W$, then $S \vDash W$. In other words, if $W$ is derivable from $S$, soundness means $W$ is a semantic consequence by $S$.
  
  \paragraph{Completeness} If $S \vDash W$, then $S \vdash W$. In other words, if $W$ is a semantic consequence of $S$, then completeness means $W$ is derivable from $S$.
  
  Propositional logic is said to be both {\bf sound} and {\bf complete}. Therefore in propositional logic we are justified in switching between syntactic proofs and semantic consequences.
  
  \section{Rules of Inference}
  
  \subsection{Natural Deduction}
  
  \paragraph{Introduction} Natural deductions are also called primitive rules of inference.
  
  \paragraph{$\land E$} Elimination of AND. Given $X \land Y$ is true, we deduce that $X$ is true and $Y$ is true. Hence:
  
  \begin{multicols}{2}
  \begin{equation*}  
  \frac{X \land Y}{X}
  \end{equation*}
  \break
  \begin{equation*}
  \frac{X \land Y}{Y}
  \end{equation*}
  \end{multicols}
  
  \paragraph{$\land I$} Introduction of AND. Given $X$ is true and $Y$ is true, we can also do the reverse: introducing a $\land$ on both $X$ and $Y$ to deduce that $X \land Y$ is true:
  
  \begin{multicols}{2}
  \begin{equation*}  
  \frac{X, Y}{X \land Y}
  \end{equation*}
  \break
  \begin{equation*}  
  \frac{X, Y}{Y \land X}
  \end{equation*}
  \end{multicols}
  
  \paragraph{$\lor E$} Elimination of OR. Given $X \lor Y$ is true and $\lnot X$ is true, we can conclude $Y$ is true. Likewise, given $X \lor Y$ is true and $\lnot Y$ is true, we can conclude $X$ is true:
  
  \begin{multicols}{2}
  \begin{equation*}  
  \frac{X \lor Y, \lnot X}{Y}
  \end{equation*}
  \break
  \begin{equation*}  
  \frac{X \lor Y, \lnot Y}{X}
  \end{equation*}
  \end{multicols}
  
  \paragraph{$\lor I$} Introduction of OR. Given $X$ is true, we can introduce $Y$ that can be true or false and still conclude $X \lor Y$ is true and $Y \lor X$ is true:
  
  \begin{multicols}{2}
  \begin{equation*}  
  \frac{X}{X \lor Y}
  \end{equation*}
  \break
  \begin{equation*}  
  \frac{X}{Y \lor X}
  \end{equation*}
  \end{multicols}
  
  \paragraph{$\Rightarrow E$} Elimination of implication (Modus Ponens). Given the antecedent $X$ is true and condition $X \Rightarrow Y$ is true, you can conclude that consequent $Y$ is true:
  
  \begin{equation*}  
  \frac{X, X \Rightarrow Y}{Y}
  \end{equation*}
  
  \paragraph{$\Rightarrow I$} Introduction of implication. If we assume that $X$ is true and find that $Y$ is true given the assumption that $X$ is true, then we can introduce the condition $X \Rightarrow Y$:
  
  \begin{align*}
   &X \tag*{\tiny Assume}\\
   &...\\
   &Y\\
   &\frac{}{X \Rightarrow Y}
  \end{align*}
  
  \paragraph{$\lnot E, \lnot I$} Elimination and introduction of negation. By proof of contradiction (Reductio Ad Absurdum or RAA), we can add or remove a negation:
  
  \begin{multicols}{2}
  \begin{align*}
   &\lnot X \tag*{\tiny Assume}\\
   &...\\
   &Y, \lnot Y \tag*{\tiny Contradiction}\\ 
   &\frac{}{X}
  \end{align*}

  \break
  
  \begin{align*}
   &X \tag*{\tiny Assume}\\
   &...\\
   &Y, \lnot Y \tag*{\tiny Contradiction}\\ 
   &\frac{}{\lnot X}
  \end{align*}
  \end{multicols}
  
  \noindent In RAA, $X$ and $Y$ may even be the same wff:
  
  \begin{multicols}{2}
  \begin{align*}
   &\lnot X \tag*{\tiny Assume}\\
   &...\\
   &X, \lnot X \tag*{\tiny Contradiction}\\ 
   &\frac{}{X}
  \end{align*}
  
  \break
  
  \begin{align*}
   &X \tag*{\tiny Assume}\\
   &...\\
   &X, \lnot X \tag*{\tiny Contradiction}\\ 
   &\frac{}{\lnot X}
  \end{align*}
  \end{multicols}
  
  \paragraph{$\Leftrightarrow E$} Elimination of biconditional implication. Given $X \Leftrightarrow Y$ is true, we can conclude that $X \Rightarrow Y$ is true and $Y \Rightarrow X$ is also true:
  
  \begin{multicols}{2}
  \begin{align*}
   &\frac{X \Leftrightarrow Y}{X \Rightarrow Y}
  \end{align*}
  
  \break
  
  \begin{align*}
   &\frac{X \Leftrightarrow Y}{Y \Rightarrow X}
  \end{align*}
  \end{multicols}
  
  \paragraph{$\Leftrightarrow I$} Introduction of biconditional implication. Given $X \Rightarrow Y$ is true and $Y \Rightarrow X$ is true, you can introduce a biconditional implication to conclude that $X \Leftrightarrow Y$ is true:
  
  \begin{align*}
   &\frac{X \Rightarrow Y, Y \Rightarrow X}{X \Leftrightarrow Y}
  \end{align*}  
  
  \subsection{Derived Inference Rules}
  
  \paragraph{$\lnot \lnot E$} Double negation elimination:
  
  \begin{align*}
   &\frac{\lnot \lnot X}{X}
  \end{align*}  
  
  \paragraph{$\lnot \lnot I$} Double negation introduction:
  
  \begin{align*}
   &\frac{X}{\lnot \lnot X}
  \end{align*}  
  
  \paragraph{Law of excluded middle} This law allows you to introduce a variable:
  
  \begin{align*}
   &\frac{}{X \lor \lnot X}
  \end{align*}  
  
  \paragraph{Proof by cases} or proof by exhaustion:
  
  \begin{align*}
   &\frac{X \lor Y, X \Rightarrow Z, Y \Rightarrow Z}{Z}
  \end{align*}  
  
  \paragraph{Modus Tollens} or denying the consequent:
  
  \begin{align*}
   &\frac{X \Rightarrow Y, \lnot Y}{\lnot X}
  \end{align*}  
  
  \paragraph{Contraposition} or denying the consequent:
  
  \begin{align*}
   &\frac{X \Rightarrow Y}{\lnot Y \Rightarrow \lnot X}
  \end{align*}  
  
  \paragraph{Dilemma} or denying the consequent:
  
  \begin{align*}
   &\frac{X \Rightarrow Y, \lnot X \Rightarrow Y}{Y}
  \end{align*}  
  
  \subsection{Rules in Quantifiers}
  
  \paragraph{} Given that there is a need to perform inference on given quantifiers, we need rules of inference for the introduction and elimination of the for-all $\forall$ and there-exists $\exists$ quantifiers.
  
    \paragraph{$\forall E$} Elimination of for-all $\forall$ quantifier. Given $a$ is any constant, the constant $a$ must replace every free occurrence of $X$ in $p(X)$. Therefore:
  
  \begin{equation*}  
  \frac{\forall X p(X)}{p(a)}
  \end{equation*}
  
    \paragraph{$\forall I$} Introduction of for-all $\forall$ quantifier. If we know all the ground terms and the number of them (e.g. $a_1, a_2, ..., a_n$) then to show $\forall X p(X)$, we show that $p(a_1), p(a_2), ..., p(a_n)$ are all true. However, there may be cases where the ground terms may be part of a large set.
    
    \paragraph{} For example, the case of $\forall X (student(X) \implies undergrad(X) \lor postgrad(X)$ would require checking every student. This is {\bf not} practical. In general to show $\forall X p(X)$, we show $p(a)$ for an arbitrary constant $a$ with no constraints:
  
  \begin{equation*}  
  \frac{p(a)}{\forall X p(X)}
  \end{equation*}
  
  The following conditions must be met for the rule to apply:
  
  \begin{enumerate}
  \item $a$ is an arbitrary constant;
  \item There are no assumptions involving $a$ left undischarged used to obtain $p(a)$; and,
  \item Substitution of $X$ for $a$ in $p(X)$ is uniform (i.e. X is substituted $\forall$ occurrence of $a$).
  \end{enumerate}
  
  \paragraph{$\exists E$} Elimination of there-exists $\exists$ quantifier. Given $W$ is any wff, the following conditions must be met:
  
  \begin{enumerate}
  \item $a$ is an arbitrary constant;
  \item In proving $W$ from $p(a)$, the only assumption left undischarged in which $a$ occurs is $p(a)$; and,
  \item $a$ does not occur in W or in $\exists X p(X)$.
  \end{enumerate}
  
  \paragraph{} $p(a)$ is an assumption which is then discharged by the application of $\exists E$. Therefore:
  
   \begin{align*}
   &p(a) \tag*{\tiny Assume}\\
   &...\\
   &W\\
   \frac{\exists X p(X)\tag*{\tiny Given}}{W}
  \end{align*}
  
   \paragraph{$\exists I$} Introduction of there-exists $\exists$ quantifier. Given $a$ is any term and $X$ does not clash with any occurrence of $X$ in $p(a)$:
  
   \begin{equation*}
   \frac{p(a)}{\exists X p(X)}
  \end{equation*}
  
  \paragraph{} $X$ is substituted $\forall$ occurrence of $a$ in $p(a)$.
  
  \subsection{Derivations for Quantifiers}
  
  \paragraph{} One useful derivation for quantifiers is as such:
  
   \begin{align*}
   \exists X (p(X) \land q(X)) \vdash \exists X p(X)\\
   \exists X (p(X) \land q(X)) \vdash \exists X q(X)
   \end{align*}
   
   This can be proven as such:
   
   \begin{enumerate}
   \item $\exists X (p(X) \land q(X))$ $\>\>$ Given
   {\indentitem 
       \item $p(a) \land q(a)$ $\>\>$ Assume
       \item $q(a)$ $\>\>$ $\land E, 2$
       \item $\exists X q(X)$ $\>\>$ $\exists I, 3$}
   \item $\exists X q(X)$ $\>\>$ $\exists E, 1, 2, 4$
   \end{enumerate}
   
   \paragraph{Negation of Quantifiers} The following statement holds:
   
   $$\forall X (p(X) \implies q(X)) \vdash p(a) \implies q(a)$$
   
   ...using $\forall E$. However, {\bf the negated version does not hold}:

   $$\lnot (\forall X (p(X) \implies q(X))) \nvdash \lnot (p(a) \implies q(a))$$
   
   The derivation is wrong because the $\lnot$ needs to be applied onto the quantifier first as such:
   
   \begin{align*}
   \lnot (\forall X (p(X) &\implies q(X))) \\
   	 &\vdash \exists X (\lnot (p(X) \implies q(X)))\\
   	 &\vdash \exists X (\lnot (\lnot p(X) \lor q(X)))\\
   	 &\vdash \exists X (\lnot\lnot p(X) \land \lnot q(X)))\\
   	 &\vdash \exists X (p(X) \land \lnot q(X))
   \end{align*}
   
   Likewise, the following statement holds:
   
   $$\lnot p(a) \vdash \exists X \lnot p(X)$$
   
   ... using $\exists I$. However, from $\lnot p(a)$ cannot derive $\lnot (\exists X p(X))$. We apply negation on $\exists X p(X)$ and we can show that:
  
   \begin{align*}
   \lnot (\exists X p(X)) \vdash \forall X (\lnot p(X))
   \end{align*}
   
  \end{multicols}
\end{document}
