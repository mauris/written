\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{dirtytalk}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{hyperref}
\usepackage{listings}
\usepackage[nodayofweek]{datetime}
\longdate
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{amsthm}
\usepackage{comment}
\usepackage[font=footnotesize,labelfont=bf]{caption}
\usepackage{float}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]

\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition} % definition numbers are dependent on theorem numbers
\newtheorem{exmp}[thm]{Example} % same for example numbers

\setlength\columnsep{30pt}

\geometry{
 	a4paper,
	total={170mm,257mm},
 	left=20mm,
 	top=20mm,
}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\title{
	 \huge 303: Systems Verification\\
	 \huge -- Reference --
}
\date{\today}
\author{
	Sam Yong \\
	\small \href{mailto:sam.yong17@imperial.ac.uk}{sam.yong17@imperial.ac.uk}
}


\begin{document}
\maketitle

\begin{multicols}{2}

\section*{Foreword}  

\paragraph{} This reference was made as an condensation from the lecture slides and notes provided by Prof. Alessio R. Lomuscio, Prof. Michael Huth and Prof. Mark D. Ryan in the Imperial College London, Department of Computing's 303: Systems Verification.

\paragraph{} This reference also contain several contributions\footnote{List of contributors in no particular order.} by Michael Akintunde and Aaron Hau. Thank you!

\paragraph{} The ordering of this reference may not correspond to the sequence introduced in the lectures, lecture slides and notes. This order is how I feel I would understand the topic better.

\begin{footnotesize}
\paragraph{License} This reference is made publicly available under the MIT License. You should not have paid anyone money in exchange for this document. If you have paid someone for it, well too bad. The source code for this document can be found public available on my Github repository\footnote{\href{https://github.com/mauris/written}{https://github.com/mauris/written}}. If you wish to help improve this document, feel free to open an issue on the Github repository.
\end{footnotesize}
\newpage

\tableofcontents
\newpage

\section{Introduction}

\paragraph{} There are two ways to know whether we're building a piece of software correctly: validation and verification.

\paragraph{Validation} To assure that the product, service, or system meets the requirements of the customer or other stakeholders.
\paragraph{Verification} To evaluate if the product, service or system compiles with regulation, requirement, specification or imposed conditions.

\paragraph{} We want to be able to automatically verify that a software or system. In order to do that define that a system has to satisfy a set of properties:

\begin{enumerate}
\item We would like to check if a system $S$ satisfies a property $P$.
\item We build an "appropriate" model $M_S$ for $S$ that represents all possible computations of interest of $S$.
\item We define an appropriate formula $\phi P$ capturing property $P$.
\item We can then check automatically if $\phi P$ is satisfied on $M_S$: i.e. $$M_S \models \phi P$$
\end{enumerate}

\section{Modal Languages}

\paragraph{} Modal logic offers:
\begin{enumerate}
\item A natural way of handling the concepts of temporal flows, knowledge, belief, necessity, possibility etc.
\item A clear and natural semantics.
\item A heritage of techniques for proving meta-logical results about modal systems\footnote{such as decidability, completeness, computational complexity, etc.}
\end{enumerate}

\subsection{Syntax vs Semantics}

\paragraph{Syntax} has to do with how we write formulas. It defines the logical language that we use when writing formulas.

\paragraph{Semantics} focuses on giving an interpretation to formulas constructed according to the syntax.

\subsection{Syntax}

\paragraph{Modality} We use an extension of propositional calculus by an operator, $\Box$, that we refer to as \textit{modality} or \textit{box}.

\begin{defn}\label{defn:Syntax} Assume a set of propositional variables $P$, the set of $\mathcal{L}$ of valid formulas of propositional modal logic defined by: \end{defn}

\begin{itemize}
\item \textbf{true} $\in \mathcal{L}$.
\item any $p \in P \implies p \in \mathcal{L}$.
\item If $\phi, \psi \in \mathcal{L}$, then $\lnot \phi, \phi \land \psi, \Box \phi \in \mathcal{L}$.
\item Nothing else is in $\mathcal{L}$,
\end{itemize}

We refer $\phi, \psi,...$ to arbitrary formulas in $\mathcal{L}$ and $p, q, ...$ to atoms in $P$. It is convenient to use other connectives derived from Definition \ref{defn:Syntax}:

\begin{itemize}
\item \textbf{false} $\equiv$ $\lnot$\textbf{true}.
\item $\phi \lor \psi \equiv \lnot(\lnot\phi \land \lnot\psi)$.
\item $\phi \implies \psi \equiv \lnot\phi\lor\psi \equiv \lnot(\phi \land \lnot\psi)$.
\item $\Diamond\phi \equiv \lnot\Box\lnot\phi$.
\end{itemize}

\noindent The modal operator $\Diamond$ is the dual of $\Box$ and is read as "diamond".

\subsection{Modality Readings}

\paragraph{Intuitive Meaning} We can develop the whole of modal theory without any reference to the intuitive meaning of the modalities. There are some meanings of the modal box such as:

\medskip 
\noindent
\begin{table}[H]
\bgroup
\def\arraystretch{1.5}\footnotesize
\begin{tabular}{ | p{2cm} || p{2.4cm} | p{2.4cm} | }
\hline
\bf Meaning of $\Box$ & \bf Reading of $\Box\phi$ & \bf Reading of $\Diamond\phi$ \\
\hline
\hline

Temporal & Forever in the future $\phi$ holds & Sometime in the future $\phi$ will hold \\
\hline

Epistemic & It is known that $\phi$ holds & It is considered (epistemically) possible that $\phi$ will hold \\
\hline

Doxastic & It is believed that $\phi$ holds & It is considered (doxastically) possible that $\phi$ will hold \\
\hline

Deontic & $\phi$ is obligatory & $\phi$ is allowed \\
\hline

Provability & It is provable that $\phi$ & It is consistent that $\phi$ \\
\hline

Necessitation & It is necessary that $\phi$ holds & It is possible that $\phi$ hold \\
\hline

\end{tabular}
\egroup
\caption{Table of Modality Readings}
\end{table}

\begin{exmp}In the \textit{Epistemic} meaning, $\Box\Box\phi$ is read as "$\phi$ is known to be known".\end{exmp}
\begin{exmp}In the \textit{Epistemic} meaning, $\Box\Diamond\phi$ is read as "$\phi$ is known to be regarded as possible".\end{exmp}
\begin{exmp}In the \textit{Temporal} meaning, $\phi \implies \Box\phi$ is read as "If $\phi$ is true now, then $\phi$ will always be true."\end{exmp}
\begin{exmp}In the \textit{Temporal} meaning, $\Box\phi \implies \Diamond\phi$ is read as "If $\phi$ is forever true, then $\phi$ will be true sometime in the future." \end{exmp}

\paragraph{Combination of Operators} It is also possible to combine $\Box$ operators with different interpretation. Let $\Box_T$ be the modality with Temporal meaning and $\Box_K$ be the modality with Epistemic meaning. $\Box_T\Box_K\phi$ is read as "It is forever known that $\phi$ holds."

\subsection{Kripe Frame}

\begin{defn}A Kripe frame $F$ is a pair $F = (W, R)$ where $W \neq \emptyset$ is a set of possible worlds and $R \subset W \times W$ is a relation $R$ defined on $W$.\end{defn}

\paragraph{} We indicate elements of W as $w$, $w'$, etc. or $s$, $s'$, etc. when in the context of temporal logic These are also called states or points.

\begin{exmp}$(N, suc)$, the set of natural numbers with the relation successor, is a Kripke frame.\end{exmp}

\paragraph{} Since Kripke frames are unvalued structures (i.e. we cannot evaluate formulas on them), we need Kripke models to evaluate formulas.

\subsection{Kripe Models}

\begin{defn}A Kripke model $M$ is a pair $M = (F, \pi)$ where $F$ is a Kripe frame and $\pi: P \mapsto \mathcal{P}(W)$ is a valuation for the atoms. \end{defn}

\paragraph{} Intuitively, $\pi(p)={w_1, w_2}$ represents the fact that the atom $p$ is true at states $w_1$ and $w_2$, and is false at $W \backslash \{w_1, w_2\}$. 

\paragraph{} By slight abuse of notation, we can indicate a Kripke model $M$ as a triple $M = (W, R, \pi)$, where $F = (W, R)$ is its underlying Kripke frame. 

\subsection{Satisfaction}

\begin{defn}The satisfaction of a formula $\phi\in\mathcal{L}$ at a world $w\in W$ of a model $M$ (formally $(M, w) \models \phi$) is inductively defined as follows:\end{defn}

\begin{itemize}
\item $(M, w) \models $ \textbf{true}
\item $(M, w) \models p \impliedby w \in \pi(p)$
\item $(M, w) \models \lnot\phi \impliedby \lnot((M, w)\models \phi)$
\item $(M, w) \models \phi \land \psi \impliedby ((M,w) \models \phi) \land ((M, w) \models \psi)$
\item $(M, w) \models \Box\psi \impliedby\\ (\forall w' \in W: w R w' \implies (M, w') \models \psi)$
\item $(M, w) \models \Diamond\psi \impliedby\\ (\exists w' \in W: w R w' \land (M, w') \models \psi)$
\end{itemize}

\noindent We read $(M, w) \models \phi$ as "$\phi$ is true at $w$ in model $M$". In the case of $(M, w) \models \Box\psi$, if $w$ does not have any successor defined by the relation $R$ then $(M, w) \models \Box\psi$ holds for any $\psi$.

\section{Linear Temporal Logic}

\paragraph{} LTL asssumes time is a linear sequence of determined discrete events. 

\begin{itemize}
\item The modal box $\Box$ is written as $G$ representing "forever in the future (globally)"
\item Its dual $\Diamond$ is represented by $F$ representing "at some point in the future."
\end{itemize}

\subsection{Operators}

\begin{itemize}
\item $G\phi$ represent situations in which "$\phi$ is forever \textbf{true} from now on."
\item $F\phi$ encode situations in which "$\phi$ will become \textbf{true} at some point in future\footnote{includes the current point in time in the context of this literature. See Section \ref{subsubsec:LTLSemanticsPath} for formal definition.}." Since $F$ is the dual of $G$, $F\phi ::= \lnot G\lnot\phi$.
\item $X\phi$ represent situations where "$\phi$ holds at the next time instant."
\item $U$ is a binary operator, written in the form $\phi U \psi$ which represents that "$\phi$ holds until $\psi$ becomes \textbf{true} (at least once)." Note that even after $\psi$ becomes \textbf{true}, $\phi$ doesn't necessary have to become false (i.e. it can continue to hold).
\item $R$ is also a binary operator, written in the form $\phi R \psi$, representing "$\psi$ holds until $\phi$ becomes \textbf{true} (or $\phi$ releases $\psi$)." Since $R$ is the dual of $U$, $\phi R \psi ::= \lnot(\lnot\psi U\lnot\phi)$
\item $W$ is a weaker version of $U$ (weak until) which relaxes the constraint that $\psi$ needs to be true at some point in time, defined as $\phi W\psi ::= (\phi U \psi)\lor G\phi$.
\end{itemize}

\subsection{Syntax}

\begin{defn}The syntax of LTL is given by the following Backus–Naur form (BNF):\end{defn}

\begin{align*}
\phi ::= p \\
\lnot\phi \\
\phi \land \phi  \\
X\phi \\
G\phi \\
\phi U \phi
\end{align*}


\subsection{Semantics}

\begin{defn}A model for LTL is a Kripke model $M = (W, R, \pi)$ st $R$ is a serial relation. A path $\rho$ in a model is a \textit{infinite sequence of states} $s_0, s_1, ...$ st $\forall i \geq 0,\ (s_i, s_{i+1})\in R$. \end{defn}

A path $\rho$ represents a possible evolution of the system. A state may belong to more than one path, i.e. for any state there may be more than one successor depending on which path we are considering.

\begin{defn}$\rho^i$ indicates the suffix of path $\rho = s_0,s_1,...$, Since a path $\rho$ is infinite, its suffix $\rho^i$ is also infinite and hence is also a path.\end{defn}

\subsubsection{Satisfaction on Paths}\label{subsubsec:LTLSemanticsPath}
\begin{defn}\label{defn:ltlsatisfaction}
Given a formula $\phi$, a model $M$ and a path $\rho = s_0, s_1, s_2,...$ on $M$, satisfaction for the LTL connectives is defined as follows:
\end{defn}

\begin{itemize}
\item $(M, \rho) \models p \Longleftrightarrow s_0 \in \pi(p)$
\item $(M, \rho) \models \lnot\phi \Longleftrightarrow \lnot ((M, \rho)\ \models \phi)\\ \Longleftrightarrow (M, \rho) \not\models \phi$
\item $(M, \rho) \models \phi\land\psi \Longleftrightarrow (M, \rho) \models \phi \land (M, \rho) \models \psi$
\item $(M, \rho) \models X\phi \Longleftrightarrow (M, \rho^1) \models \phi$
\item $(M, \rho) \models G\phi \Longleftrightarrow \forall i \geq 0\ (M, \rho^i) \models \phi$
\item $(M, \rho) \models \phi U\psi \Longleftrightarrow\\ \exists j \geq 0\ \lbrack\forall k \in [0, j)\ (M, \rho^k) \models \phi \land (M, \rho^j) \models \psi\rbrack$
\end{itemize}

\paragraph{} Using Definition \ref{defn:ltlsatisfaction}, we can derive the following additional satisfactions:

\begin{itemize}
\item $(M, \rho) \models F\phi \Longleftrightarrow \exists i \geq 0\ (M, \rho^i) \models \phi$
\item $(M, \rho) \models \psi R\phi \Longleftrightarrow\\ \exists j \geq 0\ \lbrack \forall k \in [0, j]\ (M, \rho^k) \models \phi \land (M, \rho^j) \models \psi\rbrack\\ \lor \forall i \geq 0\ (M, \rho^i) \models \phi$
\end{itemize}

\subsubsection{Satisfaction on States}
\begin{defn}
Given a formula $\phi$, a model $M$ and a state $s$ in $M$, $\phi$ is true at $s$ in $M$ (written $(M, s) \models \phi$, if $\forall$ paths $\rho$ originating from $s$, we have $(M, \rho) \models \phi$. Formally, $$\forall \rho(s): (M, \rho) \models \phi \leftarrow (M, s) \models \phi$$
\end{defn}

\paragraph{} In the case of LTL, the standard modal satisfaction definition on states involve quantification over \textit{all possible futures}.

\subsection{Equivalences}

\paragraph{} There are several useful equivalences that hold in LTL:

\begin{itemize}
\item $\lnot X\phi \equiv X \lnot\phi$
\item $G(\phi \land \psi) \equiv G\phi \land G\psi$
\item $F(\phi \lor \psi) \equiv F\phi \lor F\psi$
\item $G\phi \equiv \text{false}\ R \phi\\ \equiv \lnot (\text{true}\ U \lnot\phi)$
\item $F\phi \equiv \text{true}\ U \phi\\ \equiv \lnot (\text{false}\ R \lnot\phi)$
\item $\phi U \psi \equiv \phi W \psi \land F\psi$
\item $\phi W \psi \equiv (\phi U \psi) \lor G\phi\\
 \equiv \phi U (\psi \lor G\phi)\\
 \equiv \psi R (\psi \lor \phi)$
\item $\psi R \phi \equiv \phi W (\phi \land \psi)\\
 \equiv (\phi U (\phi \land \psi)) \lor G(\phi \land \psi)$
\end{itemize}

\subsection{Non-Equivalences}

\paragraph{} Different forumlas may provide different semantic meanings. For example, we see that $Fp \implies Fq \not\equiv F(p \implies q)$:

\begin{itemize}
\item[] We assume that $Fp \implies Fq \equiv F(p \implies q)$. We use the definition of $\implies$ to derive:\\ $Fp \implies Fq \equiv \lnot Fp \lor Fq$ and\\ $F(p \implies q) \equiv F(\lnot p \lor q) \equiv F\lnot p \lor Fq$.
\item[] To reach a contradiction, we need a model that satisfies one formula but not the other. Since we need $Fq$ to be false (otherwise $Fq$ would make both formulae true), we must never reach a point in the model where $q$ holds. We choose to eliminate $q$ from any counterexample we construct.
\item[] We're left with $\lnot Fp$ and $F\lnot q$. One must be true and the other false.
\item[] We can try to make $\lnot Fp$ true and $F\lnot p$ false, but in order to make $F\lnot p$ false, we need to $Gp$ in the model to be true, which is impossible when we're already making $\lnot Fp$ true.
\item[] Alternatively, we make $\lnot Fp$ false and $F\lnot p$ true in the same model. We construct a model such that $p$ starts off as true, and at some other point $p$ becomes false. 
\end{itemize}

\noindent With the following model $\mathcal{M}$: for all models $Fp \implies Fq \not\equiv F(p \implies q)$.

\begin{figure}[H]
\centering
\includegraphics[width=0.2\textwidth]{graphics/ltl-non-equiv-example1.png}
\caption{The constructed model $\mathcal{M}$ st given the sequence $\rho = w_1 w_2^+$ we have $(\mathcal{M}, \rho) \not\models Fp \implies Fq$, but $(\mathcal{M}, \rho) \models F(p \implies q)$.}
\end{figure}

\paragraph{} By the counterexample, we proved that there exists a model $\mathcal{M}$ and a path $\rho$ st $(\mathcal{M}, \rho) \not\models (Fp \implies Fq) \land (\mathcal{M}, \rho) \models F(p \implies q)$. Hence $Fp \implies Fq \not\equiv F(p \implies q)$.

\section{Computation Tree Logic}

\paragraph{} LTL allows us to talk about the temporal evolution of a system, but sometimes we would like to check whether or not something happens in one path but not in all. CTL accommodates this need. CTL's syntax allows one to \textit{quantify explicitly} over paths.

\subsection{Syntax}
\begin{defn}The syntax of CTL is given by the following BNF:\end{defn}

\begin{align*}
\phi ::= p \\
\lnot\phi \\
\phi \land \phi  \\
EX\phi \\
EG\phi \\
E(\phi U \phi)
\end{align*}

\subsection{Operators}\label{subsec:Operators}

\paragraph{} In CTL we have two different path quantification modifiers: $E$ and $A$. $E$ encodes an existential quantification on paths while $A$ encodes a universal quantification on paths. 

\begin{itemize}
\item $EX\phi$: "there exists a path from the current state st at the next state $\phi$ holds."
\item $EG\phi$: "there exists a path from the current state st $\phi$ holds forever in the future."
\item $E(\phi U\psi)$: "there exists a path from the current state st $\phi$ holds until $\psi$ becomes true."
\end{itemize}

\paragraph{} In CTL, dual operators can also be defined: 
\begin{itemize}
\item $AX\phi ::= \lnot EX \lnot\phi$
\item $EX\phi ::= \lnot AX \lnot\phi$
\item $AG\phi ::= \lnot EF \lnot\phi$
\item $AF\phi ::= \lnot EG \lnot\phi$
\item $EF\phi ::= \lnot AG \lnot\phi$
\item $EG\phi ::= \lnot AF \lnot\phi$
\end{itemize}

\subsection{Semantics}
\subsubsection{Satisfaction}
\begin{defn}
Given a formula $\phi$, a model $M = (W, R, \pi)$ and a state $s$ in $M$, the satisfaction of $\phi$ at $s$ in $M$ (written $(M, s) \models \phi$) is defined inductively as follows:
\end{defn}

\begin{itemize}
\item $(M, s) \models p \Leftrightarrow s \in \pi(p)$
\item $(M, s) \models EX\phi \Leftrightarrow\\ \exists \rho = s_0, s_1, ... \land s = s_0: (M, s_1) \models \phi$
\item $(M, s) \models EG\phi \Leftrightarrow\\ \exists \rho = s_0, s_1, ... \land s = s_0: \forall i \geq 0: (M, s_i) \models \phi$
\item $(M, s) \models EF\phi \Leftrightarrow\\ \exists \rho = s_0, s_1, ... \land s = s_0: \exists i \geq 0: (M, s_i) \models \phi$
\item $(M, s) \models E(\phi U\psi) \Leftrightarrow\\ \exists \rho = s_0, s_1, ... \land s = s_0:\\ \exists j \geq 0\  \lbrack\forall k \in [0, j): (M, s_k) \models \phi \land (M, s_j) \models \psi\rbrack$
\item $(M, s) \models E(\psi R\phi) \Leftrightarrow\\ \exists \rho = s_0, s_1, ... \land s = s_0:\\ \exists j \geq 0\  \lbrack\forall k \in [0, j]: (M, s_k) \models \phi \land (M, s_j) \models \psi\rbrack\\ \lor \forall i \geq 0\ (M, s_i) \models \phi$
\item $(M, s) \models AG\phi \Leftrightarrow\\ \forall \rho = s_0, s_1, ... \land s = s_0: \forall i \geq 0: (M, s_i) \models \phi$
\item $(M, s) \models AF\phi \Leftrightarrow\\ \forall \rho = s_0, s_1, ... \land s = s_0: \exists i \geq 0: (M, s_i) \models \phi$
\item $(M, s) \models A(\phi U\psi) \Leftrightarrow\\ \forall \rho = s_0, s_1, ... \land s = s_0:\\ \exists j \geq 0\  \lbrack\forall k \in [0, j): (M, s_k) \models \phi \land (M, s_j) \models \psi\rbrack$
\item $(M, s) \models A(\psi R\phi) \Leftrightarrow\\ \forall \rho = s_0, s_1, ... \land s = s_0:\\ \exists j \geq 0\  \lbrack\forall k \in [0, j]: (M, s_k) \models \phi \land (M, s_j) \models \psi\rbrack\\ \lor \forall i \geq 0\ (M, s_i) \models \phi$
\end{itemize}

\subsubsection{Skolemization}

\paragraph{} $AFEG\phi \neq EGAF\phi$. The $EG\phi$ in $AFEG\phi$ is dependent on the path taken by the quantifier $AF$ and hence cannot be interchanged without changing its semantic meaning.

\subsection{Semantic Equivalence}

\paragraph{} The following are some semantic equivalence apart those seen in Section \ref{subsec:Operators}:

\begin{itemize}
\item $AG\phi \equiv \phi \land AXAG\phi$
\item $EG\phi \equiv \phi \land EXEG\phi$
\item $AF\phi \equiv \phi \lor AXAF\phi$
\item $EF\phi \equiv \phi \lor EXEF\phi$
\item $A(\phi U \psi) \equiv \psi \lor (\phi \land AX[A(\phi U \psi)])$
\item $E(\phi U \psi) \equiv \psi \lor (\phi \land EX[E(\phi U \psi)])$
\item $EG\phi \equiv \lnot A(\text{true}\ U \lnot\phi)$
\item $EF\phi \equiv E(\text{true}\ U \phi)$
\item $AG\phi \equiv \lnot EF \lnot\phi \equiv \lnot E(\text{true}\ U \lnot\phi)$
\item $AF\phi \equiv \lnot EG \lnot\phi \equiv A(\text{true}\ U \phi)$
\item $A(\phi U \psi) \equiv \lnot E(\lnot\psi U \lnot(\phi\lor\psi)) \land \lnot EG(\lnot \psi)\\
 \equiv \lnot E(\lnot\psi U \lnot(\phi\lor\psi)) \land AF\psi\\
 \equiv \lnot A(\phi R \psi)$
\end{itemize}

\subsection{Non-Equivalences}

\paragraph{} Formulas can differ in what they specify. For example, $AGAF\phi \not\equiv AFAG\phi$.

\begin{itemize}
\item $AGAF\phi$ states that however far I go into any path, I will always find another $\phi$ in all the paths from there. 
\item $AFAG\phi$ states that in all the paths, eventually you only find paths where $\phi$ always holds.
\end{itemize}


\section{Model Checking}

\paragraph{} Suppose we have a system $S$ and a property $P$ representing the specification of the system. Assume that we can build a Kripke model $M_S = (W, R, \pi)$ representing all possible computations of $S$. 

\begin{itemize}
\item $W$ contains all the possible computational states of $S$.
\item $R$ is the temporal relation between states that represents all temporal transitions in the system.
\end{itemize}

\paragraph{} Assume that property $P$ can be represented as a logical formula $\phi_P$. If $M_S$ faithfully encodes $S$ and $\phi_P$ captures $P$, then checking whether $S$ satisfies $P$ can be solved by checking if

$$M_S \models \phi_P$$

\paragraph{} However, there may still be some questions we need to address:

\begin{itemize}
\item Are the temporal logics (LTL / CTL) expressive enough to express the kind of specifications $\phi_P$ we are likely to encounter?
\item How do we build $M_S$?
\item Won't $M_S$ have too many states (possibly infinite) for us to reason able?
\end{itemize}

\subsection{Specifications in LTL and CTL}

\paragraph{} There are some statements that can be naturally expressed in LTL, CTL or both. Other statements may never be able to express in one of the temporal logics.

\begin{itemize}
\item "A faulty state is never reached":\\ LTL: $\lnot F\ faulty$\\ CTL: $\lnot EF\ faulty$
\item "It is impossible to get to a state where $started$ holds but $ready$ does not":\\ LTL: $G\lnot(started \land \lnot ready)$\\ CTL: $AG\lnot(started \land \lnot ready)$
\item "It is possible (i.e. there is a possible computation in which this happens) to get to a state where $started$ holds but $ready$ does not.":\\ LTL: we cannot express this!\\CTL: $EF(started \land \lnot ready)$
\item "Every request will get acknowledged":\\ LTL: $G(req \implies F\ ack)$\\ CTL: $AG(req \implies AF\ ack)$
\item "An event $p$ happens infinitely often":\\ LTL: $GF\ p$\\ CTL: $AGAF\ p$
\end{itemize}

\subsection{Case Study: Mutual Exclusion}

\subsubsection{Introduction}

\paragraph{} We consider a key implementation of distributed systems - mutual exclusion. There are three main property of a mutual exclusion system:

\begin{itemize}\label{list:MutexProperties}
\item \textbf{Safety}: Only one process may have access to the same resource at any time.
\item \textbf{Liveness}: Whenever a process requests for the access to the resource, it will \textit{eventually} be granted the access.
\item \textbf{Non-blocking}: A process can always make a request to the use the resource.
\end{itemize}

\paragraph{} How do we build a system that satisfies all three properties? i.e. what is the simplest example of a system that satisfies the properties?

\paragraph{Naive Implementation} One method is to let the processes take turn (with timeout) i.e. time slicing. This is inefficient and would not scale if we need to add more processes. 

\paragraph{} We add another specification - \textbf{No strict sequencing}: No ordering exists in resource access.

\paragraph{} To model these properties of the system in temporal logic, we assign some propositions:

\begin{itemize}
\item Process $i$ is in critical section ($c_i$) when it is using the resource.
\item Process $i$ is in the trying state ($t_i$) when it is making the request to use the resource.
\item Process $i$ is in outside of critical section ($n_i$) when it is not using the resource nor requesting for access to it.
\end{itemize}

\paragraph{} In this example, we assume that there are two processes in the world and each process can only be in one of the three states written above.

\subsubsection{LTL Specification}

\paragraph{} We attempt to model in LTL:

\begin{itemize}
\item \textbf{Safety}: $G\lnot(c_1 \land c_2)$
\item \textbf{Liveness}: $G(t_1 \implies Fc_1) \land G(t_2 \implies Fc_2)$
\item \textbf{Non-blocking}: We cannot express this in LTL.
\item \textbf{No strict sequencing}: We cannot express this directly, but we can express a formula that implies the negation of no strict sequencing: $G(c_1 \implies (c_1\ W\ (\lnot c_1 \land \lnot c_1\ W\ c_2)))$.\footnote{It says that everytime we get to a $c_1$ state, either we remain in $c_1$ forever or we need to go through a $c_2$ state before getting to $c_1$ again.}
\end{itemize}

\subsubsection{CTL Specification}

\paragraph{} We attempt to model in CTL:

\begin{itemize}
\item \textbf{Safety}: $AG\lnot(c_1 \land c_2)$
\item \textbf{Liveness}:\\ $AG(t_1 \implies AFc_1) \land AG(t_2 \implies AFc_2)$
\item \textbf{Non-blocking}: 
\item \textbf{No strict sequencing}: 
\end{itemize}

\subsection{Model Building}

\paragraph{} Now that we have a set of formal specifications, we can try to build its model and check whether the model satisfies the specifications given above. 

\begin{figure}[H]
\centering
\includegraphics[scale=0.36]{graphics/mutex-model1.png}
\caption{A model of the mutual exclusion system for process 1 and 2. This model is a possible implementation for a system that satisfies mutual exclusion. The initial state is $s_0$.}\label{fig:MutexModel1}
\end{figure}

\paragraph{} We now check if our \textit{LTL specifications} are satisfied at the initial state $s_0$, i.e. $(M, s_0) \models \phi$, where $\phi$ expresses our four specifications in Section \ref{list:MutexProperties}. We find that:

\begin{itemize}
\item Safety is satisfied: There is no state in the model such that $c_1, c_2$ hold in the same state.
\item Liveness is not satisfied: check the path $s_0s_1s_3s_7s_1...$
\item Non-blocking is not expressible in LTL.
\item The negation of no-strict sequencing is not satisfied, hence the property of no-strict sequencing is satisfied: check the path $s_0s_5s_3s_4s_5s_3s_4$
\end{itemize}

\paragraph{} There are also a few assumptions we are making in this diagram:

\begin{enumerate}
\item Is the amount of time spent in each state unit time or variable time? If it is fixed time, how can we allow process 1 to stay in the critical section as long as it needs while process 2 doesn't try? i.e. do we need to add a loop from $s_2$ to itself and a loop from $s_6$ to itself?
\item A process $i$ is either in $n_i$, $t_i$ or $c_i$ state. We take the assumption that two or more states for a single process cannot happen in the same state of the model.
\end{enumerate}

\paragraph{} The way we represented non-determinism may result in one process always getting preference over the other: i.e. at $s_3$, how do we choose which state to advance to: $s_4$ or $s_7$? We need to revise the model.

\begin{figure}[H]
\centering
\includegraphics[scale=0.36]{graphics/mutex-model2.png}
\caption{The revised model (from Fig. \ref{fig:MutexModel1}) of the mutual exclusion system for process 1 and 2. We split $s_3$ into two so that we can fix the non-determinism and hence satisfying liveness.}\label{fig:MutexModel2}
\end{figure}

\paragraph{} We find that the model in Figure \ref{fig:MutexModel2} satisfies the three properties:

\begin{itemize}
\item Safety is remains satisfied.
\item Liveness is now satisfied.
\item The negation of no-strict sequencing is not satisfied, hence the property of no-strict sequencing remains satisfied.
\end{itemize}

\subsection{Fairness}

\paragraph{} In Figure \ref{fig:MutexModel1}, we see that we had paths in which some requests (states with $t_i$) that would never be served (reaching a state with $c_i$) by some "unfair" executions. To avoid this situation, we need to forbid these paths to happen in the model.

\paragraph{} As shown in Figure \ref{fig:MutexModel2}, we split $s_3$ into $s_3$ and $s_8$ in the model to hardwire order of requests by using appropriate transitions. In some sense we can think of considering the previous path in addition to the current state to determine the appropriate transitions. 

\paragraph{} To solve such a problem, we introduce what we call "fairness constraints". These limits the paths considered to the ones in which some formulas are true indefinitely often. The argument of a fairness constraint can be any formula.

\paragraph{} In the Mutual Exclusion example, we could introduce the fairness constraint $(c_1 \lor c_2)$ representing the fact that along any path, we need to serve either process infinitely often. This can be represented by adding fairness constraint statements in automatic model checkers such as NuSMV.

\paragraph{} There are two classes of fairness constraints that are usually considered:

\begin{itemize}
\item Justice Constraints: "Formula $\phi$ is true infinitely often over any path."
\item Compassion Constraints: "If formula $\phi$ is true infinitely often over any path, then $\psi$ is also true infinitely often."
\end{itemize}

\paragraph{} Note that compassion constraints impose the formula $GF\phi \implies GF\phi$ in all states considered (as it needs to be satisfied in all paths considered). We can express both justice and compassion constraints in NuSMV.

\section{Explicit Model Checking}

\paragraph{} We need an algorithmic way of computing $(M, s_0) \models \phi$ and we need it to be efficient. Turns out it is convenient to compute the whole set of states $[\phi]_M$ on which $\phi$ is true. By definition,

$$s_0 \in [\phi]_M \equiv (M, s_0) \models \phi$$

\subsection{Labelling Algorithm}\label{sec:LabellingAlgorithm}

\paragraph{} We label the states where the subformulas of $\phi$ are satisfied starting from the smallest subformulas and working outwards towards $\phi$. 

\begin{itemize}
\item Input: A model $M$ and a CTL formula $\phi$.
\item Output: The set of states in $M$ which satisfies $\phi$ (i.e. $[\phi]_M$).
\end{itemize}

\subsubsection{Labelling Propositional Variables}

\paragraph{} First, we consider all propositional variables in $\phi$ and label the states in which they hold. 

\paragraph{} For example, if $\phi = a \land b$, we label all the states where $a$ hold and also all the states where $b$ hold.

\subsubsection{Labelling Subformulas}

\paragraph{} Next, $\forall s$ state and $\forall\psi$ subformulas of $\phi$ (including $\phi$), we perform the following labelling:

\begin{itemize}
\item $\lnot\psi$: label state $s$ with $\lnot\psi$ where the state $s$ is not labelled with $\psi$.
\item $\psi_1 \land \psi_2$: label state $s$ with $\psi_1 \land \psi_2$ if state $s$ has been labelled with both $\psi_1$ and $\psi_2$.
\end{itemize}

\paragraph{} With the two definitions, we can also easily label any OR operators using double negation and De Morgan's laws.

\paragraph{} In the remaining parts of the labelling algorithm, we also consider the minimal implementation by taking advantage of equivalences and duality. Hence we will only discuss the implementation of $EX\psi$, $AF\psi$ and $E(\psi_1\ U\ \psi_2)$ as an adequate set of connectives for CTL. All others can be written in terms of these connectives.

\subsubsection{Labelling $EX\psi$}

\paragraph{} We label any state with $EX\psi$ if \textit{one of its successors} is labelled with $\psi$.

\subsubsection{Labelling $AF\psi$}

\paragraph{} If any state $s$ is labelled with $\psi$, we label it with $AF\psi$. Then we repeatedly label any state with $AF\psi$ if \textit{all of its successors} are labelled with $AF\psi$ until there is no more new labelling.

\subsubsection{Labelling $E(\psi_1\ U\ \psi_2)$}

\paragraph{} If any state $s$ is labelled with $\psi_2$, label it with $E(\psi_1\ U\ \psi_2)$. Then we repeatedly label any state with $E(\psi_1\ U\ \psi_2)$ if it is labelled with $\psi_1$ and \textit{at least one of it successor} is labelled with $E(\psi_1\ U\ \psi_2)$ until there is no more new labelling.

\subsubsection{Algorithm Output}

\paragraph{} When all the labellings are complete, we output the states which are labelled $\phi$ as the answer. 

\subsubsection{Variants: $EG\psi$}

\paragraph{} Instead of adding labels, we could also start from adding labels to all then removing them. For example, we could label states by using the following algorithm for $EG\psi$:

\begin{enumerate}
\item Label \textit{all} states with $EG\psi$.
\item If any state $s$ is not labelled with $\psi$, we delete the label $EG\psi$ from $s$. 
\item Repeatedly delete label $EG\psi$ from states that has no successors labelled $EG\psi$ until there is no more changes.
\end{enumerate}

\subsection{General Algorithm}

\paragraph{} We attempt to build a more formal and general algorithm that takes a CTL formula $\phi$ and a model $M$ as input and return the set of states $[\phi]_M$ as output. The algorithm will rely on basic set operations and three additional functions to calculate set of states that satisfy subformulas with EX, EU and AF.

\paragraph{} Again, we choose the functions to be implemented for EX, EU and AF because they form an adequate set of connectives for CTL. Alternative implementations are possible. We will see that our function will perform the appropriate rewriting for the other CTL connectives.

\subsubsection{Implementation of $SAT(\phi, M)$}

\begin{lstlisting}[mathescape=true]
function SAT($\phi$, M)
switch $\phi$:
  case $\top$: return S(M) 
    /* S(M) -> all states in model M */
  case $\perp$: return $\emptyset$
  case is atomic: return $\{s \in S(M) | \phi \in L(s)\}$
  case $\lnot\psi$: return S \ SAT($\psi$, M)
  case $\psi_1 \land \psi_2$: return SAT($\psi_1$,M) $\cap$ SAT($\psi_2$,M)
  case $\psi_1 \lor \psi_2$: return SAT($\psi_1$,M) $\cup$ SAT($\psi_2$,M)
  case $\psi_1 \rightarrow \psi_2$: return SAT($\lnot\psi_1\lor\psi_2$, M)
  case $AX\psi$: return SAT($\lnot EX\lnot\psi$, M)
  case $A(\psi_1\ U\ \psi_2)$: return
    SAT($\lnot(E[\lnot\psi_2\ U\ (\lnot\psi_1\land\lnot\psi_2)]\lor EG\lnot\psi_2)$, M)
  case $EF\psi$: return SAT($E(\top\ U\ \psi)$, M)
  case $EG\psi$: return SAT($\lnot AF\lnot\psi$, M)
  case $AG\psi$: return SAT($\lnot EF\lnot\psi$, M)
  case $EX\psi$: return SATex($\psi$, M)
  case $AF\psi$: return SATaf($\psi$, M)
  case $E(\psi_1\ U\ \psi_2)$: return SATeu($\psi_1$, $\psi_2$, M)
end switch
end function
\end{lstlisting}

\paragraph{} In the implementation of $SAT(\phi, M)$ above, we can see that rewritings are done using recursive calls to itself with a rewritten version of the formula.

\subsubsection{Auxiliary Function $SATex(\phi, M)$}

\begin{lstlisting}[mathescape=true]
function SATex($\phi$, M)
  local var X, Y
  X := SAT($\phi$, M)
  Y := $\{s_0 \in S(M)\ |\ \exists s_1 \in X: s_0 \rightarrow s_1\}$
  return Y
end function
\end{lstlisting}

\paragraph{} Notice the statement $X := SAT(\phi, M)$ handles complex formula in $\phi$ recursively. 

\subsubsection{Auxiliary Function $SATaf(\phi, M)$}

\begin{lstlisting}[mathescape=true]
function SATaf($\phi$, M)
  local var X, Y
  X := S(M)
  Y := SAT($\phi$, M)
  repeat until X = Y:
    X := Y
    Y := $Y \cup \{s\ |\ \forall s'\text{ successors of } s: s' \in Y\}$
  end repeat
  return Y
end function
\end{lstlisting}

\subsubsection{Auxiliary Function $SATeu(\phi, \psi, M)$}

\begin{lstlisting}[mathescape=true]
function SATeu($\phi$, $\psi$, M)
  local var W, X, Y
  W := SAT($\phi$, M)
  X := S(M)
  Y := SAT($\psi$, M)
  repeat until X = Y:
    X := Y
    Y := $Y \cup (W \cap \{s\ |\ \exists s'\text{ successor of }s: s' \in Y\})$
  end repeat
  return Y
end function
\end{lstlisting}

\subsubsection{LTL Implementation}

\paragraph{} Note that we do not specify the implementation for LTL here because the algorithm will need to check for all paths from a given state. This will give you a hint about the time complexity of such computation if we were to perform explicit model checking on LTL. We will discuss the time complexity of LTL explicit model checking later in Section \ref{sec:ExplicitModelCheckingComplexityAnalysis}.

\subsection{Handling Fairness}\label{sec:HandlingFairness}
\paragraph{} We use fairness conditions not to consider paths that are not meaningful for our purposes. The way model checkers handle this depends on what logic (CTL, LTL, CTL* ...) they are checking specifications for.

\paragraph{} For the case of LTL, it is trivial. Suppose we need to check a condition $\phi$ where fair paths satisfy $p$. We can simply check for the condition $GFp \implies \phi$. For CTL, we cannot sub-select path in a similar way so we need to redefine satisfaction for certain operators\footnote{Not covered in syllabus}.

\subsection{Complexity Analysis}\label{sec:ExplicitModelCheckingComplexityAnalysis}

\paragraph{} Suppose we can input the whole model explicitly. Let $V$ be the set of vertices in the model (i.e. states in the model), $E$ be the set of edges (i.e. transitions) and $|\phi|$ be the length of formula $\phi$. We see the complexities are as follows:

\begin{itemize}
\item For CTL model checking: $O(|\phi| \times (|V| + |E|))$
\item For LTL model checking: $O(2^{|\phi|} \times |V|)$
\end{itemize}

\paragraph{} The key factors that affect the time complexities are the length of the formula $\phi$ and the size of the model. In CTL, the time complexity grows linearly with $|\phi|$ and $(|V| + |E|)$. However in LTL, the time complexity grows exponentially with $|\phi|$ and linearly with $|V|$. 

\paragraph{} Despite being linear wrt the model size and formula, model checking for CTL on compact descritpions is actually a PSPACE-Complete problem: it turns out that this problem is intrinsically more difficult. 

\subsubsection{State Explosion Problem}

\paragraph{} The linearity in the size of the model does not always translate into something practically viable. The model still grows exponentially in the number of variables used in the program describing it. For example, by introducing just one Boolean variable in a NuSMV program, we are effectively doubling the size of the model. The apparent attractiveness of the linearity of the problem is still hindered by the difficulty of generating compact models. This difficulty is known as the state explosion problem.

\subsubsection{Beyond Explicit Model Checkers}

\paragraph{} We need to look for techniques that can handle large state-spaces in models resulting in descriptions of actual scenarios, irrespective of the theoretical complexity of the decision problem. While there is a variety of techniques available, we will study Ordered Binary Decision Diagrams (OBDDs) and Bounded Model Checking (BMC). 

\section{Ordered Binary Decision Diagrams}

\paragraph{} Ordered Binary Decision Diagrams (OBDDs) are efficient symbolic structures to represent Boolean formulas. This will enable us to perform symbolic model checking later.

\subsection{Binary Decision Trees}

\paragraph{} Binary Decision Trees (BDTs) are binary trees that represent propositional formulas just like truth tables. By convention, we use dashed lines (-\ -\ -) to assign a false decision to a variable and solid lines (---) to assign a true decision to a variable.

\paragraph{} For example, we consider the formula $\lnot(x \lor y)$. The truth table would be:

\begin{table}[H]
\centering
\begin{tabular}{c | c | c}
$x$ & $y$ & $f(x, y)$ \\
\hline
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0 \\
1 & 1 & 0 \\
\end{tabular}
\caption{The truth table for the formula $\lnot(x \lor y)$.}
\end{table}

\paragraph{} We can draw its corresponding BDT to be:

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{graphics/bdt-d1.png}
\caption{The BDT of the formula $\lnot(x \lor y)$.}\label{fig:BDTD1}
\end{figure}

\subsubsection{Truth Tables vs BDTs}\label{sec:TruthTablesvsBDTs}

\paragraph{} Considering a propositional formula $\phi$ with $n$ propositional variables. 

\begin{itemize}
\item It would take $O(n^2)$ to look through the truth table for the satisfiability of a given assignment, while it only takes $O(n)$ in a BDT.
\item Checking for validity of a formula via truth tables can be done going through at most $2^n$ values, which is the same on BDTs (leaf nodes).
\end{itemize}

\paragraph{} If we perform Boolean operations on a formula, using a truth table would require a recalculation of the truth table, while we will see later that on BDT it can be done quickly. 

\paragraph{} Checking for equivalences between formulas is expensive on both truth tables and BDTs. However this can become easy with some advanced representations generated from BDTs.

\subsection{Reduction Algorithm}

\subsubsection{Optimisations to BDTs -- BDDs}

\paragraph{} We can develop algorithms to reduce the size of a BDT which produces a Binary Decision Diagram (BDD). A BDD is a directed graph that serves the same purpose as BDT. For example:

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{graphics/bdd-d1.png}
\caption{Two versions of BDDs reduced from the BDT in Figure \ref{fig:BDTD1} of the formula $\lnot(x \lor y)$. The left BDD shows the collapse of the three "0" leaf node into one (i.e. sharing common results) while the right BDD shows the removal of a redundant decision point "$y$".}
\end{figure}

\subsubsection{Algorithm Steps}

\paragraph{} We formally define a reduction algorithm that reduces a BDT to a reduced Binary Decision Diagram by iteratively applying these steps:

\paragraph{C1. Removal of duplicate terminals} If a BDD contains more than one $0$-node, we redirect all edges which point to such a $0$-node to just one of them and remove the others. We proceed with the same way for terminal nodes labelled with $1$.

\paragraph{C2. Removal of redundant tests} If both outgoing edges of a node $n$ in the BDD point to the same node $m$, then we send all incoming edges of $n$ to $m$ and eliminate the node $n$.

\paragraph{C3. Removal of duplicate non-terminals} If two distinct nodes $n$ and $m$ in the BDD are the roots of structurally identical sub-BDDs, we eliminate one of them. Say for example we eliminate $m$, and we direct all of $m$'s incoming edges to $n$.

\subsubsection{Definition}

\paragraph{} A BDD is said to be reduced if none of the optimisations C1, C2, C3 can be applied (i.e. no more possible reductions). 

\begin{defn}
(Huth and Ryan Def 6.5)\\ A binary decision diagram (BDD) is a finite DAG with a unique initial node, where all terminal nodes are labelled with $0$ or $1$, and all non-terminal nodes are labelled with a Boolean variable. Each non-terminal node has exactly two edges from that node to others: one labelled $0$ and one labelled $1$ (we represent them as a dashed line and a solid line respectively; alternatively we write $0$ and $1$ on the edges respectively.)
\end{defn}

\subsubsection{Important BDDs}

\paragraph{} There are some important BDDs, which we call $B_0, B_1, B_x$:

\begin{figure}[H]
\centering
\includegraphics[scale=0.36]{graphics/bdd-impt.png}
\caption{The three important BDDs (left to right): $B_0, B_1, B_x$}
\end{figure}

\subsection{Comparing BDDs}

\paragraph{} Comparing two formulas is computationally expensive as discussed in Section \ref{sec:TruthTablesvsBDTs}. Depending on the order of the variables in the ranks of the BDT, we may have different reduced BDDs of the same formula with different sizes. We need a canonical method to compare these formula.

\subsection{Variable Ordering}

\paragraph{} Different variable orderings would create different reduced BDDs. Certain variable orderings may give smaller reduced BDDs than others. An ordered BDD (OBDD) is a BDD which has an ordering for its variables.

\begin{defn}
(Huth and Ryan Def 6.6)\\
Let $[x_1,...,x_n]$ be an ordered list of variables without duplications and let $B$ be a BDD all of whose variables occur somewhere in the list. We say that $B$ has the ordering $[x_1, ..., x_n]$ if all variable labels of $B$ occur in that list and for every occurrence of $x_i$ followed by $x_j$ along any path in $B$, we have $i < j$
\end{defn}

\subsection{Reduced OBDDs}

\paragraph{} One important property of OBDDs is that their reduced structure is unique for a given Boolean formula. We call these reduced structures as ROBDDs.

\begin{thm}
The reduced OBDD representing a given Boolean function $f$ is unique, once a variable ordering has been fixed.
\end{thm}

\paragraph{} When performing operations on two OBDDs, we require them to have compatible variable orderings. The orderings of $B_f$ and $B_y$ are said to be compatible iff there are no variables $x$ and $y$ st $x$ precedes $y$ in the ordering of variables in $B_f$ and $y$ precedes $x$ in the ordering of variables in $B_y$.

\begin{thm}
Assume $B_f$ and $B_y$ to be two ROBDDs with compatible variable orderings. If $B_f$ and $B_y$ represent the same Boolean function, then they have identical structure.
\end{thm}

\paragraph{} If we apply the reductions C1, C2, C4 to an OBDD until there are no further reductions possible, then we are guaranteed that the result is always the same ROBDD. We therefore say that the OBDDs have a \textit{canonical form}, which is their reduced form.

\subsection{Importance of Canonical Form}

\paragraph{} The canonical representation for BDDs become crucial when we would like to perform certain useful tests on its corresponding Boolean formula. Consider the formulas $f$ and $g$ and their ROBDD representations $B_f$ and $B_g$. We can:

\begin{itemize}
\item \textbf{Test for validity}: $f$ is valid iff $B_f = B_1$.
\item \textbf{Test for satisfiability}: $f$ is satisfiable iff $B_f \not= B_0$.
\item \textbf{Test for semantic equivalence}: $f$ and $g$ are semantically equivalent iff $B_f = B_g$.
\end{itemize}

\section{Symbolic Model Checking with OBDDs}

\paragraph{} OBDDs can be used to perform symbolic model checking. This is the technique implemented in NuSMV, MCMAS and many other model checkers as symbolic model checking technique can be much more efficient than explicit model checking techniques. 

\paragraph{} The key observation is that we can represent sets and functions between sets as Boolean formulas. Once we have a Boolean formula, we can construct the corresponding OBDD and build the corresponding ROBDD. Operations on sets and functions can then be executed on the ROBDD. 

\subsection{Representing sets of states}

\paragraph{} Boolean functions can be used to encode states. Considering the set of states $S = \{a, b, c, d, e, f\}$, to represent any element in $S$ we need a number of $n = 3$ bits. This means that we can build a correspondence between a vector of Boolean values to elements in a set. 

\paragraph{} In general, to represent any element of a set $S$, we need at least $n$ bits where $2^n > |S| > 2^{n-1}$. Usually, $S$ does not have a cardinality power of 2 and hence some vectors will not code up any element.

\subsection{Representing Subsets}

\paragraph{} The subsets of $S$ can now be thought of as functions $\{0, 1\} \times \{0, 1\} \times \{0, 1\} \rightarrow \{0, 1\}$. The domain / pre-image of the function codes up all possible vectors representing the state and the range / image of the function is 0 or 1 depending on whether the element in in the subset or not.

\paragraph{} In the example $S = \{a, b, c, d, e, f\}$, since $n = 3$, there are $2^{2^3} = 256$ such functions / propositions, even though in reality there are only $2^6 = 64$ subsets of $S$\footnote{We had to pad representation of $S$ to 8 elements.}. 

\paragraph{} Equivalently, we can represent a subset using a Boolean formula over the atoms $\{x_1, x_2, x_3\}$. Consider the subset $S_1 = \{a, c, e\} \subseteq S$: $S_1$ can be encoded as $\{000, 010, 100\}$ and represented by the following propositional formula:

\begin{align*}
f_{S_1} =\ &(\lnot x_1 \land \lnot x_2 \land \lnot x_3)\\
 &\lor (\lnot x_1 \land x_2 \land \lnot x_3)\\
 &\lor (x_1 \land \lnot x_2 \land \lnot x_3)
\end{align*}

\paragraph{} The simplification of $f_{S_1}$ results in:

\begin{align*}
f_{S_1} = (\lnot x_1 \lor \lnot x_2) \land \lnot x_3
\end{align*}

\paragraph{} $f_{S_1}$ can now be encoded as ROBDD after picking a variable ordering.

\subsection{Operation on Sets}

\paragraph{} Set operations can be encoded as Boolean operations on their corresponding Boolean formulas. In particular:

\begin{align*}
f_{S_1 \cap S_2} &= f_{S_1} \land f_{S_2} \\
f_{S_1 \cup S_2} &= f_{S_1} \lor f_{S_2} \\
f_{-S_1} &= \lnot f_{S_1} \\
\end{align*}

\paragraph{} The set operations - namely intersection, union and complement - mentioned in explicit model checking can now be encoded as boolean operations directly. 

\paragraph{} There are two other functions $pre_\exists$ and $pre_\forall$ used in explicit model checking where

\begin{itemize}
\item $pre_\exists(X) = \{ s\ |\ \exists s': s \rightarrow s' \land s \in X \}$
\item $pre_\forall(X) = \{ s\ |\ \forall s': s \rightarrow s' \implies s \in X \}$
\end{itemize}

\paragraph{} To see how these functions can be implemented in symbolic model checking, we need to first see how the transition relation $\rightarrow$ is represented.

\subsection{Symbolic Encoding}\label{sec:SymbolicEncoding}

\paragraph{} Models denoted by model checkers have the property that where $S$ is the set of all states, $\forall s_1, s_2 \in S: \pi(s_1) = \pi(s_2) \implies s_1 = s_2$. This means that a state is determined entirely by the atomic formulas that are true in it. This is because the variables used in the code are then used as propositional variables for the specifications.

\paragraph{} Consider the following model:

\begin{figure}[H]
\centering
\includegraphics[scale=0.7]{graphics/symbolic-encoding-example}
\caption{Example model}\label{fig:SymbolicModelExample}
\end{figure}

\paragraph{} The set of states from the model may be represented by Boolean values and by Boolean formulas as follows:

\begin{table}[H]
\centering\footnotesize
\bgroup
\def\arraystretch{1.5}
\begin{tabular}{ p{0.8cm} | p{2.4cm} p{3.2cm} }
Set of States & Representation by Boolean values & Representation by Boolean function\\
\hline
\hline

$\emptyset$ & & 0\\
\hline
$\{s_0\}$ & $\{(1, 0)\}$ & $x_1 \land \lnot x_2$\\
$\{s_1\}$ & $\{(0, 1)\}$ & $\lnot x_1 \land x_2$\\
$\{s_2\}$ & $\{(0, 0)\}$ & $\lnot x_1 \land \lnot x_2$\\
\hline
$\{s_0, s_1\}$ & $\{(1, 0), (0, 1)\}$ & $(x_1 \land \lnot x_2) \lor (\lnot x_1 \land x_2)$\\
$\{s_1, s_2\}$ & $\{(0, 1), (0, 0)\}$ & $(\lnot x_1 \land x_2) \lor (\lnot x_1 \land \lnot x_2)$\\
$\{s_2, s_0\}$ & $\{(0, 0), (1, 0)\}$ & $(\lnot x_1 \land \lnot x_2) \lor (\lnot x_1 \land x_2)$\\
\hline
$S$ & $\{(1, 0), (0, 1), (0, 0)\}$ & $(x_1 \land \lor x_2) \lor (\lnot x_1 \land x_2) \lor (\lnot x_1 \land \lnot x_2)$\\

\end{tabular}
\egroup
\caption{Symbolic encoding for the model in Figure \ref{fig:SymbolicModelExample}.}
\end{table}

\paragraph{} Noticed that the vector $(1, 1)$ and its corresponding formula $x_1 \land x_2$ are unused by the model in Figure \ref{fig:SymbolicModelExample}. It is up to us to decide whether to include it in the representation of a subset of $S$ or not. We may include it if this optimises the size of the resulting ROBDD.

\paragraph{} For example, the subset $\{s_0, s_1\}$ is more efficiently represented by the equivalent Boolean function $x_1 \lor x_2$ (that means $(1, 1)$) since its ROBDD is smaller than that for $(x_1 \land \lnot x_2) \lor (\lnot x_1 \land x_2)$ as we can see below:

\begin{multicols}{2}
\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{graphics/symbolic-encoding-obdd1}
\caption{The ROBDD of $x_1 \lor x_2$ using order $(x_1, x_2)$.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.6]{graphics/symbolic-encoding-obdd2}
\caption{The ROBDD of $(x_1 \land \lnot x_2) \lor (\lnot x_1 \land x_2)$ using the same order $(x_1, x_2)$.}
\end{figure}
\end{multicols}

\paragraph{} To compute the OBDD for the transition relation $\rightarrow$ of the model given in Figure \ref{fig:SymbolicModelExample}, we first need to encode the truth table of $\rightarrow$. Each $1$ in the relation column represents a transition between two states and $0$ represents absence of such transition. We write $-$ to denote transitions we don't care. The table below shows this:

\begin{table}[H]
\centering
\begin{tabular}{ c c | c c | c }
\multicolumn{2}{ c |} {$s_1$} & \multicolumn{2}{ c |} {$s_2$} & \\
$x_1$ & $x_2$ & $x'_1$ & $x'_2$ & $\rightarrow$ \\
\hline

0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 1 & 0\\
0 & 0 & 1 & 0 & 1\\
0 & 0 & 1 & 1 & -\\
\hline

0 & 1 & 0 & 0 & 1\\
0 & 1 & 0 & 1 & 0\\
0 & 1 & 1 & 0 & 0\\
0 & 1 & 1 & 1 & -\\
\hline

1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 1 & 1\\
1 & 0 & 1 & 0 & 0\\
1 & 0 & 1 & 1 & -\\
\hline

1 & 1 & 0 & 0 & -\\
1 & 1 & 0 & 1 & -\\
1 & 1 & 1 & 0 & -\\
1 & 1 & 1 & 1 & -\\

\end{tabular}
\caption{The truth table of state transition relation for the example model given in Figure \ref{fig:SymbolicModelExample}.}
\end{table}

\paragraph{} Now we can represent the transition relation $\rightarrow$ as a Boolean function by taking the disjunction of the rows having $1$ in the last column. We would obtain the following expression:

\begin{align*}
f_\rightarrow = &(\lnot x_1 \land \lnot x_2 \land \lnot x'_1 \land \lnot x'_2)\\
&\lor (\lnot x_1 \land \lnot x_2 \land x'_1 \land \lnot x'_2)\\
&\lor (x_1 \land \lnot x_2 \land \lnot x'_1 \land x'_2)\\
&\lor (\lnot x_1 \land x_2 \land \lnot x'_1 \land \lnot x'_2)
\end{align*}

\paragraph{Variable Ordering} It is usually more efficient to interleave unprimed and primed variables in the OBDD variable ordering for $\rightarrow$. Variable ordering is important in getting compact OBDD representations. Consider using the ordering $(x_1, x'_1, x_2, x'_2)$ instead:

\begin{table}[H]
\centering
\begin{tabular}{ c c | c c | c }
$x_1$ & $x'_1$ & $x_2$ & $x'_2$ & $\rightarrow$ \\
\hline

0 & 0 & 0 & 0 & 1\\
0 & 0 & 0 & 1 & 0\\
0 & 0 & 1 & 0 & 1\\
0 & 0 & 1 & 1 & 0\\
\hline

0 & 1 & 0 & 0 & 1\\
0 & 1 & 0 & 1 & -\\
0 & 1 & 1 & 0 & 0\\
0 & 1 & 1 & 1 & -\\
\hline

1 & 0 & 0 & 0 & 0\\
1 & 0 & 0 & 1 & 1\\
1 & 0 & 1 & 0 & -\\
1 & 0 & 1 & 1 & -\\
\hline

1 & 1 & 0 & 0 & 0\\
1 & 1 & 0 & 1 & -\\
1 & 1 & 1 & 0 & -\\
1 & 1 & 1 & 1 & -\\

\end{tabular}
\caption{The truth table of state transition relation for the example model given in Figure \ref{fig:SymbolicModelExample} using the ordering $(x_1, x'_1, x_2, x'_2)$.}
\end{table}

\paragraph{BDD Reduction} For the don't care expressions, we can choose to assign them with $0$ or $1$ reduce the BDD. Ideally, we want to group them with their neighbours to form blocks of $0$s and $1$s. For example, consider the following substitutions:


\begin{table}[H]
\centering
\begin{tabular}{ c c | c c | c | c | p{1,4cm} }
$x_1$ & $x'_1$ & $x_2$ & $x'_2$ & $\rightarrow$ & $\rightarrow_\theta$ &  \\
\hline

0 & 0 & 0 & 0 & 1 & 1 & \\
0 & 0 & 0 & 1 & 0 & 0 & \\
0 & 0 & 1 & 0 & 1 & 1 & \\
0 & 0 & 1 & 1 & 0 & 0 & \\
\hline

0 & 1 & 0 & 0 & 1 & 1 & \multirow{2}{2cm}{\footnotesize '$1$' groups these rows} \\
0 & 1 & 0 & 1 & - & 1 & \\
\cline{7-7}
0 & 1 & 1 & 0 & 0 & 0 & \multirow{2}{2cm}{\footnotesize '$0$' groups these rows} \\
0 & 1 & 1 & 1 & - & 0 & \\
\hline

1 & 0 & 0 & 0 & 0 & 0 & \\
1 & 0 & 0 & 1 & 1 & 1 & \\
\cline{7-7}
1 & 0 & 1 & 0 & - & 0 & \multirow{2}{2cm}{\footnotesize '$0$' groups these rows} \\
1 & 0 & 1 & 1 & - & 0 & \\
\hline

1 & 1 & 0 & 0 & 0 & 0 & \multirow{4}{2cm}{\footnotesize '$0$' groups these rows} \\
1 & 1 & 0 & 1 & - & 0 & \\
1 & 1 & 1 & 0 & - & 0 & \\
1 & 1 & 1 & 1 & - & 0 & \\

\end{tabular}
\caption{The truth table of state transition relation for the example model given in Figure \ref{fig:SymbolicModelExample}  with the appropriate don't-care $\theta$ substitutions.}
\end{table}

\subsection{Implementing $pre_\exists$ and $pre_\forall$}

\paragraph{} Now we consider how an OBDD for $pre_\exists$ and $pre_\forall$ can be constructed, given OBDDs $B_X$ for $X$ and $B_\rightarrow$ for the transition relation $\rightarrow$. Recall that this is required for computing the pre-images of sets for the explicit labelling algorithm in Section \ref{sec:LabellingAlgorithm}. Observe that because

$$pre_\forall(X) = S \backslash pre_\exists(S \backslash X)$$

\noindent we only need to compute the OBDD for $pre_\exists(X)$. 

\subsection{$pre_\exists(X)$ BDD Computation}

\paragraph{} The following is the algorithm for the BDD computation of $pre_\exists(X)$:

\begin{enumerate}
\item We rename variables in $B_X$ to their primed versions and call this resulting OBDD $B_{X'}$.
\item We compute the OBDD for\\ $exists(\hat{x}, apply(\land, B_\rightarrow, B_{X'}))$ using the apply and exists algorithms\footnote{The $apply$ and $exists$ algorithms are not covered in this course. For more details, see Huth and Ryan pp. 372-380.}. 
\end{enumerate}

\paragraph{} The $apply$ algorithm implements a number of set operations on the corresponding OBDDs, but in this case we are only using the $\land$ operation. The $exists$ algorithm\footnote{The algorithm is NP-complete.} exploits the reduction $\exists x f = f[0/x] \lor f[1/x]$\footnote{Quantified Boolean formula (QBF) problem.}. Hence in OBDD terms: $exists(x, B_f) = apply(+, restrict(0, x, B_f), restrict(1, x, B_f))$.

\subsection{Direct BDD construction}

\paragraph{} In Section \ref{sec:SymbolicEncoding} we constructed $B_\rightarrow$ by defining its Boolean function first. This is not scalable for real systems and it is not how model checkers would build $B_\rightarrow$. We will see how NuSMV and other model checkers enable us to define how the values of variables change over states given the current state. Essentially, this defines a function $f_i$ for each variable $x_i$ in the system. 

\paragraph{} It follows that the transition relation $\rightarrow$ can be encoded as the Boolean function

$$\prod_{i = 1,...,n} x'_i \leftrightarrow f_i(x_1, ..., x_n)$$

\paragraph{} This enables us to compute the BDD $B_\rightarrow$ directly from the program describing the next state of functions.

\section{NuSMV Model Checking}

\paragraph{} We want to describe the model $M_S$ of a system $S$ by means of writing a program and use a specialised tool to determine if $M_S \models \phi_P$. A \textit{model checker} is a tool supporting both requirements. It provides a programming language to describe the model succinctly and performs the specification checks automatically. The $phi_P$ checked by the model checker usually corresponds with the specification $P$ that needs checking.

\subsection{Model Checkers}

\paragraph{} There is a variety of model checkers available: some are released under the GNU GPL for free to download. Here are a few:

\begin{itemize}
\item NuSMV: an extremely popular model checker supporting both LTL and CTL. Supports both BDDs and SAT-based checking (bounded model checking). 
\item PRISM: a popular probabilistic model checker supporting discrete and continuous time Markov chains and Markov decision processes (MDPs). Language incorporates PCTL and Continuous Stochastic Logic (CSL).
\item SPIN: a popular on-the-fly verifier for LTL specifications. It can be unsed in combination with with partial order reduction and BDD. Its programming language, PROMELA\footnote{Process or Protocol Meta Language}, is very well-known. Released in the 1990s.
\item MCMAS: an experimental model checker for CTL and logics for multi-agent systems using BDDs. The input language directly implements \textit{Interpreted Systems}, a semantics for multi-agent system logics.
\item VerICS: a well-developed SAT-based model checker for CTL, LTL and real-time logics, as well as some logics for multi-agent systems. It also supports BDD-based model checking for various extensions of LTL and CTL. It uses bounded and unbounded model checking techniques. Supports a variety of input languages (e.g. KRONOS and UML).
\end{itemize}

\subsection{Intro to NuSMV}

\paragraph{} NuSMV\footnote{A re-implementation of the original PhD work by McMillan.} is an open-source automatic model checker uses OBDDs for both LTL and CTL model checking and Boolean satisfiability for bounded model checking. SMV stands for Symbolic Model Verifier.

\paragraph{} The input language of NuSMV is simply called SMV and the $\phi_P$ in SMV are formulae in LTL or CTL that are appropriately formalised. Given the input model and formulae to be checked, NuSMV will return either $true$ or $false$, and in some cases with counterexamples when returning $false$.

\paragraph{} It takes time to compute the answer and the amount of time depends on the size of the model and formulae under checking:

\begin{itemize}
\item Models up to $10^{10}$ states should be generally fast to verify.
\item Anything beyond $10^{15}$ states may require a lot more time.
\end{itemize}

\subsection{SMV Language}

\paragraph{} A full description of the SMV language can be found on their website\footnote{\url{http://nusmv.irst.itc.it/NuSMV/userman/index-v2.html}}. This section will only cover some basic features of the SMV language.

\subsubsection{First SMV Program}

\paragraph{} Consider the following simple example of a SMV program:

\begin{lstlisting}
MODULE main
VAR
	b0: boolean;
ASSIGN
	init(b0) := 0;
	next(b0) := !b0;
\end{lstlisting}

This is equivalent of building the following model:

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{graphics/smv-example1-state}
\caption{The visual state diagram of the simple SMV program.}
\end{figure}

\begin{itemize}
\item \lstinline{b0: boolean;} declares a variable $b0$ of boolean type.
\item \lstinline{init(b0) := 0;} defines the initial state(s) that a variable can have.
\item \lstinline{next(b0) := !b0;} defines the transition relation.
\end{itemize}

\subsubsection{State Variable Data Types}

\paragraph{} In SMV, you can declare various data types:

\begin{itemize}
\item Boolean: \begin{lstlisting}
VAR
  v: boolean;
\end{lstlisting}
\item Enumerate: \begin{lstlisting}
VAR
  v: { running, stopped, idle };
\end{lstlisting}
\item Bounded Integers: \begin{lstlisting}
VAR
  v: 1 .. 10;
\end{lstlisting}
\end{itemize}

\paragraph{} Bounded Integers are used instead of unbounded integers or floating point precision numbers because we want to limit the amount of state space that the program has to check.

\subsubsection{Assignments}

\paragraph{} Assignments are ways we can update the state variables and set their initial state.

\paragraph{Initialisation} To initialise a variable, we write:

\begin{lstlisting}
init(x) := expr;
\end{lstlisting}

\paragraph{} If a variable contains no init statements, it is initialised non-deterministically (i.e. random) and the number of initial states will reflect this. This depends on the data type of the variable.

\paragraph{Updating} To update a variable, we write:

\begin{lstlisting}
next(x) := expr;
\end{lstlisting}

\paragraph{} If a variable does not contain any next statements, it will be updated non-deterministically. If you want a variable to be initialised non-deterministically but use the same value throughout the program, you need to omit the init statement and use the following next statement:

\begin{lstlisting}
next(x) := x;
\end{lstlisting}

\paragraph{} You can think of adding init and next statements to constraint the possible transition of a variable from one state to another.

\subsubsection{Boolean Operators}

\paragraph{} The following are some boolean operators expressed in SMV:

\begin{itemize}
\item ! represents negation (i.e. $\lnot$)
\item \& represents and (i.e. $\land$)
\item | represents or (i.e. $\lor$)
\item -> represents implication (i.e. $\implies$)
\end{itemize}

\subsubsection{Using Cases}

\paragraph{} To encode some if-else/switch logic into the next statements, you can write for example:

\begin{lstlisting}
next(status) := case
	req: busy; -- return busy if req
	1: {ready, busy}; -- non-det choice
esac; -- esac is just flipping case
\end{lstlisting}

\subsubsection{Writing CTL/LTL Specifications}

\paragraph{} To write a LTL statement, we use the \lstinline{LTLSPEC} keyword. For example to foramlise the LTL formula $G(request \rightarrow F(status = busy))$:

\begin{lstlisting}
LTLSPEC
	G(request -> F status = busy);
\end{lstlisting}

\paragraph{} For CTL specifications, we specify similarly using the \lstinline{SPEC} keyword: 

\begin{lstlisting}
SPEC
	AG(request -> AF status = busy);
\end{lstlisting}

\subsubsection{Modules}

\paragraph{} To break a model into smaller modules, we can write additional modules using the \lstinline{MODULE} keyword:

\begin{lstlisting}
MODULE my_mod
VAR
	out: 0..9;
ASSIGN
	next(out) := (out + 1) mod 10;

MODULE main
VAR
	m1: my_mod; -- my_mod gets used here
	m2: my_mod;
	sum: 0..18;
ASSIGN
	sum := m1.out + m2.out;
\end{lstlisting}

\paragraph{} Note that in this example, the module is placed as data types to variables in the main module. Also, the sum assignment is not bounded to any state. Module declarations can also take parameters, which makes it useful for communicating between modules:

\begin{lstlisting}
MODULE my_mod(in)
VAR
	out: 0..9;
	my_sum: 0 .. 18;
ASSIGN
	next(out) := (out + 1) mod 10;
	my_sum = out + in;

MODULE main
VAR
	m1: my_mod(m2.out);
	m2: my_mod(m1.out);
ASSIGN
	...
\end{lstlisting}

\subsubsection{Fairness}

\paragraph{} In Section \ref{sec:HandlingFairness}, we talked about the incorrect behaviour that can arise sometimes because it corresponds to circumstances of no interest (e.g. bit transmission with a constantly faulty channel). In these circumstances, we often mentioned the possibility of assuming "fairness". This is supported by NuSMV by the statement:

\begin{lstlisting}
FAIRNESS X;
\end{lstlisting}

where $X$ is a valid statement or variable. For example:

\begin{lstlisting}
FAIRNESS !(channel.status = faulty);
\end{lstlisting}

\paragraph{} NuSMV will only consider runs in which the variable X becomes true infinitely often.

\subsubsection{Synchronous/Asynchronous}

\paragraph{} So far we assume synchronous execution / transition of the model, i.e. all processes move from state to state together in a locked transition. Often it is helpful though to assume that processes may make moves independently as threads on a single-core machine would.

\paragraph{} To take advantage of the possibilities offered by asynchronous modelling in NuSMV\footnote{Since NUSMV version 2.5.0 processes are deprecated. In future versions of NUSMV processes
may be no longer supported, and only synchronous FSM will be supported by the input language.
Modeling of asynchronous processes will have to be resolved at higher level.}, we use the construct of \textit{processes}. Processes enable NuSMV to select non-deterministically which process gets selected to compute a next state (i.e. interleaving concurrency). It is only the state of the selected process that will have a changed state and all other processes will remain unchanged. To say that a variable represents a process, we write "process" before the variable type:

\begin{lstlisting}
VAR
	pr1: process prc(other.val);
\end{lstlisting}

\section{Epistemic Specifications}

\subsection{Donald Rumsfeld (2002)}

\paragraph{} Assuming that $E_{we}$ is a pseudo-common knowledge operator, we can formalise the words from Donald Rumsfeld in 2002\footnote{Donald Rumsfeld was United States of America Secretary of Defense. The full transcript can be found at \url{http://archive.defense.gov/Transcripts/Transcript.aspx?TranscriptID=2636}} into the following:

\paragraph{} "As we know, there are known knowns, i.e. there are things we know that we know"

$$\exists x E_{we} E_{we} p(x)$$

\paragraph{} "We also know that there are known unknowns, i.e. we know there are some things we know that we do not know"

$$E_{we} \exists x \lnot E_{we} p(x)$$

\paragraph{} "But there are unknown unknowns - the ones we don't know we don't know."

$$\exists x \lnot E_{we} \lnot E_{we} p(x)$$

\paragraph{} There are some specifications - in particular epistemic specifications\footnote{specification of relation to knowledge that one or a group of agents have.} - that cannot be expressed in CTL or LTL. We can express the concept of knowledge over time (i.e. CTL or LTL) and eventually express high level concepts such as wants and beliefs\footnote{Doxastic logic}. These concepts can help us describe complex behaviour, especially when autonomous. 

\subsection{Autonomous Multi-Agent Systems (MAS)}

\paragraph{} Agents are computer systems that are:

\begin{itemize}
\item \textit{situated} in some environment;
\item capable of \textit{autonomous actions};
\item capable of \textit{social interaction} with peers; and
\item acting \textit{to meet} their design objectives.
\end{itemize}

\paragraph{} In some sense, MAS are distributed systems but with:

\begin{itemize}
\item Emphasis on intentional properties of the processes.
\item Programmed and specified in terms of high-level concepts such as their knowledge, beliefs, desires, intentions, goals, commitments,...
\end{itemize}

\paragraph{} Compare these requirements with simpler specifications given in terms of temporal ones only.

\paragraph{} There are three levels of work on MAS systems with different levels of abstraction:

\begin{enumerate}
\item \textbf{Agent Technology}: Communication languages and coordination platforms.
\item \textbf{Models of Interaction}: negotiation, auctions, cooperation, etc.
\item \textbf{Formalisms}: on specification and verification - logical models of knowledge, strategic abilities, beliefs, etc.
\end{enumerate}

\subsection{MAS Specification vs Epistemic Logic}

\paragraph{} It is important to verify knowledge of agents because agents' behaviour depends on what they know. We use the notation $K_i p$ for represent that agent $i$ knows $p$. Some examples include:

\begin{itemize}
\item Agent $a$ does not know whether "key" is the secret key or not\footnote{This fact is represented either timeless (i.e. forever) or at the current point in time.}: $$\lnot K_a\ key \lor \lnot K_a \lnot key$$
\item ... but Agent $b$ knows: $$K_b\ key \lor K_b \lnot key$$
\item Agent $a$ knows that agent $b$ knows: $$K_a(K_b\ key \lor K_b \lnot key)$$
\item Agent $b$ knows that agent $a$ at some point in time will know as well: $$K_b\ AF(K_a\ key \lor K_a \lnot key)$$
\end{itemize}

\paragraph{} As shown in the last example, we can combine temporal logics with epistemic logics to model the specifications accurately.

\subsection{Interpreted Systems}

\paragraph{} We take the basic assumption that a MAS can be represented in terms of local \textbf{states}, \textbf{actions}, \textbf{protocols} and \textbf{transitions} for the agents $A = \{1, ..., n\}$ and for the environment $e$. Then,

\begin{itemize}
\item $L_i$ is the set of local states for agent $i \in A$.
\item $L_e$ is the set of local states of the environment.
\item $Act_i$ is the set of local actions for agent $i \in A$.
\item $Act_e$ is the set of local actions of the environment
\item $Act = Act_1 \times ... \times Act_n \times Act_e$ is the \textit{set of joint actions} for all agents and the environment.
\item A protocol $P_i: L_i \rightarrow \mathcal{P}(Act_i), i \in A$ expresses the selection mechanism of agent $i$. \footnote{$\mathcal{P}(A)$ is the powerset of the set $A$.}
\item $P_e: L_e \rightarrow \mathcal{P}(Act_e)$ expresses the functioning conditions for the environment.
\item $S = L_1 \times ... \times L_n \times L_e$ is the set of all possible global states.
\end{itemize}

\paragraph{} The system evolves synchronously with agents and the environment, selecting and performing an action at each tick of the clock. All actions need to be enabled by the respective protocols ($P_i$ or $P_e$) to be performed. 

\paragraph{} An \textit{interpreted system}\footnote{Introduced in [Fagin et al., 1995]} is then a tuple $IS = \langle {L_i, Act_i, P_i, \tau}_{i \in A\cup\{e\}}, I, h \rangle$.

\paragraph{Initial Global States} $I \subseteq S$ is the set of initial global states for the system. There exists initial local states for agent $i$ and the environment $e$.

\paragraph{System Transition Function} $\tau: S \times Act \rightarrow S$ is a deterministic transition function for the system. If $\tau(g, act) = g'$ with $act = (act_1, ..., act_n, act_e)$ then $\forall i \in A: act_i \in P_i(g_i) \land act_e \in P_i(g_e)$. $g_i$ represents the local state of agent $i$ when in state $g$ and $g_e$ represents the local state of the environment when in state $g$.

\paragraph{Reachable Global States} We refer to $G \subseteq S$ as the set of global states reachable from the set of initial global states $I$ via transition function $\tau$.

\subsection{LTLK Syntax}

\paragraph{} We use the LTLK (i.e. LTL with knowledge) language to build our specifications formally:

$$\phi ::== p | \lnot \phi | \phi \land \phi | X\phi | G\phi | \phi U \phi | K_i\phi | E_\Gamma \phi | D_\Gamma \phi | C_\Gamma \phi$$

\paragraph{} where $i \in A$ and $\Gamma \subseteq A$ (subset of all agents).

\paragraph{} Reading for the modalities above are:

\begin{itemize}
\item $K_i\phi$: "agent $i$ knows $\phi$."
\item $E_\Gamma \phi$: "everyone in the group $\Gamma$ knows $\phi$."
\item $D_\Gamma \phi$: "it is distributed knowledge in the group $\Gamma$ knows $\phi$."
\item $C_\Gamma \phi$: "it is common knowledge in the group $\Gamma$ knows $\phi$."
\end{itemize}

\subsection{LTLK Semantics}

\paragraph{} Given a formula $\phi$, a system $IS$ and a path $\rho = s_0, ...$ on $IS$, satisfaction for the LTLK connectives is defined as follows:

\begin{itemize}
\item $(IS, \rho) \models p$ iff $s_0 \in L(p)$
\item $(IS, \rho) \models X\phi$ iff $(IS, \rho^1) \models \phi$.
\item $(IS, \rho) \models G\phi$ iff $\forall j \geq 0: (IS, \rho^i) \models \phi$
\item $(IS, \rho) \models K_i\phi$ iff $\forall p' = s_0',...$ st $l_i(s_0) = l_i(s_0')$ we have $(IS, \rho') \models \phi$
\end{itemize}

\paragraph{} $l_i: G \rightarrow L_i$ returns the $i^{th}$ local component of a global state.

\paragraph{} Private knowledge is defined as a function on the local states only. Local states characterise what an agent knows about other agents and the environment. Intuitively, if one agent has the same local state in wo different global states, then the agent cannot distinguish between the two. A fact is known by an agent if it is true in all the states that he considers (epistemically) possible, i.e. the fact holds in every possible state of the system that he regards as possible.

\paragraph{} The semantics of $E_\Gamma \phi$, $D_\Gamma \phi$ and $C_\Gamma \phi$ can be extended from $K_i\phi$

\begin{itemize}
\item $(IS, \rho) \models E_\Gamma \phi$ iff $\forall p' = s_0',...$ st $l_i(s_0) = l_i(s_0')$, $\exists i \in \Gamma$ st $(IS, \rho') \models \phi$. The equivalence $E_\Gamma \phi \equiv \land_{i \in \Gamma} K_i \phi$ holds.
\item $(IS, \rho) \models D_\Gamma \phi$ iff $\forall p' = s_0',...$ where $l_i(s_0) = l_i(s_0')$, $\forall i \in \Gamma$ st $(IS, \rho') \models \phi$. There is no equivalence for $D_\Gamma \phi$ in terms of $K_i \phi$ holds.
\item $(IS, \rho) \models C_\Gamma \phi$ iff $\forall \bar{p} = \bar{s_0},...$ st there is a $p^{(1)} = s_0^{(1)},...$; $p^{(2)} = s_0^{(2)},...$; ...; $p^{(m)} = s_0^{(m)},...$ with $l_i(s_0) = l_i(s_0^{(1)}); l_j(s_0^{(1)}) = l_j(s_0^{(2)});...;l_k(s_0^{(m)}) = l_k(\bar{s_0})$, $\forall i,j,k \in \Gamma$ we have $(IS, \bar{\rho}) \models \phi$. Common knowledge for agents in $\Gamma$ is defined on the transitive closure of the union of the relations induced by the equality of local states. Common knowledge is equivalent to the unbounded conjunction of everyone knows formula: $$C_\Gamma \phi = E_\Gamma \phi \land E_\Gamma E_\Gamma \phi \land ...$$
\end{itemize}

\paragraph{} LTLK satisfaction at states is defined as in the case of LTL: $$(IS, s) \models \phi\text{ iff } \forall \rho(s): (IS, \rho(s)) \models \phi$$

\subsection{CTLK: Branching temporal-epistemic models}

\paragraph{} Interpreted systems can also be used to give a semantics to CTLK, the logic obtained by combining CTL with epistemic modalities discussed in LTLK. 

\paragraph{} Given a formula $\phi$, an interpreted system $IS$ and a state $s_0 \in IS$, satisfaction of $\phi$ at $s \in IS$ (denoted $(IS, s) \models \phi$) is defined inductively by adding the following clause to the CTL satisfaction definition:

$$(IS, s) \models K_i \phi\text{ iff } \forall s'[s \mathtt{\sim}_i s' \implies (IS, s') \models \phi]$$

\noindent where $s \mathtt{\sim}_i s' \Leftrightarrow l_i(s) = l_i'(s')$. Observe that this definition is equivalent to the one given for LTLK. We complete the remaining semantics of CTLK for $E_\Gamma \phi$, $D_\Gamma \phi$ and $C_\Gamma \phi$:

\begin{itemize}
\item $(IS, \rho) \models E_\Gamma \phi$ iff $\forall s'\ [s(\cup_{i \in \tau}\ \mathtt{\sim}_i)]s' \implies (IS, s') \models \phi$. 
\item $(IS, \rho) \models D_\Gamma \phi$ iff $\forall s'\ [s(\cap_{i \in \tau}\ \mathtt{\sim}_i)]s' \implies (IS, s') \models \phi$. 
\item $(IS, \rho) \models C_\Gamma \phi$ iff $\forall s'\ [s(\cup_{i \in \tau}\ \mathtt{\sim}_i)]^+s' \implies (IS, s') \models \phi$. 
\end{itemize}

\paragraph{} Note that the $+$ in $s'\ [s(\cup_{i \in \tau}\ \mathtt{\sim}_i)]^+s$ of the definition of $(IS, \rho) \models C_\Gamma \phi$ refers to a transitive closure on the union of relations.

\end{multicols}
\end{document}